{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama PDF RAG Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_community.vectorstores import FAISS  # This is the correct import for FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_path(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = local_path(\"Data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split text into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split into 322 chunks\n"
     ]
    }
   ],
   "source": [
    "# Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(extracted_data)\n",
    "print(f\"Text split into {len(chunks)} chunks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FAISS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create FAISS vector store\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m      3\u001b[0m     documents\u001b[38;5;241m=\u001b[39mchunks,\n\u001b[0;32m      4\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membeddings\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Save the FAISS index\u001b[39;00m\n\u001b[0;32m      8\u001b[0m index_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaiss_index_new\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FAISS' is not defined"
     ]
    }
   ],
   "source": [
    "# Create FAISS vector store\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Save the FAISS index\n",
    "index_path = \"faiss_index_new\"\n",
    "vector_store.save_local(index_path)\n",
    "print(f\"FAISS index saved to {index_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 0, 'page_label': '1'}, page_content='DSA\\nDat a St ruc tur es and Alg orith ms\\nAnn otated Referenc e w ith  Examp les\\nGranville Bar ne/g425 Luca  Del Tongo'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 1, 'page_label': '2'}, page_content='Data Structures and Algorithms:\\nAnnotated Reference with Examples\\nFirst Edition\\nCopyright c⃝ Granville Barnett, and Luca Del Tongo 2008.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 2, 'page_label': '3'}, page_content='This book is made exclusively available from DotNetSlackers\\n(http://dotnetslackers.com/) the place for .NET articles, and news from\\nsome of the leading minds in the software industry.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 3, 'page_label': '4'}, page_content='Contents\\n1 Introduction 1\\n1.1 What this book is, and what it isn’t . . . . . . . . . . . . . . . .1\\n1.2 Assumed knowledge . . . . . . . . . . . . . . . . . . . . . . . . . 1\\n1.2.1 Big Oh notation . . . . . . . . . . . . . . . . . . . . . . . 1\\n1.2.2 Imperative programming language . . . . . . . . . . . . . 3\\n1.2.3 Object oriented concepts . . . . . . . . . . . . . . . . . . 4\\n1.3 Pseudocode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4\\n1.4 Tips for working through the examples . . . . . . . . . . . . . . .6\\n1.5 Book outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n1.6 Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n1.7 Where can I get the code? . . . . . . . . . . . . . . . . . . . . . .7\\n1.8 Final messages . . . . . . . . . . . . . . . . . . . . . . . . . . . .7\\nI Data Structures 8\\n2 Linked Lists 9\\n2.1 Singly Linked List . . . . . . . . . . . . . . . . . . . . . . . . . .9'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 3, 'page_label': '4'}, page_content='1.8 Final messages . . . . . . . . . . . . . . . . . . . . . . . . . . . .7\\nI Data Structures 8\\n2 Linked Lists 9\\n2.1 Singly Linked List . . . . . . . . . . . . . . . . . . . . . . . . . .9\\n2.1.1 Insertion . . . . . . . . . . . . . . . . . . . . . . . . . . . .10\\n2.1.2 Searching . . . . . . . . . . . . . . . . . . . . . . . . . . .10\\n2.1.3 Deletion . . . . . . . . . . . . . . . . . . . . . . . . . . . .11\\n2.1.4 Traversing the list . . . . . . . . . . . . . . . . . . . . . .12\\n2.1.5 Traversing the list in reverse order . . . . . . . . . . . . .13\\n2.2 Doubly Linked List . . . . . . . . . . . . . . . . . . . . . . . . . .13\\n2.2.1 Insertion . . . . . . . . . . . . . . . . . . . . . . . . . . . .15\\n2.2.2 Deletion . . . . . . . . . . . . . . . . . . . . . . . . . . . .15\\n2.2.3 Reverse Traversal . . . . . . . . . . . . . . . . . . . . . . .16\\n2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .17\\n3 Binary Search Tree 19'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 3, 'page_label': '4'}, page_content='2.2.3 Reverse Traversal . . . . . . . . . . . . . . . . . . . . . . .16\\n2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .17\\n3 Binary Search Tree 19\\n3.1 Insertion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .20\\n3.2 Searching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .21\\n3.3 Deletion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .22\\n3.4 Finding the parent of a given node . . . . . . . . . . . . . . . . .24\\n3.5 Attaining a reference to a node . . . . . . . . . . . . . . . . . . .24\\n3.6 Finding the smallest and largest values in the binary search tree25\\n3.7 Tree Traversals . . . . . . . . . . . . . . . . . . . . . . . . . . . .26\\n3.7.1 Preorder . . . . . . . . . . . . . . . . . . . . . . . . . . . .26\\nI'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 4, 'page_label': '5'}, page_content='3.7.2 Postorder . . . . . . . . . . . . . . . . . . . . . . . . . . .26\\n3.7.3 Inorder . . . . . . . . . . . . . . . . . . . . . . . . . . . .29\\n3.7.4 Breadth First . . . . . . . . . . . . . . . . . . . . . . . . .30\\n3.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .31\\n4 Heap 32\\n4.1 Insertion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .33\\n4.2 Deletion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .37\\n4.3 Searching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .38\\n4.4 Traversal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .41\\n4.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\n5 Sets 44\\n5.1 Unordered . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .46\\n5.1.1 Insertion . . . . . . . . . . . . . . . . . . . . . . . . . . . .46\\n5.2 Ordered . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .47'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 4, 'page_label': '5'}, page_content='5.1.1 Insertion . . . . . . . . . . . . . . . . . . . . . . . . . . . .46\\n5.2 Ordered . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .47\\n5.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .47\\n6 Queues 48\\n6.1 A standard queue . . . . . . . . . . . . . . . . . . . . . . . . . . .49\\n6.2 Priority Queue . . . . . . . . . . . . . . . . . . . . . . . . . . . .49\\n6.3 Double Ended Queue . . . . . . . . . . . . . . . . . . . . . . . . .49\\n6.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\n7 AVL Tree 54\\n7.1 Tree Rotations . . . . . . . . . . . . . . . . . . . . . . . . . . . .56\\n7.2 Tree Rebalancing . . . . . . . . . . . . . . . . . . . . . . . . . . .57\\n7.3 Insertion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .58\\n7.4 Deletion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .59\\n7.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .61\\nII Algorithms 62\\n8 Sorting 63'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 4, 'page_label': '5'}, page_content='7.4 Deletion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .59\\n7.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .61\\nII Algorithms 62\\n8 Sorting 63\\n8.1 Bubble Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .63\\n8.2 Merge Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .63\\n8.3 Quick Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .65\\n8.4 Insertion Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . .67\\n8.5 Shell Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .68\\n8.6 Radix Sort . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .68\\n8.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .70\\n9 Numeric 72\\n9.1 Primality Test . . . . . . . . . . . . . . . . . . . . . . . . . . . .72\\n9.2 Base conversions . . . . . . . . . . . . . . . . . . . . . . . . . . .72\\n9.3 Attaining the greatest common denominator of two numbers . .73'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 4, 'page_label': '5'}, page_content='9.2 Base conversions . . . . . . . . . . . . . . . . . . . . . . . . . . .72\\n9.3 Attaining the greatest common denominator of two numbers . .73\\n9.4 Computing the maximum value for a number of a speciﬁc base\\nconsisting of N digits . . . . . . . . . . . . . . . . . . . . . . . . .74\\n9.5 Factorial of a number . . . . . . . . . . . . . . . . . . . . . . . .74\\n9.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75\\nII'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 5, 'page_label': '6'}, page_content='10 Searching 76\\n10.1 Sequential Search . . . . . . . . . . . . . . . . . . . . . . . . . . .76\\n10.2 Probability Search . . . . . . . . . . . . . . . . . . . . . . . . . .76\\n10.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .77\\n11 Strings 79\\n11.1 Reversing the order of words in a sentence . . . . . . . . . . . . .79\\n11.2 Detecting a palindrome . . . . . . . . . . . . . . . . . . . . . . .80\\n11.3 Counting the number of words in a string . . . . . . . . . . . . .81\\n11.4 Determining the number of repeated words within a string . . . .83\\n11.5 Determining the ﬁrst matching character between two strings . .84\\n11.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .85\\nA Algorithm Walkthrough 86\\nA.1 Iterative algorithms . . . . . . . . . . . . . . . . . . . . . . . . .86\\nA.2 Recursive Algorithms . . . . . . . . . . . . . . . . . . . . . . . . .88\\nA.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\\nB Translation Walkthrough 91'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 5, 'page_label': '6'}, page_content='A.2 Recursive Algorithms . . . . . . . . . . . . . . . . . . . . . . . . .88\\nA.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\\nB Translation Walkthrough 91\\nB.1 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .92\\nC Recursive Vs. Iterative Solutions 93\\nC.1 Activation Records . . . . . . . . . . . . . . . . . . . . . . . . . .94\\nC.2 Some problems are recursive in nature . . . . . . . . . . . . . . .95\\nC.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .95\\nD Testing 97\\nD.1 What constitutes a unit test? . . . . . . . . . . . . . . . . . . . .97\\nD.2 When should I write my tests? . . . . . . . . . . . . . . . . . . .98\\nD.3 How seriously should I view my test suite? . . . . . . . . . . . . .99\\nD.4 The three A’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99\\nD.5 The structuring of tests . . . . . . . . . . . . . . . . . . . . . . .99\\nD.6 Code Coverage . . . . . . . . . . . . . . . . . . . . . . . . . . . .100'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 5, 'page_label': '6'}, page_content='D.5 The structuring of tests . . . . . . . . . . . . . . . . . . . . . . .99\\nD.6 Code Coverage . . . . . . . . . . . . . . . . . . . . . . . . . . . .100\\nD.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .100\\nE Symbol Deﬁnitions 101\\nIII'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 6, 'page_label': '7'}, page_content='Preface\\nEvery book has a story as to how it came about and this one is no diﬀerent,\\nalthough we would be lying if we said its development had not been somewhat\\nimpromptu. Put simply this book is the result of a series of emails sent back\\nand forth between the two authors during the development of a library for\\nthe .NET framework of the same name (with the omission of the subtitle of\\ncourse!). The conversation started oﬀ something like, “Why don’t we create\\na more aesthetically pleasing way to present our pseudocode?” After a few\\nweeks this new presentation style had in fact grown into pseudocode listings\\nwith chunks of text describing how the data structure or algorithm in question\\nworks and various other things about it. At this point we thought, “What the\\nheck, let’s make this thing into a book!” And so, in the summer of 2008 we\\nbegan work on this book side by side with the actual library implementation.\\nWhen we started writing this book the only things that we were sure about'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 6, 'page_label': '7'}, page_content='began work on this book side by side with the actual library implementation.\\nWhen we started writing this book the only things that we were sure about\\nwith respect to how the book should be structured were:\\n1. always make explanations as simple as possible while maintaining a moder-\\nately ﬁne degree of precision to keep the more eager minded reader happy;\\nand\\n2. inject diagrams to demystify problems that are even moderatly challenging\\nto visualise (. . . and so we could remember how our own algorithms worked\\nwhen looking back at them!); and ﬁnally\\n3. present concise and self-explanatory pseudocode listings that can be ported\\neasily to most mainstream imperative programming languages like C++,\\nC#, and Java.\\nA key factor of this book and its associated implementations is that all\\nalgorithms (unless otherwise stated) were designed by us, using the theory of\\nthe algorithm in question as a guideline (for which we are eternally grateful to'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 6, 'page_label': '7'}, page_content='algorithms (unless otherwise stated) were designed by us, using the theory of\\nthe algorithm in question as a guideline (for which we are eternally grateful to\\ntheir original creators). Therefore they may sometimes turn out to be worse\\nthan the “normal” implementations—and sometimes not. We are two fellows\\nof the opinion that choice is a great thing. Read our book, read several others\\non the same subject and use what you see ﬁt from each (if anything) when\\nimplementing your own version of the algorithms in question.\\nThrough this book we hope that you will see the absolute necessity of under-\\nstanding which data structure or algorithm to use for a certain scenario. In all\\nprojects, especially those that are concerned with performance (here we apply\\nan even greater emphasis on real-time systems) the selection of the wrong data\\nstructure or algorithm can be the cause of a great deal of performance pain.\\nIV'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 7, 'page_label': '8'}, page_content='V\\nTherefore it is absolutely key that you think about the run time complexity and\\nspace requirements of your selected approach. In this book we only explain the\\ntheoretical implications to consider, but this is for a good reason: compilers are\\nvery diﬀerent in how they work. One C++ compiler may have some amazing\\noptimisation phases speciﬁcally targeted at recursion, another may not, for ex-\\nample. Of course this is just an example but you would be surprised by how\\nmany subtle diﬀerences there are between compilers. These diﬀerences which\\nmay make a fast algorithm slow, and vice versa. We could also factor in the\\nsame concerns about languages that target virtual machines, leaving all the\\nactual various implementation issues to you given that you will know your lan-\\nguage’s compiler much better than us...well in most cases. This has resulted in\\na more concise book that focuses on what we think are the key issues.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 7, 'page_label': '8'}, page_content='guage’s compiler much better than us...well in most cases. This has resulted in\\na more concise book that focuses on what we think are the key issues.\\nOne ﬁnal note: never take the words of others as gospel; verify all that can\\nbe feasibly veriﬁed and make up your own mind.\\nWe hope you enjoy reading this book as much as we have enjoyed writing it.\\nGranville Barnett\\nLuca Del Tongo'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 8, 'page_label': '9'}, page_content='Acknowledgements\\nWriting this short book has been a fun and rewarding experience. We would\\nlike to thank, in no particular order the following people who have helped us\\nduring the writing of this book.\\nSonu Kapoor generously hosted our book which when we released the ﬁrst\\ndraft received over thirteen thousand downloads, without his generosity this\\nbook would not have been able to reach so many people. Jon Skeet provided us\\nwith an alarming number of suggestions throughout for which we are eternally\\ngrateful. Jon also edited this book as well.\\nWe would also like to thank those who provided the odd suggestion via email\\nto us. All feedback was listened to and you will no doubt see some content\\ninﬂuenced by your suggestions.\\nA special thank you also goes out to those who helped publicise this book\\nfrom Microsoft’s Channel 9 weekly show (thanks Dan!) to the many bloggers\\nwho helped spread the word. You gave us an audience and for that we are\\nextremely grateful.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 8, 'page_label': '9'}, page_content='from Microsoft’s Channel 9 weekly show (thanks Dan!) to the many bloggers\\nwho helped spread the word. You gave us an audience and for that we are\\nextremely grateful.\\nThank you to all who contributed in some way to this book. The program-\\nming community never ceases to amaze us in how willing its constituents are to\\ngive time to projects such as this one. Thank you.\\nVI'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 9, 'page_label': '10'}, page_content='About the Authors\\nGranville Barnett\\nGranville is currently a Ph.D candidate at Queensland University of Technology\\n(QUT) working on parallelism at the Microsoft QUT eResearch Centre1. He also\\nholds a degree in Computer Science, and is a Microsoft MVP. His main interests\\nare in programming languages and compilers. Granville can be contacted via\\none of two places: either his personal website (http://gbarnett.org) or his\\nblog (http://msmvps.com/blogs/gbarnett).\\nLuca Del Tongo\\nLuca is currently studying for his masters degree in Computer Science at Flo-\\nrence. His main interests vary from web development to research ﬁelds such as\\ndata mining and computer vision. Luca also maintains an Italian blog which\\ncan be found athttp://blogs.ugidotnet.org/wetblog/.\\n1http://www.mquter.qut.edu.au/\\nVII'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 10, 'page_label': '11'}, page_content='Page intentionally left blank.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 11, 'page_label': '12'}, page_content='Chapter 1\\nIntroduction\\n1.1 What this book is, and what it isn’t\\nThis book provides implementations of common and uncommon algorithms in\\npseudocode which is language independent and provides for easy porting to most\\nimperative programming languages. It is not a deﬁnitive book on the theory of\\ndata structures and algorithms.\\nFor the most part this book presents implementations devised by the authors\\nthemselves based on the concepts by which the respective algorithms are based\\nupon so it is more than possible that our implementations diﬀer from those\\nconsidered the norm.\\nYou should use this book alongside another on the same subject, but one\\nthat contains formal proofs of the algorithms in question. In this book we use\\nthe abstract big Oh notation to depict the run time complexity of algorithms\\nso that the book appeals to a larger audience.\\n1.2 Assumed knowledge\\nWe have written this book with few assumptions of the reader, but some have'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 11, 'page_label': '12'}, page_content='so that the book appeals to a larger audience.\\n1.2 Assumed knowledge\\nWe have written this book with few assumptions of the reader, but some have\\nbeen necessary in order to keep the book as concise and approachable as possible.\\nWe assume that the reader is familiar with the following:\\n1. Big Oh notation\\n2. An imperative programming language\\n3. Object oriented concepts\\n1.2.1 Big Oh notation\\nFor run time complexity analysis we use big Oh notation extensively so it is vital\\nthat you are familiar with the general concepts to determine which is the best\\nalgorithm for you in certain scenarios. We have chosen to use big Oh notation\\nfor a few reasons, the most important of which is that it provides an abstract\\nmeasurement by which we can judge the performance of algorithms without\\nusing mathematical proofs.\\n1'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 12, 'page_label': '13'}, page_content='CHAPTER 1. INTRODUCTION 2\\nFigure 1.1: Algorithmic run time expansion\\nFigure 1.1 shows some of the run times to demonstrate how important it is to\\nchoose an eﬃcient algorithm. For the sanity of our graph we have omitted cubic\\nO(n3), and exponential O(2n) run times. Cubic and exponential algorithms\\nshould only ever be used for very small problems (if ever!); avoid them if feasibly\\npossible.\\nThe following list explains some of the most common big Oh notations:\\nO(1) constant: the operation doesn’t depend on the size of its input, e.g. adding\\na node to the tail of a linked list where we always maintain a pointer to\\nthe tail node.\\nO(n) linear: the run time complexity is proportionate to the size ofn.\\nO(log n) logarithmic: normally associated with algorithms that break the problem\\ninto smaller chunks per each invocation, e.g. searching a binary search\\ntree.\\nO(n log n) just n log n: usually associated with an algorithm that breaks the problem'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 12, 'page_label': '13'}, page_content='into smaller chunks per each invocation, e.g. searching a binary search\\ntree.\\nO(n log n) just n log n: usually associated with an algorithm that breaks the problem\\ninto smaller chunks per each invocation, and then takes the results of these\\nsmaller chunks and stitches them back together, e.g. quick sort.\\nO(n2) quadratic: e.g. bubble sort.\\nO(n3) cubic: very rare.\\nO(2n) exponential: incredibly rare.\\nIf you encounter either of the latter two items (cubic and exponential) this is\\nreally a signal for you to review the design of your algorithm. While prototyp-\\ning algorithm designs you may just have the intention of solving the problem\\nirrespective of how fast it works. We would strongly advise that you always\\nreview your algorithm design and optimise where possible—particularly loops'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 13, 'page_label': '14'}, page_content='CHAPTER 1. INTRODUCTION 3\\nand recursive calls—so that you can get the most eﬃcient run times for your\\nalgorithms.\\nThe biggest asset that big Oh notation gives us is that it allows us to es-\\nsentially discard things like hardware. If you have two sorting algorithms, one\\nwith a quadratic run time, and the other with a logarithmic run time then the\\nlogarithmic algorithm will always be faster than the quadratic one when the\\ndata set becomes suitably large. This applies even if the former is ran on a ma-\\nchine that is far faster than the latter. Why? Because big Oh notation isolates\\na key factor in algorithm analysis: growth. An algorithm with a quadratic run\\ntime grows faster than one with a logarithmic run time. It is generally said at\\nsome point asn → ∞the logarithmic algorithm will become faster than the\\nquadratic algorithm.\\nBig Oh notation also acts as a communication tool. Picture the scene: you\\nare having a meeting with some fellow developers within your product group.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 13, 'page_label': '14'}, page_content='quadratic algorithm.\\nBig Oh notation also acts as a communication tool. Picture the scene: you\\nare having a meeting with some fellow developers within your product group.\\nYou are discussing prototype algorithms for node discovery in massive networks.\\nSeveral minutes elapse after you and two others have discussed your respective\\nalgorithms and how they work. Does this give you a good idea of how fast each\\nrespective algorithm is? No. The result of such a discussion will tell you more\\nabout the high level algorithm design rather than its eﬃciency. Replay the scene\\nback in your head, but this time as well as talking about algorithm design each\\nrespective developer states the asymptotic run time of their algorithm. Using\\nthe latter approach you not only get a good general idea about the algorithm\\ndesign, but also key eﬃciency data which allows you to make better choices\\nwhen it comes to selecting an algorithm ﬁt for purpose.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 13, 'page_label': '14'}, page_content='design, but also key eﬃciency data which allows you to make better choices\\nwhen it comes to selecting an algorithm ﬁt for purpose.\\nSome readers may actually work in a product group where they are given\\nbudgets per feature. Each feature holds with it a budget that represents its up-\\npermost time bound. If you save some time in one feature it doesn’t necessarily\\ngive you a buﬀer for the remaining features. Imagine you are working on an\\napplication, and you are in the team that is developing the routines that will\\nessentially spin up everything that is required when the application is started.\\nEverything is great until your boss comes in and tells you that the start up\\ntime should not exceedn ms. The eﬃciency of every algorithm that is invoked\\nduring start up in this example is absolutely key to a successful product. Even\\nif you don’t have these budgets you should still strive for optimal solutions.\\nTaking a quantitative approach for many software development properties'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 13, 'page_label': '14'}, page_content='if you don’t have these budgets you should still strive for optimal solutions.\\nTaking a quantitative approach for many software development properties\\nwill make you a far superior programmer - measuring one’s work is critical to\\nsuccess.\\n1.2.2 Imperative programming language\\nAll examples are given in a pseudo-imperative coding format and so the reader\\nmust know the basics of some imperative mainstream programming language\\nto port the examples eﬀectively, we have written this book with the following\\ntarget languages in mind:\\n1. C++\\n2. C#\\n3. Java'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 14, 'page_label': '15'}, page_content='CHAPTER 1. INTRODUCTION 4\\nThe reason that we are explicit in this requirement is simple—all our imple-\\nmentations are based on an imperative thinking style. If you are a functional\\nprogrammer you will need to apply various aspects from the functional paradigm\\nto produce eﬃcient solutions with respect to your functional language whether\\nit be Haskell, F#, OCaml, etc.\\nTwo of the languages that we have listed (C# and Java) target virtual\\nmachines which provide various things like security sand boxing, and memory\\nmanagement via garbage collection algorithms. It is trivial to port our imple-\\nmentations to these languages. When porting to C++ you must remember to\\nuse pointers for certain things. For example, when we describe a linked list\\nnode as having a reference to the next node, this description is in the context\\nof a managed environment. In C++ you should interpret the reference as a\\npointer to the next node and so on. For programmers who have a fair amount'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 14, 'page_label': '15'}, page_content='of a managed environment. In C++ you should interpret the reference as a\\npointer to the next node and so on. For programmers who have a fair amount\\nof experience with their respective language these subtleties will present no is-\\nsue, which is why we really do emphasise that the reader must be comfortable\\nwith at least one imperative language in order to successfully port the pseudo-\\nimplementations in this book.\\nIt is essential that the user is familiar with primitive imperative language\\nconstructs before reading this book otherwise you will just get lost. Some algo-\\nrithms presented in this book can be confusing to follow even for experienced\\nprogrammers!\\n1.2.3 Object oriented concepts\\nFor the most part this book does not use features that are speciﬁc to any one\\nlanguage. In particular, we never provide data structures or algorithms that\\nwork on generic types—this is in order to make the samples as easy to follow'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 14, 'page_label': '15'}, page_content='language. In particular, we never provide data structures or algorithms that\\nwork on generic types—this is in order to make the samples as easy to follow\\nas possible. However, to appreciate the designs of our data structures you will\\nneed to be familiar with the following object oriented (OO) concepts:\\n1. Inheritance\\n2. Encapsulation\\n3. Polymorphism\\nThis is especially important if you are planning on looking at the C# target\\nthat we have implemented (more on that in§1.7) which makes extensive use\\nof the OO concepts listed above. As a ﬁnal note it is also desirable that the\\nreader is familiar with interfaces as the C# target uses interfaces throughout\\nthe sorting algorithms.\\n1.3 Pseudocode\\nThroughout this book we use pseudocode to describe our solutions. For the\\nmost part interpreting the pseudocode is trivial as it looks very much like a\\nmore abstract C++, or C#, but there are a few things to point out:\\n1. Pre-conditions should always be enforced'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 14, 'page_label': '15'}, page_content='most part interpreting the pseudocode is trivial as it looks very much like a\\nmore abstract C++, or C#, but there are a few things to point out:\\n1. Pre-conditions should always be enforced\\n2. Post-conditions represent the result of applying algorithma to data struc-\\nture d'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 15, 'page_label': '16'}, page_content='CHAPTER 1. INTRODUCTION 5\\n3. The type of parameters is inferred\\n4. All primitive language constructs are explicitly begun and ended\\nIf an algorithm has a return type it will often be presented in the post-\\ncondition, but where the return type is suﬃciently obvious it may be omitted\\nfor the sake of brevity.\\nMost algorithms in this book require parameters, and because we assign no\\nexplicit type to those parameters the type is inferred from the contexts in which\\nit is used, and the operations performed upon it. Additionally, the name of\\nthe parameter usually acts as the biggest clue to its type. For instancen is a\\npseudo-name for a number and so you can assume unless otherwise stated that\\nn translates to an integer that has the same number of bits as a WORD on a\\n32 bit machine, similarlyl is a pseudo-name for a list where a list is a resizeable\\narray (e.g. a vector).\\nThe last major point of reference is that we always explicitly end a language'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 15, 'page_label': '16'}, page_content='32 bit machine, similarlyl is a pseudo-name for a list where a list is a resizeable\\narray (e.g. a vector).\\nThe last major point of reference is that we always explicitly end a language\\nconstruct. For instance if we wish to close the scope of afor loop we will\\nexplicitly state end forrather than leaving the interpretation of when scopes\\nare closed to the reader. While implicit scope closure works well in simple code,\\nin complex cases it can lead to ambiguity.\\nThe pseudocode style that we use within this book is rather straightforward.\\nAll algorithms start with a simple algorithm signature, e.g.\\n1) algorithm AlgorithmName(arg1, arg2, ...,argN )\\n2) ...\\nn) end AlgorithmName\\nImmediately after the algorithm signature we list anyPre or Post condi-\\ntions.\\n1) algorithm AlgorithmName(n)\\n2) Pre: n is the value to compute the factorial of\\n3) n ≥ 0\\n4) Post: the factorial ofn has been computed\\n5) // ...\\nn) end AlgorithmName\\nThe example above describes an algorithm by the name ofAlgorithmName,'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 15, 'page_label': '16'}, page_content='3) n ≥ 0\\n4) Post: the factorial ofn has been computed\\n5) // ...\\nn) end AlgorithmName\\nThe example above describes an algorithm by the name ofAlgorithmName,\\nwhich takes a single numeric parametern. The pre and post conditions follow\\nthe algorithm signature; you should always enforce the pre-conditions of an\\nalgorithm when porting them to your language of choice.\\nNormally what is listed as a pre-conidition is critical to the algorithms opera-\\ntion. This may cover things like the actual parameter not being null, or that the\\ncollection passed in must contain at leastn items. The post-condition mainly\\ndescribes the eﬀect of the algorithms operation. An example of a post-condition\\nmight be “The list has been sorted in ascending order”\\nBecause everything we describe is language independent you will need to\\nmake your own mind up on how to best handle pre-conditions. For example,\\nin the C# target we have implemented, we consider non-conformance to pre-'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 15, 'page_label': '16'}, page_content='make your own mind up on how to best handle pre-conditions. For example,\\nin the C# target we have implemented, we consider non-conformance to pre-\\nconditions to be exceptional cases. We provide a message in the exception to\\ntell the caller why the algorithm has failed to execute normally.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 16, 'page_label': '17'}, page_content='CHAPTER 1. INTRODUCTION 6\\n1.4 Tips for working through the examples\\nAs with most books you get out what you put in and so we recommend that in\\norder to get the most out of this book you work through each algorithm with a\\npen and paper to track things like variable names, recursive calls etc.\\nThe best way to work through algorithms is to set up a table, and in that\\ntable give each variable its own column and continuously update these columns.\\nThis will help you keep track of and visualise the mutations that are occurring\\nthroughout the algorithm. Often while working through algorithms in such\\na way you can intuitively map relationships between data structures rather\\nthan trying to work out a few values on paper and the rest in your head. We\\nsuggest you put everything on paper irrespective of how trivial some variables\\nand calculations may be so that you always have a point of reference.\\nWhen dealing with recursive algorithm traces we recommend you do the'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 16, 'page_label': '17'}, page_content='and calculations may be so that you always have a point of reference.\\nWhen dealing with recursive algorithm traces we recommend you do the\\nsame as the above, but also have a table that records function calls and who\\nthey return to. This approach is a far cleaner way than drawing out an elaborate\\nmap of function calls with arrows to one another, which gets large quickly and\\nsimply makes things more complex to follow. Track everything in a simple and\\nsystematic way to make your time studying the implementations far easier.\\n1.5 Book outline\\nWe have split this book into two parts:\\nPart 1: Provides discussion and pseudo-implementations of common and uncom-\\nmon data structures; and\\nPart 2: Provides algorithms of varying purposes from sorting to string operations.\\nThe reader doesn’t have to read the book sequentially from beginning to\\nend: chapters can be read independently from one another. We suggest that\\nin part 1 you read each chapter in its entirety, but in part 2 you can get away'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 16, 'page_label': '17'}, page_content='end: chapters can be read independently from one another. We suggest that\\nin part 1 you read each chapter in its entirety, but in part 2 you can get away\\nwith just reading the section of a chapter that describes the algorithm you are\\ninterested in.\\nEach of the chapters on data structures present initially the algorithms con-\\ncerned with:\\n1. Insertion\\n2. Deletion\\n3. Searching\\nThe previous list represents what we believe in the vast majority of cases to\\nbe the most important for each respective data structure.\\nFor all readers we recommend that before looking at any algorithm you\\nquickly look at Appendix E which contains a table listing the various symbols\\nused within our algorithms and their meaning. One keyword that we would like\\nto point out here isyield. You can think ofyield in the same light asreturn.\\nThe return keyword causes the method to exit and returns control to the caller,\\nwhereas yield returns each value to the caller. Withyield control only returns'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 16, 'page_label': '17'}, page_content='The return keyword causes the method to exit and returns control to the caller,\\nwhereas yield returns each value to the caller. Withyield control only returns\\nto the caller when all values to return to the caller have been exhausted.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 17, 'page_label': '18'}, page_content='CHAPTER 1. INTRODUCTION 7\\n1.6 Testing\\nAll the data structures and algorithms have been tested using a minimised test\\ndriven development style on paper to ﬂesh out the pseudocode algorithm. We\\nthen transcribe these tests into unit tests satisfying them one by one. When\\nall the test cases have been progressively satisﬁed we consider that algorithm\\nsuitably tested.\\nFor the most part algorithms have fairly obvious cases which need to be\\nsatisﬁed. Some however have many areas which can prove to be more complex\\nto satisfy. With such algorithms we will point out the test cases which are tricky\\nand the corresponding portions of pseudocode within the algorithm that satisfy\\nthat respective case.\\nAs you become more familiar with the actual problem you will be able to\\nintuitively identify areas which may cause problems for your algorithms imple-\\nmentation. This in some cases will yield an overwhelming list of concerns which\\nwill hinder your ability to design an algorithm greatly. When you are bom-'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 17, 'page_label': '18'}, page_content='mentation. This in some cases will yield an overwhelming list of concerns which\\nwill hinder your ability to design an algorithm greatly. When you are bom-\\nbarded with such a vast amount of concerns look at the overall problem again\\nand sub-divide the problem into smaller problems. Solving the smaller problems\\nand then composing them is a far easier task than clouding your mind with too\\nmany little details.\\nThe only type of testing that we use in the implementation of all that is\\nprovided in this book are unit tests. Because unit tests contribute such a core\\npiece of creating somewhat more stable software we invite the reader to view\\nAppendix D which describes testing in more depth.\\n1.7 Where can I get the code?\\nThis book doesn’t provide any code speciﬁcally aligned with it, however we do\\nactively maintain an open source project1 that houses a C# implementation of\\nall the pseudocode listed. The project is namedData Structures and Algorithms'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 17, 'page_label': '18'}, page_content='actively maintain an open source project1 that houses a C# implementation of\\nall the pseudocode listed. The project is namedData Structures and Algorithms\\n(DSA) and can be found athttp://codeplex.com/dsa.\\n1.8 Final messages\\nWe have just a few ﬁnal messages to the reader that we hope you digest before\\nyou embark on reading this book:\\n1. Understand how the algorithm works ﬁrst in an abstract sense; and\\n2. Always work through the algorithms on paper to understand how they\\nachieve their outcome\\nIf you always follow these key points, you will get the most out of this book.\\n1All readers are encouraged to provide suggestions, feature requests, and bugs so we can\\nfurther improve our implementations.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 18, 'page_label': '19'}, page_content='Part I\\nData Structures\\n8'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 19, 'page_label': '20'}, page_content='Chapter 2\\nLinked Lists\\nLinked lists can be thought of from a high level perspective as being a series\\nof nodes. Each node has at least a single pointer to the next node, and in the\\nlast node’s case a null pointer representing that there are no more nodes in the\\nlinked list.\\nIn DSA our implementations of linked lists always maintain head and tail\\npointers so that insertion at either the head or tail of the list is a constant\\ntime operation. Random insertion is excluded from this and will be a linear\\noperation. As such, linked lists in DSA have the following characteristics:\\n1. Insertion isO(1)\\n2. Deletion isO(n)\\n3. Searching isO(n)\\nOut of the three operations the one that stands out is that of insertion. In\\nDSA we chose to always maintain pointers (or more aptly references) to the\\nnode(s) at the head and tail of the linked list and so performing a traditional\\ninsertion to either the front or back of the linked list is anO(1) operation. An'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 19, 'page_label': '20'}, page_content='node(s) at the head and tail of the linked list and so performing a traditional\\ninsertion to either the front or back of the linked list is anO(1) operation. An\\nexception to this rule is performing an insertion before a node that is neither\\nthe head nor tail in a singly linked list. When the node we are inserting before\\nis somewhere in the middle of the linked list (known as random insertion) the\\ncomplexity is O(n). In order to add before the designated node we need to\\ntraverse the linked list to ﬁnd that node’s current predecessor. This traversal\\nyields anO(n) run time.\\nThis data structure is trivial, but linked lists have a few key points which at\\ntimes make them very attractive:\\n1. the list is dynamically resized, thus it incurs no copy penalty like an array\\nor vector would eventually incur; and\\n2. insertion isO(1).\\n2.1 Singly Linked List\\nSingly linked lists are one of the most primitive data structures you will ﬁnd in'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 19, 'page_label': '20'}, page_content='or vector would eventually incur; and\\n2. insertion isO(1).\\n2.1 Singly Linked List\\nSingly linked lists are one of the most primitive data structures you will ﬁnd in\\nthis book. Each node that makes up a singly linked list consists of a value, and\\na reference to the next node (if any) in the list.\\n9'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 20, 'page_label': '21'}, page_content='CHAPTER 2. LINKED LISTS 10\\nFigure 2.1: Singly linked list node\\nFigure 2.2: A singly linked list populated with integers\\n2.1.1 Insertion\\nIn general when people talk about insertion with respect to linked lists of any\\nform they implicitly refer to the adding of a node to the tail of the list. When\\nyou use an API like that of DSA and you see a general purpose method that\\nadds a node to the list, you can assume that you are adding the node to the tail\\nof the list not the head.\\nAdding a node to a singly linked list has only two cases:\\n1. head = ∅ in which case the node we are adding is now both thehead and\\ntail of the list; or\\n2. we simply need to append our node onto the end of the list updating the\\ntail reference appropriately.\\n1) algorithm Add(value)\\n2) Pre: value is the value to add to the list\\n3) Post: value has been placed at the tail of the list\\n4) n ← node(value)\\n5) if head = ∅\\n6) head ← n\\n7) tail ← n\\n8) else\\n9) tail.Next ← n\\n10) tail ← n\\n11) end if\\n12) end Add'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 20, 'page_label': '21'}, page_content='3) Post: value has been placed at the tail of the list\\n4) n ← node(value)\\n5) if head = ∅\\n6) head ← n\\n7) tail ← n\\n8) else\\n9) tail.Next ← n\\n10) tail ← n\\n11) end if\\n12) end Add\\nAs an example of the previous algorithm consider adding the following se-\\nquence of integers to the list: 1, 45, 60, and 12, the resulting list is that of\\nFigure 2.2.\\n2.1.2 Searching\\nSearching a linked list is straightforward: we simply traverse the list checking\\nthe value we are looking for with the value of each node in the linked list. The\\nalgorithm listed in this section is very similar to that used for traversal in§2.1.4.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 21, 'page_label': '22'}, page_content='CHAPTER 2. LINKED LISTS 11\\n1) algorithm Contains(head, value)\\n2) Pre: head is the head node in the list\\n3) value is the value to search for\\n4) Post: the item is either in the linked list, true; otherwise false\\n5) n ← head\\n6) while n ̸= ∅ and n.Value ̸= value\\n7) n ← n.Next\\n8) end while\\n9) if n = ∅\\n10) return false\\n11) end if\\n12) return true\\n13) end Contains\\n2.1.3 Deletion\\nDeleting a node from a linked list is straightforward but there are a few cases\\nwe need to account for:\\n1. the list is empty; or\\n2. the node to remove is the only node in the linked list; or\\n3. we are removing the head node; or\\n4. we are removing the tail node; or\\n5. the node to remove is somewhere in between the head and tail; or\\n6. the item to remove doesn’t exist in the linked list\\nThe algorithm whose cases we have described will remove a node from any-\\nwhere within a list irrespective of whether the node is thehead etc. If you know\\nthat items will only ever be removed from thehead or tail of the list then you'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 21, 'page_label': '22'}, page_content='where within a list irrespective of whether the node is thehead etc. If you know\\nthat items will only ever be removed from thehead or tail of the list then you\\ncan create much more concise algorithms. In the case of always removing from\\nthe front of the linked list deletion becomes anO(1) operation.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 22, 'page_label': '23'}, page_content='CHAPTER 2. LINKED LISTS 12\\n1) algorithm Remove(head, value)\\n2) Pre: head is the head node in the list\\n3) value is the value to remove from the list\\n4) Post: value is removed from the list, true; otherwise false\\n5) if head = ∅\\n6) // case 1\\n7) return false\\n8) end if\\n9) n ← head\\n10) if n.Value =value\\n11) if head = tail\\n12) // case 2\\n13) head ← ∅\\n14) tail ← ∅\\n15) else\\n16) // case 3\\n17) head ← head.Next\\n18) end if\\n19) return true\\n20) end if\\n21) while n.Next ̸= ∅ and n.Next.Value ̸= value\\n22) n ← n.Next\\n23) end while\\n24) if n.Next ̸= ∅\\n25) if n.Next =tail\\n26) // case 4\\n27) tail ← n\\n28) end if\\n29) // this is only case 5 if the conditional on line 25 wasfalse\\n30) n.Next ← n.Next.Next\\n31) return true\\n32) end if\\n33) // case 6\\n34) return false\\n35) end Remove\\n2.1.4 Traversing the list\\nTraversing a singly linked list is the same as that of traversing a doubly linked\\nlist (deﬁned in§2.2). You start at the head of the list and continue until you'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 22, 'page_label': '23'}, page_content='2.1.4 Traversing the list\\nTraversing a singly linked list is the same as that of traversing a doubly linked\\nlist (deﬁned in§2.2). You start at the head of the list and continue until you\\ncome across a node that is∅. The two cases are as follows:\\n1. node = ∅, we have exhausted all nodes in the linked list; or\\n2. we must update thenode reference to benode.Next.\\nThe algorithm described is a very simple one that makes use of a simple\\nwhile loop to check the ﬁrst case.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 23, 'page_label': '24'}, page_content='CHAPTER 2. LINKED LISTS 13\\n1) algorithm Traverse(head)\\n2) Pre: head is the head node in the list\\n3) Post: the items in the list have been traversed\\n4) n ← head\\n5) while n ̸= 0\\n6) yield n.Value\\n7) n ← n.Next\\n8) end while\\n9) end Traverse\\n2.1.5 Traversing the list in reverse order\\nTraversing a singly linked list in a forward manner (i.e. left to right) is simple\\nas demonstrated in§2.1.4. However, what if we wanted to traverse the nodes in\\nthe linked list in reverse order for some reason? The algorithm to perform such\\na traversal is very simple, and just like demonstrated in§2.1.3 we will need to\\nacquire a reference to the predecessor of a node, even though the fundamental\\ncharacteristics of the nodes that make up a singly linked list make this an\\nexpensive operation. For each node, ﬁnding its predecessor is anO(n) operation,\\nso over the course of traversing the whole list backwards the cost becomesO(n2).\\nFigure 2.3 depicts the following algorithm being applied to a linked list with'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 23, 'page_label': '24'}, page_content='so over the course of traversing the whole list backwards the cost becomesO(n2).\\nFigure 2.3 depicts the following algorithm being applied to a linked list with\\nthe integers 5, 10, 1, and 40.\\n1) algorithm ReverseTraversal(head, tail)\\n2) Pre: head and tail belong to the same list\\n3) Post: the items in the list have been traversed in reverse order\\n4) if tail ̸= ∅\\n5) curr ← tail\\n6) while curr ̸= head\\n7) prev ← head\\n8) while prev.Next ̸= curr\\n9) prev ← prev.Next\\n10) end while\\n11) yield curr.Value\\n12) curr ← prev\\n13) end while\\n14) yield curr.Value\\n15) end if\\n16) end ReverseTraversal\\nThis algorithm is only of real interest when we are using singly linked lists,\\nas you will soon see that doubly linked lists (deﬁned in§2.2) make reverse list\\ntraversal simple and eﬃcient, as shown in§2.2.3.\\n2.2 Doubly Linked List\\nDoubly linked lists are very similar to singly linked lists. The only diﬀerence is\\nthat each node has a reference to both the next and previous nodes in the list.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 24, 'page_label': '25'}, page_content='CHAPTER 2. LINKED LISTS 14\\nFigure 2.3: Reverse traveral of a singly linked list\\nFigure 2.4: Doubly linked list node'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 25, 'page_label': '26'}, page_content='CHAPTER 2. LINKED LISTS 15\\nThe following algorithms for the doubly linked list are exactly the same as\\nthose listed previously for the singly linked list:\\n1. Searching (deﬁned in§2.1.2)\\n2. Traversal (deﬁned in§2.1.4)\\n2.2.1 Insertion\\nThe only major diﬀerence between the algorithm in§2.1.1 is that we need to\\nremember to bind the previous pointer ofn to the previous tail node ifn was\\nnot the ﬁrst node to be inserted into the list.\\n1) algorithm Add(value)\\n2) Pre: value is the value to add to the list\\n3) Post: value has been placed at the tail of the list\\n4) n ← node(value)\\n5) if head = ∅\\n6) head ← n\\n7) tail ← n\\n8) else\\n9) n.Previous ← tail\\n10) tail.Next ← n\\n11) tail ← n\\n12) end if\\n13) end Add\\nFigure 2.5 shows the doubly linked list after adding the sequence of integers\\ndeﬁned in§2.1.1.\\nFigure 2.5: Doubly linked list populated with integers\\n2.2.2 Deletion\\nAs you may of guessed the cases that we use for deletion in a doubly linked'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 25, 'page_label': '26'}, page_content='deﬁned in§2.1.1.\\nFigure 2.5: Doubly linked list populated with integers\\n2.2.2 Deletion\\nAs you may of guessed the cases that we use for deletion in a doubly linked\\nlist are exactly the same as those deﬁned in§2.1.3. Like insertion we have the\\nadded task of binding an additional reference (P revious) to the correct value.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 26, 'page_label': '27'}, page_content='CHAPTER 2. LINKED LISTS 16\\n1) algorithm Remove(head, value)\\n2) Pre: head is the head node in the list\\n3) value is the value to remove from the list\\n4) Post: value is removed from the list, true; otherwise false\\n5) if head = ∅\\n6) return false\\n7) end if\\n8) if value = head.Value\\n9) if head = tail\\n10) head ← ∅\\n11) tail ← ∅\\n12) else\\n13) head ← head.Next\\n14) head.Previous ← ∅\\n15) end if\\n16) return true\\n17) end if\\n18) n ← head.Next\\n19) while n ̸= ∅ and value ̸= n.Value\\n20) n ← n.Next\\n21) end while\\n22) if n = tail\\n23) tail ← tail.Previous\\n24) tail.Next ← ∅\\n25) return true\\n26) else if n ̸= ∅\\n27) n.Previous.Next ← n.Next\\n28) n.Next.Previous ← n.Previous\\n29) return true\\n30) end if\\n31) return false\\n32) end Remove\\n2.2.3 Reverse Traversal\\nSingly linked lists have a forward only design, which is why the reverse traversal\\nalgorithm deﬁned in§2.1.5 required some creative invention. Doubly linked lists\\nmake reverse traversal as simple as forward traversal (deﬁned in§2.1.4) except'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 26, 'page_label': '27'}, page_content='algorithm deﬁned in§2.1.5 required some creative invention. Doubly linked lists\\nmake reverse traversal as simple as forward traversal (deﬁned in§2.1.4) except\\nthat we start at the tail node and update the pointers in the opposite direction.\\nFigure 2.6 shows the reverse traversal algorithm in action.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 27, 'page_label': '28'}, page_content='CHAPTER 2. LINKED LISTS 17\\nFigure 2.6: Doubly linked list reverse traversal\\n1) algorithm ReverseTraversal(tail)\\n2) Pre: tail is the tail node of the list to traverse\\n3) Post: the list has been traversed in reverse order\\n4) n ← tail\\n5) while n ̸= ∅\\n6) yield n.Value\\n7) n ← n.Previous\\n8) end while\\n9) end ReverseTraversal\\n2.3 Summary\\nLinked lists are good to use when you have an unknown number of items to\\nstore. Using a data structure like an array would require you to specify the size\\nup front; exceeding that size involves invoking a resizing algorithm which has\\na linear run time. You should also use linked lists when you will only remove\\nnodes at either the head or tail of the list to maintain a constant run time.\\nThis requires maintaining pointers to the nodes at the head and tail of the list\\nbut the memory overhead will pay for itself if this is an operation you will be\\nperforming many times.\\nWhat linked lists are not very good for is random insertion, accessing nodes'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 27, 'page_label': '28'}, page_content='but the memory overhead will pay for itself if this is an operation you will be\\nperforming many times.\\nWhat linked lists are not very good for is random insertion, accessing nodes\\nby index, and searching. At the expense of a little memory (in most cases 4\\nbytes would suﬃce), and a few more read/writes you could maintain acount\\nvariable that tracks how many items are contained in the list so that accessing\\nsuch a primitive property is a constant operation - you just need to update\\ncount during the insertion and deletion algorithms.\\nSingly linked lists should be used when you are only performing basic in-\\nsertions. In general doubly linked lists are more accommodating for non-trivial\\noperations on a linked list.\\nWe recommend the use of a doubly linked list when you require forwards\\nand backwards traversal. For the most cases this requirement is present. For\\nexample, consider a token stream that you want to parse in a recursive descent'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 27, 'page_label': '28'}, page_content='and backwards traversal. For the most cases this requirement is present. For\\nexample, consider a token stream that you want to parse in a recursive descent\\nfashion. Sometimes you will have to backtrack in order to create the correct\\nparse tree. In this scenario a doubly linked list is best as its design makes\\nbi-directional traversal much simpler and quicker than that of a singly linked'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 28, 'page_label': '29'}, page_content='CHAPTER 2. LINKED LISTS 18\\nlist.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 29, 'page_label': '30'}, page_content='Chapter 3\\nBinary Search Tree\\nBinary search trees (BSTs) are very simple to understand. We start with a root\\nnode with valuex, where the left subtree ofx contains nodes with values< x\\nand the right subtree contains nodes whose values are≥ x. Each node follows\\nthe same rules with respect to nodes in their left and right subtrees.\\nBSTs are of interest because they have operations which are favourably fast:\\ninsertion, look up, and deletion can all be done inO(log n) time. It is important\\nto note that theO(log n) times for these operations can only be attained if\\nthe BST is reasonably balanced; for a tree data structure with self balancing\\nproperties see AVL tree deﬁned in§7).\\nIn the following examples you can assume, unless used as a parameter alias\\nthat root is a reference to the root node of the tree.\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37 /K31/K37\\n/K39\\nFigure 3.1: Simple unbalanced binary search tree\\n19'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 30, 'page_label': '31'}, page_content='CHAPTER 3. BINARY SEARCH TREE 20\\n3.1 Insertion\\nAs mentioned previously insertion is anO(log n) operation provided that the\\ntree is moderately balanced.\\n1) algorithm Insert(value)\\n2) Pre: value has passed custom type checks for typeT\\n3) Post: value has been placed in the correct location in the tree\\n4) if root = ∅\\n5) root ← node(value)\\n6) else\\n7) InsertNode( root, value)\\n8) end if\\n9) end Insert\\n1) algorithm InsertNode(current, value)\\n2) Pre: current is the node to start from\\n3) Post: value has been placed in the correct location in the tree\\n4) if value < current.Value\\n5) if current.Left =∅\\n6) current.Left ← node(value)\\n7) else\\n8) InsertNode( current.Left, value)\\n9) end if\\n10) else\\n11) if current.Right =∅\\n12) current.Right ← node(value)\\n13) else\\n14) InsertNode( current.Right, value)\\n15) end if\\n16) end if\\n17) end InsertNode\\nThe insertion algorithm is split for a good reason. The ﬁrst algorithm (non-\\nrecursive) checks a very core base case - whether or not the tree is empty. If'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 30, 'page_label': '31'}, page_content='15) end if\\n16) end if\\n17) end InsertNode\\nThe insertion algorithm is split for a good reason. The ﬁrst algorithm (non-\\nrecursive) checks a very core base case - whether or not the tree is empty. If\\nthe tree is empty then we simply create our root node and ﬁnish. In all other\\ncases we invoke the recursiveInsertNode algorithm which simply guides us to\\nthe ﬁrst appropriate place in the tree to putvalue. Note that at each stage we\\nperform a binary chop: we either choose to recurse into the left subtree or the\\nright by comparing the new value with that of the current node. For any totally\\nordered type, no value can simultaneously satisfy the conditions to place it in\\nboth subtrees.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 31, 'page_label': '32'}, page_content='CHAPTER 3. BINARY SEARCH TREE 21\\n3.2 Searching\\nSearching a BST is even simpler than insertion. The pseudocode is self-explanatory\\nbut we will look brieﬂy at the premise of the algorithm nonetheless.\\nWe have talked previously about insertion, we go either left or right with the\\nright subtree containing values that are≥ x where x is the value of the node\\nwe are inserting. When searching the rules are made a little more atomic and\\nat any one time we have four cases to consider:\\n1. the root = ∅ in which casevalue is not in the BST; or\\n2. root.Value =value in which casevalue is in the BST; or\\n3. value < root.Value, we must inspect the left subtree ofroot for value; or\\n4. value > root.Value, we must inspect the right subtree ofroot for value.\\n1) algorithm Contains(root, value)\\n2) Pre: root is the root node of the tree,value is what we would like to locate\\n3) Post: value is either located or not\\n4) if root = ∅\\n5) return false\\n6) end if\\n7) if root.Value =value\\n8) return true'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 31, 'page_label': '32'}, page_content='2) Pre: root is the root node of the tree,value is what we would like to locate\\n3) Post: value is either located or not\\n4) if root = ∅\\n5) return false\\n6) end if\\n7) if root.Value =value\\n8) return true\\n9) else if value < root.Value\\n10) return Contains(root.Left, value)\\n11) else\\n12) return Contains(root.Right, value)\\n13) end if\\n14) end Contains'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 32, 'page_label': '33'}, page_content='CHAPTER 3. BINARY SEARCH TREE 22\\n3.3 Deletion\\nRemoving a node from a BST is fairly straightforward, with four cases to con-\\nsider:\\n1. the value to remove is a leaf node; or\\n2. the value to remove has a right subtree, but no left subtree; or\\n3. the value to remove has a left subtree, but no right subtree; or\\n4. the value to remove has both a left and right subtree in which case we\\npromote the largest value in the left subtree.\\nThere is also an implicit ﬁfth case whereby the node to be removed is the\\nonly node in the tree. This case is already covered by the ﬁrst, but should be\\nnoted as a possibility nonetheless.\\nOf course in a BST a value may occur more than once. In such a case the\\nﬁrst occurrence of that value in the BST will be removed.\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K23/K31/K3A/K20/K4C/K65/K61/K66/K20/K4E/K6F/K64/K65\\n/K23/K32/K3A/K20/K52/K69/K67/K68/K74/K20/K73/K75/K62/K74/K72/K65/K65\\n/K20/K20/K20/K20/K20/K20/K6E/K6F/K20/K6C/K65/K66/K74/K20/K73/K75/K62/K74/K72/K65/K65'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 32, 'page_label': '33'}, page_content='/K23/K32/K3A/K20/K52/K69/K67/K68/K74/K20/K73/K75/K62/K74/K72/K65/K65\\n/K20/K20/K20/K20/K20/K20/K6E/K6F/K20/K6C/K65/K66/K74/K20/K73/K75/K62/K74/K72/K65/K65\\n/K23/K33/K3A/K20/K4C/K65/K66/K74/K20/K73/K75/K62/K74/K72/K65/K65\\n/K20/K20/K20/K20/K20/K20/K6E/K6F/K20/K72/K69/K67/K68/K74/K20/K73/K75/K62/K74/K72/K65/K65\\n/K23/K34/K3A/K20/K52/K69/K67/K68/K74/K20/K73/K75/K62/K74/K72/K65/K65\\n/K20/K20/K20/K20/K20/K20/K61/K6E/K64/K20/K6C/K65/K66/K74/K20/K73/K75/K62/K74/K72/K65/K65\\nFigure 3.2: binary search tree deletion cases\\nThe Remove algorithm given below relies on two further helper algorithms\\nnamed FindP arent, and FindNode which are described in§3.4 and §3.5 re-\\nspectively.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 33, 'page_label': '34'}, page_content='CHAPTER 3. BINARY SEARCH TREE 23\\n1) algorithm Remove(value)\\n2) Pre: value is the value of the node to remove,root is the root node of the BST\\n3) Count is the number of items in the BST\\n3) Post: node withvalue is removed if found in which case yields true, otherwise false\\n4) nodeToRemove ← FindNode(value)\\n5) if nodeT oRemove= ∅\\n6) return false// value not in BST\\n7) end if\\n8) parent ← FindParent(value)\\n9) if Count = 1\\n10) root ← ∅// we are removing the only node in the BST\\n11) else if nodeToRemove .Left =∅ and nodeT oRemove.Right =null\\n12) // case #1\\n13) if nodeToRemove .Value < parent.Value\\n14) parent.Left ← ∅\\n15) else\\n16) parent.Right ← ∅\\n17) end if\\n18) else if nodeToRemove .Left =∅ and nodeT oRemove.Right ̸= ∅\\n19) // case # 2\\n20) if nodeToRemove .Value < parent.Value\\n21) parent.Left ← nodeToRemove .Right\\n22) else\\n23) parent.Right ← nodeToRemove .Right\\n24) end if\\n25) else if nodeToRemove .Left ̸= ∅ and nodeT oRemove.Right =∅\\n26) // case #3\\n27) if nodeToRemove .Value < parent.Value'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 33, 'page_label': '34'}, page_content='22) else\\n23) parent.Right ← nodeToRemove .Right\\n24) end if\\n25) else if nodeToRemove .Left ̸= ∅ and nodeT oRemove.Right =∅\\n26) // case #3\\n27) if nodeToRemove .Value < parent.Value\\n28) parent.Left ← nodeToRemove .Left\\n29) else\\n30) parent.Right ← nodeToRemove .Left\\n31) end if\\n32) else\\n33) // case #4\\n34) largestV alue← nodeT oRemove.Left\\n35) while largestV alue.Right ̸= ∅\\n36) // ﬁnd the largest value in the left subtree of nodeToRemove\\n37) largestV alue← largestV alue.Right\\n38) end while\\n39) // set the parents’ Right pointer of largestV alueto ∅\\n40) FindParent( largestV alue.Value).Right ← ∅\\n41) nodeT oRemove.Value ← largestV alue.Value\\n42) end if\\n43) Count ← Count −1\\n44) return true\\n45) end Remove'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 34, 'page_label': '35'}, page_content='CHAPTER 3. BINARY SEARCH TREE 24\\n3.4 Finding the parent of a given node\\nThe purpose of this algorithm is simple - to return a reference (or pointer) to\\nthe parent node of the one with the given value. We have found that such an\\nalgorithm is very useful, especially when performing extensive tree transforma-\\ntions.\\n1) algorithm FindParent(value, root)\\n2) Pre: value is the value of the node we want to ﬁnd the parent of\\n3) root is the root node of the BST and is ! =∅\\n4) Post: a reference to the parent node ofvalue if found; otherwise∅\\n5) if value = root.Value\\n6) return ∅\\n7) end if\\n8) if value < root.Value\\n9) if root.Left =∅\\n10) return ∅\\n11) else if root.Left.Value =value\\n12) return root\\n13) else\\n14) return FindParent(value, root.Left)\\n15) end if\\n16) else\\n17) if root.Right =∅\\n18) return ∅\\n19) else if root.Right.Value =value\\n20) return root\\n21) else\\n22) return FindParent(value, root.Right)\\n23) end if\\n24) end if\\n25) end FindParent'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 34, 'page_label': '35'}, page_content='15) end if\\n16) else\\n17) if root.Right =∅\\n18) return ∅\\n19) else if root.Right.Value =value\\n20) return root\\n21) else\\n22) return FindParent(value, root.Right)\\n23) end if\\n24) end if\\n25) end FindParent\\nA special case in the above algorithm is when the speciﬁed value does not\\nexist in the BST, in which case we return∅. Callers to this algorithm must take\\naccount of this possibility unless they are already certain that a node with the\\nspeciﬁed value exists.\\n3.5 Attaining a reference to a node\\nThis algorithm is very similar to§3.4, but instead of returning a reference to the\\nparent of the node with the speciﬁed value, it returns a reference to the node\\nitself. Again, ∅ is returned if the value isn’t found.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 35, 'page_label': '36'}, page_content='CHAPTER 3. BINARY SEARCH TREE 25\\n1) algorithm FindNode(root, value)\\n2) Pre: value is the value of the node we want to ﬁnd the parent of\\n3) root is the root node of the BST\\n4) Post: a reference to the node ofvalue if found; otherwise∅\\n5) if root = ∅\\n6) return ∅\\n7) end if\\n8) if root.Value =value\\n9) return root\\n10) else if value < root.Value\\n11) return FindNode(root.Left, value)\\n12) else\\n13) return FindNode(root.Right, value)\\n14) end if\\n15) end FindNode\\nAstute readers will have noticed that theFindNode algorithm is exactly the\\nsame as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\\nwe are returning a reference to a node nottrue or false. Given FindNode,\\nthe easiest way of implementingContains is to callFindNode and compare the\\nreturn value with∅.\\n3.6 Finding the smallest and largest values in\\nthe binary search tree\\nTo ﬁnd the smallest value in a BST you simply traverse the nodes in the left\\nsubtree of the BST always going left upon each encounter with a node, termi-'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 35, 'page_label': '36'}, page_content='the binary search tree\\nTo ﬁnd the smallest value in a BST you simply traverse the nodes in the left\\nsubtree of the BST always going left upon each encounter with a node, termi-\\nnating when you ﬁnd a node with no left subtree. The opposite is the case when\\nﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\\nare listed simply for completeness.\\nThe base case in bothF indMin, andFindMax algorithms is when the Left\\n(FindMin ), or Right (FindMax ) node references are∅ in which case we have\\nreached the last node.\\n1) algorithm FindMin(root)\\n2) Pre: root is the root node of the BST\\n3) root ̸= ∅\\n4) Post: the smallest value in the BST is located\\n5) if root.Left =∅\\n6) return root.Value\\n7) end if\\n8) FindMin( root.Left)\\n9) end FindMin'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 36, 'page_label': '37'}, page_content='CHAPTER 3. BINARY SEARCH TREE 26\\n1) algorithm FindMax(root)\\n2) Pre: root is the root node of the BST\\n3) root ̸= ∅\\n4) Post: the largest value in the BST is located\\n5) if root.Right =∅\\n6) return root.Value\\n7) end if\\n8) FindMax( root.Right)\\n9) end FindMax\\n3.7 Tree Traversals\\nThere are various strategies which can be employed to traverse the items in a\\ntree; the choice of strategy depends on which node visitation order you require.\\nIn this section we will touch on the traversals that DSA provides on all data\\nstructures that derive fromBinarySearchT ree.\\n3.7.1 Preorder\\nWhen using the preorder algorithm, you visit the root ﬁrst, then traverse the left\\nsubtree and ﬁnally traverse the right subtree. An example of preorder traversal\\nis shown in Figure 3.3.\\n1) algorithm Preorder(root)\\n2) Pre: root is the root node of the BST\\n3) Post: the nodes in the BST have been visited in preorder\\n4) if root ̸= ∅\\n5) yield root.Value\\n6) Preorder( root.Left)\\n7) Preorder( root.Right)\\n8) end if\\n9) end Preorder'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 36, 'page_label': '37'}, page_content='3) Post: the nodes in the BST have been visited in preorder\\n4) if root ̸= ∅\\n5) yield root.Value\\n6) Preorder( root.Left)\\n7) Preorder( root.Right)\\n8) end if\\n9) end Preorder\\n3.7.2 Postorder\\nThis algorithm is very similar to that described in§3.7.1, however the value\\nof the node is yielded after traversing both subtrees. An example of postorder\\ntraversal is shown in Figure 3.4.\\n1) algorithm Postorder(root)\\n2) Pre: root is the root node of the BST\\n3) Post: the nodes in the BST have been visited in postorder\\n4) if root ̸= ∅\\n5) Postorder( root.Left)\\n6) Postorder( root.Right)\\n7) yield root.Value\\n8) end if\\n9) end Postorder'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 37, 'page_label': '38'}, page_content='CHAPTER 3. BINARY SEARCH TREE 27\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37 /K31 /K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K28/K61/K29 /K28/K62/K29 /K28/K63/K29\\n/K28/K64/K29 /K28/K65/K29 /K28/K66/K29\\n/K31/K37\\n/K31/K37\\n/K31/K37 /K31/K37 /K31/K37\\nFigure 3.3: Preorder visit binary search tree example'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 38, 'page_label': '39'}, page_content='CHAPTER 3. BINARY SEARCH TREE 28\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37 /K31 /K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K28/K61/K29 /K28/K62/K29 /K28/K63/K29\\n/K28/K64/K29 /K28/K65/K29 /K28/K66/K29\\n/K31/K37\\n/K31/K37\\n/K31/K37 /K31/K37 /K31/K37\\nFigure 3.4: Postorder visit binary search tree example'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 39, 'page_label': '40'}, page_content='CHAPTER 3. BINARY SEARCH TREE 29\\n3.7.3 Inorder\\nAnother variation of the algorithms deﬁned in§3.7.1 and§3.7.2 is that of inorder\\ntraversal where the value of the current node is yielded in between traversing\\nthe left subtree and the right subtree. An example of inorder traversal is shown\\nin Figure 3.5.\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37 /K31 /K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K28/K61/K29 /K28/K62/K29 /K28/K63/K29\\n/K28/K64/K29 /K28/K65/K29 /K28/K66/K29\\n/K31/K37\\n/K31/K37\\n/K31/K37 /K31/K37 /K31/K37\\nFigure 3.5: Inorder visit binary search tree example\\n1) algorithm Inorder(root)\\n2) Pre: root is the root node of the BST\\n3) Post: the nodes in the BST have been visited in inorder\\n4) if root ̸= ∅\\n5) Inorder( root.Left)\\n6) yield root.Value\\n7) Inorder( root.Right)\\n8) end if\\n9) end Inorder'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 39, 'page_label': '40'}, page_content='3) Post: the nodes in the BST have been visited in inorder\\n4) if root ̸= ∅\\n5) Inorder( root.Left)\\n6) yield root.Value\\n7) Inorder( root.Right)\\n8) end if\\n9) end Inorder\\nOne of the beauties of inorder traversal is that values are yielded in their\\ncomparison order. In other words, when traversing a populated BST with the\\ninorder strategy, the yielded sequence would have propertyxi ≤ xi+1∀i.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 40, 'page_label': '41'}, page_content='CHAPTER 3. BINARY SEARCH TREE 30\\n3.7.4 Breadth First\\nTraversing a tree in breadth ﬁrst order yields the values of all nodes of a par-\\nticular depth in the tree before any deeper ones. In other words, given a depth\\nd we would visit the values of all nodes atd in a left to right fashion, then we\\nwould proceed tod + 1 and so on until we hade no more nodes to visit. An\\nexample of breadth ﬁrst traversal is shown in Figure 3.6.\\nTraditionally breadth ﬁrst traversal is implemented using a list (vector, re-\\nsizeable array, etc) to store the values of the nodes visited in breadth ﬁrst order\\nand then a queue to store those nodes that have yet to be visited.\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37 /K31 /K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K28/K61/K29 /K28/K62/K29 /K28/K63/K29\\n/K28/K64/K29 /K28/K65/K29 /K28/K66/K29\\n/K31/K37\\n/K31/K37'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 40, 'page_label': '41'}, page_content='/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K32/K33\\n/K31/K34 /K33/K31\\n/K37\\n/K39\\n/K28/K61/K29 /K28/K62/K29 /K28/K63/K29\\n/K28/K64/K29 /K28/K65/K29 /K28/K66/K29\\n/K31/K37\\n/K31/K37\\n/K31/K37 /K31/K37 /K31/K37\\nFigure 3.6: Breadth First visit binary search tree example'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 41, 'page_label': '42'}, page_content='CHAPTER 3. BINARY SEARCH TREE 31\\n1) algorithm BreadthFirst(root)\\n2) Pre: root is the root node of the BST\\n3) Post: the nodes in the BST have been visited in breadth ﬁrst order\\n4) q ← queue\\n5) while root ̸= ∅\\n6) yield root.Value\\n7) if root.Left ̸= ∅\\n8) q.Enqueue(root.Left)\\n9) end if\\n10) if root.Right ̸= ∅\\n11) q.Enqueue(root.Right)\\n12) end if\\n13) if !q.IsEmpty()\\n14) root ← q.Dequeue()\\n15) else\\n16) root ← ∅\\n17) end if\\n18) end while\\n19) end BreadthFirst\\n3.8 Summary\\nA binary search tree is a good solution when you need to represent types that are\\nordered according to some custom rules inherent to that type. With logarithmic\\ninsertion, lookup, and deletion it is very eﬀecient. Traversal remains linear, but\\nthere are many ways in which you can visit the nodes of a tree. Trees are\\nrecursive data structures, so typically you will ﬁnd that many algorithms that\\noperate on a tree are recursive.\\nThe run times presented in this chapter are based on a pretty big assumption'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 41, 'page_label': '42'}, page_content='recursive data structures, so typically you will ﬁnd that many algorithms that\\noperate on a tree are recursive.\\nThe run times presented in this chapter are based on a pretty big assumption\\n- that the binary search tree’s left and right subtrees are reasonably balanced.\\nWe can only attain logarithmic run times for the algorithms presented earlier\\nwhen this is true. A binary search tree does not enforce such a property, and\\nthe run times for these operations on a pathologically unbalanced tree become\\nlinear: such a tree is eﬀectively just a linked list. Later in§7 we will examine\\nan AVL tree that enforces self-balancing properties to help attain logarithmic\\nrun times.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 42, 'page_label': '43'}, page_content='Chapter 4\\nHeap\\nA heap can be thought of as a simple tree data structure, however a heap usually\\nemploys one of two strategies:\\n1. min heap; or\\n2. max heap\\nEach strategy determines the properties of the tree and its values. If you\\nwere to choose the min heap strategy then each parent node would have a value\\nthat is ≤ than its children. For example, the node at the root of the tree will\\nhave the smallest value in the tree. The opposite is true for the max heap\\nstrategy. In this book you should assume that a heap employs the min heap\\nstrategy unless otherwise stated.\\nUnlike other tree data structures like the one deﬁned in§3 a heap is generally\\nimplemented as an array rather than a series of nodes which each have refer-\\nences to other nodes. The nodes are conceptually the same, however, having at\\nmost two children. Figure 4.1 shows how the tree (not a heap data structure)\\n(12 7(3 2) 6(9 )) would be represented as an array. The array in Figure 4.1 is a'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 42, 'page_label': '43'}, page_content='most two children. Figure 4.1 shows how the tree (not a heap data structure)\\n(12 7(3 2) 6(9 )) would be represented as an array. The array in Figure 4.1 is a\\nresult of simply adding values in a top-to-bottom, left-to-right fashion. Figure\\n4.2 shows arrows to the direct left and right child of each value in the array.\\nThis chapter is very much centred around the notion of representing a tree as\\nan array and because this property is key to understanding this chapter Figure\\n4.3 shows a step by step process to represent a tree data structure as an array.\\nIn Figure 4.3 you can assume that the default capacity of our array is eight.\\nUsing just an array is often not suﬃcient as we have to be up front about the\\nsize of the array to use for the heap. Often the run time behaviour of a program\\ncan be unpredictable when it comes to the size of its internal data structures,\\nso we need to choose a more dynamic data structure that contains the following\\nproperties:'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 42, 'page_label': '43'}, page_content='can be unpredictable when it comes to the size of its internal data structures,\\nso we need to choose a more dynamic data structure that contains the following\\nproperties:\\n1. we can specify an initial size of the array for scenarios where we know the\\nupper storage limit required; and\\n2. the data structure encapsulates resizing algorithms to grow the array as\\nrequired at run time\\n32'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 43, 'page_label': '44'}, page_content='CHAPTER 4. HEAP 33\\nFigure 4.1: Array representation of a simple tree data structure\\nFigure 4.2: Direct children of the nodes in an array representation of a tree data\\nstructure\\n1. Vector\\n2. ArrayList\\n3. List\\nFigure 4.1 does not specify how we would handle adding null references to\\nthe heap. This varies from case to case; sometimes null values are prohibited\\nentirely; in other cases we may treat them as being smaller than any non-null\\nvalue, or indeed greater than any non-null value. You will have to resolve this\\nambiguity yourself having studied your requirements. For the sake of clarity we\\nwill avoid the issue by prohibiting null values.\\nBecause we are using an array we need some way to calculate the index of a\\nparent node, and the children of a node. The required expressions for this are\\ndeﬁned as follows for a node atindex:\\n1. (index − 1)/2 (parent index)\\n2. 2 ∗ index + 1 (left child)\\n3. 2 ∗ index + 2 (right child)'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 43, 'page_label': '44'}, page_content='deﬁned as follows for a node atindex:\\n1. (index − 1)/2 (parent index)\\n2. 2 ∗ index + 1 (left child)\\n3. 2 ∗ index + 2 (right child)\\nIn Figure 4.4 a) represents the calculation of the right child of 12 (2∗0 + 2);\\nand b) calculates the index of the parent of 3 ((3− 1)/2).\\n4.1 Insertion\\nDesigning an algorithm for heap insertion is simple, but we must ensure that\\nheap order is preserved after each insertion. Generally this is a post-insertion\\noperation. Inserting a value into the next free slot in an array is simple: we just\\nneed to keep track of the next free index in the array as a counter, and increment\\nit after each insertion. Inserting our value into the heap is the ﬁrst part of the\\nalgorithm; the second is validating heap order. In the case of min-heap ordering\\nthis requires us to swap the values of a parent and its child if the value of the\\nchild is< the value of its parent. We must do this for each subtree containing\\nthe value we just inserted.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 44, 'page_label': '45'}, page_content='CHAPTER 4. HEAP 34\\nFigure 4.3: Converting a tree data structure to its array counterpart'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 45, 'page_label': '46'}, page_content='CHAPTER 4. HEAP 35\\nFigure 4.4: Calculating node properties\\nThe run time eﬃciency for heap insertion isO(log n). The run time is a\\nby product of verifying heap order as the ﬁrst part of the algorithm (the actual\\ninsertion into the array) isO(1).\\nFigure 4.5 shows the steps of inserting the values 3, 9, 12, 7, and 1 into a\\nmin-heap.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 46, 'page_label': '47'}, page_content='CHAPTER 4. HEAP 36\\nFigure 4.5: Inserting values into a min-heap'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 47, 'page_label': '48'}, page_content='CHAPTER 4. HEAP 37\\n1) algorithm Add(value)\\n2) Pre: value is the value to add to the heap\\n3) Count is the number of items in the heap\\n4) Post: the value has been added to the heap\\n5) heap[Count] ← value\\n6) Count ← Count +1\\n7) MinHeapify()\\n8) end Add\\n1) algorithm MinHeapify()\\n2) Pre: Count is the number of items in the heap\\n3) heap is the array used to store the heap items\\n4) Post: the heap has preserved min heap ordering\\n5) i ← Count −1\\n6) while i >0 and heap[i] < heap[(i − 1)/2]\\n7) Swap( heap[i], heap[(i − 1)/2]\\n8) i ← (i − 1)/2\\n9) end while\\n10) end MinHeapify\\nThe design of theMaxHeapify algorithm is very similar to that of theMin-\\nHeapify algorithm, the only diﬀerence is that the< operator in the second\\ncondition of entering the while loop is changed to>.\\n4.2 Deletion\\nJust as for insertion, deleting an item involves ensuring that heap ordering is\\npreserved. The algorithm for deletion has three steps:\\n1. ﬁnd the index of the value to delete'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 47, 'page_label': '48'}, page_content='4.2 Deletion\\nJust as for insertion, deleting an item involves ensuring that heap ordering is\\npreserved. The algorithm for deletion has three steps:\\n1. ﬁnd the index of the value to delete\\n2. put the last value in the heap at the index location of the item to delete\\n3. verify heap ordering for each subtree which used to include the value'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 48, 'page_label': '49'}, page_content='CHAPTER 4. HEAP 38\\n1) algorithm Remove(value)\\n2) Pre: value is the value to remove from the heap\\n3) left, andright are updated alias’ for 2∗ index + 1, and 2∗ index + 2 respectively\\n4) Count is the number of items in the heap\\n5) heap is the array used to store the heap items\\n6) Post: value is located in the heap and removed, true; otherwise false\\n7) // step 1\\n8) index ← FindIndex(heap, value)\\n9) if index <0\\n10) return false\\n11) end if\\n12) Count ← Count −1\\n13) // step 2\\n14) heap[index] ← heap[Count]\\n15) // step 3\\n16) while left < Count and heap[index] > heap[left] or heap[index] > heap[right]\\n17) // promote smallest key from subtree\\n18) if heap[left] < heap[right]\\n19) Swap( heap, left, index)\\n20) index ← left\\n21) else\\n22) Swap( heap, right, index)\\n23) index ← right\\n24) end if\\n25) end while\\n26) return true\\n27) end Remove\\nFigure 4.6 shows theRemove algorithm visually, removing 1 from a heap\\ncontaining the values 1, 3, 9, 12, and 13. In Figure 4.6 you can assume that we'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 48, 'page_label': '49'}, page_content='25) end while\\n26) return true\\n27) end Remove\\nFigure 4.6 shows theRemove algorithm visually, removing 1 from a heap\\ncontaining the values 1, 3, 9, 12, and 13. In Figure 4.6 you can assume that we\\nhave speciﬁed that the backing array of the heap should have an initial capacity\\nof eight.\\nPlease note that in our deletion algorithm that we don’t default the removed\\nvalue in theheap array. If you are using a heap for reference types, i.e. objects\\nthat are allocated on a heap you will want to free that memory. This is important\\nin both unmanaged, and managed languages. In the latter we will want to null\\nthat empty hole so that the garbage collector can reclaim that memory. If we\\nwere to not null that hole then the object could still be reached and thus won’t\\nbe garbage collected.\\n4.3 Searching\\nSearching a heap is merely a matter of traversing the items in the heap array\\nsequentially, so this operation has a run time complexity ofO(n). The search'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 48, 'page_label': '49'}, page_content='be garbage collected.\\n4.3 Searching\\nSearching a heap is merely a matter of traversing the items in the heap array\\nsequentially, so this operation has a run time complexity ofO(n). The search\\ncan be thought of as one that uses a breadth ﬁrst traversal as deﬁned in§3.7.4\\nto visit the nodes within the heap to check for the presence of a speciﬁed item.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 49, 'page_label': '50'}, page_content='CHAPTER 4. HEAP 39\\nFigure 4.6: Deleting an item from a heap'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 50, 'page_label': '51'}, page_content='CHAPTER 4. HEAP 40\\n1) algorithm Contains(value)\\n2) Pre: value is the value to search the heap for\\n3) Count is the number of items in the heap\\n4) heap is the array used to store the heap items\\n5) Post: value is located in the heap, in which case true; otherwise false\\n6) i ← 0\\n7) while i <Count and heap[i] ̸= value\\n8) i ← i + 1\\n9) end while\\n10) if i <Count\\n11) return true\\n12) else\\n13) return false\\n14) end if\\n15) end Contains\\nThe problem with the previous algorithm is that we don’t take advantage\\nof the properties in which all values of a heap hold, that is the property of the\\nheap strategy being used. For instance if we had a heap that didn’t contain the\\nvalue 4 we would have to exhaust the whole backing heap array before we could\\ndetermine that it wasn’t present in the heap. Factoring in what we know about\\nthe heap we can optimise the search algorithm by including logic which makes\\nuse of the properties presented by a certain heap strategy.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 50, 'page_label': '51'}, page_content='the heap we can optimise the search algorithm by including logic which makes\\nuse of the properties presented by a certain heap strategy.\\nOptimising to deterministically state that a value is in the heap is not that\\nstraightforward, however the problem is a very interesting one. As an example\\nconsider a min-heap that doesn’t contain the value 5. We can only rule that the\\nvalue is not in the heap if 5> the parent of the current node being inspected\\nand < the current node being inspected∀ nodes at the current level we are\\ntraversing. If this is the case then 5 cannot be in the heap and so we can\\nprovide an answer without traversing the rest of the heap. If this property is\\nnot satisﬁed for any level of nodes that we are inspecting then the algorithm\\nwill indeed fall back to inspecting all the nodes in the heap. The optimisation\\nthat we present can be very common and so we feel that the extra logic within\\nthe loop is justiﬁed to prevent the expensive worse case run time.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 50, 'page_label': '51'}, page_content='that we present can be very common and so we feel that the extra logic within\\nthe loop is justiﬁed to prevent the expensive worse case run time.\\nThe following algorithm is speciﬁcally designed for a min-heap. To tailor the\\nalgorithm for a max-heap the two comparison operations in theelse ifcondition\\nwithin the innerwhile loop should be ﬂipped.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 51, 'page_label': '52'}, page_content='CHAPTER 4. HEAP 41\\n1) algorithm Contains(value)\\n2) Pre: value is the value to search the heap for\\n3) Count is the number of items in the heap\\n4) heap is the array used to store the heap items\\n5) Post: value is located in the heap, in which case true; otherwise false\\n6) start ← 0\\n7) nodes ← 1\\n8) while start <Count\\n9) start ← nodes − 1\\n10) end ← nodes + start\\n11) count ← 0\\n12) while start <Count and start < end\\n13) if value = heap[start]\\n14) return true\\n15) else if value >Parent(heap[start]) and value < heap[start]\\n16) count ← count + 1\\n17) end if\\n18) start ← start + 1\\n19) end while\\n20) if count = nodes\\n21) return false\\n22) end if\\n23) nodes ← nodes ∗ 2\\n24) end while\\n25) return false\\n26) end Contains\\nThe new Contains algorithm determines if thevalue is not in the heap by\\nchecking whethercount = nodes. In such an event where this is true then we\\ncan conﬁrm that∀ nodes n at leveli : value >Parent(n), value < nthus there'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 51, 'page_label': '52'}, page_content='checking whethercount = nodes. In such an event where this is true then we\\ncan conﬁrm that∀ nodes n at leveli : value >Parent(n), value < nthus there\\nis no possible way thatvalue is in the heap. As an example consider Figure 4.7.\\nIf we are searching for the value 10 within the min-heap displayed it is obvious\\nthat we don’t need to search the whole heap to determine 9 is not present. We\\ncan verify this after traversing the nodes in the second level of the heap as the\\nprevious expression deﬁned holds true.\\n4.4 Traversal\\nAs mentioned in§4.3 traversal of a heap is usually done like that of any other\\narray data structure which our heap implementation is based upon. As a result\\nyou traverse the array starting at the initial array index (0 in most languages)\\nand then visit each value within the array until you have reached the upper\\nbound of the heap. You will note that in the search algorithm that we useCount\\nas this upper bound rather than the actual physical bound of the allocated'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 51, 'page_label': '52'}, page_content='bound of the heap. You will note that in the search algorithm that we useCount\\nas this upper bound rather than the actual physical bound of the allocated\\narray. Count is used to partition the conceptual heap from the actual array\\nimplementation of the heap: we only care about the items in the heap, not the\\nwhole array—the latter may contain various other bits of data as a result of\\nheap mutation.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 52, 'page_label': '53'}, page_content='CHAPTER 4. HEAP 42\\nFigure 4.7: Determining 10 is not in the heap after inspecting the nodes of Level\\n2\\nFigure 4.8: Living and dead space in the heap backing array\\nIf you have followed the advice we gave in the deletion algorithm then a\\nheap that has been mutated several times will contain some form of default\\nvalue for items no longer in the heap. Potentially you will have at most\\nLengthOf (heapArray) − Count garbage values in the backing heap array data\\nstructure. The garbage values of course vary from platform to platform. To\\nmake things simple the garbage value of a reference type will be simple∅ and 0\\nfor a value type.\\nFigure 4.8 shows a heap that you can assume has been mutated many times.\\nFor this example we can further assume that at some point the items in indexes\\n3 − 5 actually contained references to live objects of typeT. In Figure 4.8\\nsubscript is used to disambiguate separate objects ofT.\\nFrom what you have read thus far you will most likely have picked up that'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 52, 'page_label': '53'}, page_content='subscript is used to disambiguate separate objects ofT.\\nFrom what you have read thus far you will most likely have picked up that\\ntraversing the heap in any other order would be of little beneﬁt. The heap\\nproperty only holds for the subtree of each node and so traversing a heap in\\nany other fashion requires some creative intervention. Heaps are not usually\\ntraversed in any other way than the one prescribed previously.\\n4.5 Summary\\nHeaps are most commonly used to implement priority queues (see§6.2 for a\\nsample implementation) and to facilitate heap sort. As discussed in both the\\ninsertion §4.1 and deletion§4.2 sections a heap maintains heap order according\\nto the selected ordering strategy. These strategies are referred to as min-heap,'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 53, 'page_label': '54'}, page_content='CHAPTER 4. HEAP 43\\nand max heap. The former strategy enforces that the value of a parent node is\\nless than that of each of its children, the latter enforces that the value of the\\nparent is greater than that of each of its children.\\nWhen you come across a heap and you are not told what strategy it enforces\\nyou should assume that it uses the min-heap strategy. If the heap can be\\nconﬁgured otherwise, e.g. to use max-heap then this will often require you to\\nstate this explicitly. The heap abides progressively to a strategy during the\\ninvocation of the insertion, and deletion algorithms. The cost of such a policy is\\nthat upon each insertion and deletion we invoke algorithms that have logarithmic\\nrun time complexities. While the cost of maintaining the strategy might not\\nseem overly expensive it does still come at a price. We will also have to factor\\nin the cost of dynamic array expansion at some stage. This will occur if the'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 53, 'page_label': '54'}, page_content='seem overly expensive it does still come at a price. We will also have to factor\\nin the cost of dynamic array expansion at some stage. This will occur if the\\nnumber of items within the heap outgrows the space allocated in the heap’s\\nbacking array. It may be in your best interest to research a good initial starting\\nsize for your heap array. This will assist in minimising the impact of dynamic\\narray resizing.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 54, 'page_label': '55'}, page_content='Chapter 5\\nSets\\nA set contains a number of values, in no particular order. The values within\\nthe set are distinct from one another.\\nGenerally set implementations tend to check that a value is not in the set\\nbefore adding it, avoiding the issue of repeated values from ever occurring.\\nThis section does not cover set theory in depth; rather it demonstrates brieﬂy\\nthe ways in which the values of sets can be deﬁned, and common operations that\\nmay be performed upon them.\\nThe notationA = {4, 7, 9, 12, 0} deﬁnes a setA whose values are listed within\\nthe curly braces.\\nGiven the set A deﬁned previously we can say that 4 is a member ofA\\ndenoted by 4∈ A, and that 99 is not a member ofA denoted by 99/∈ A.\\nOften deﬁning a set by manually stating its members is tiresome, and more\\nimportantly the set may contain a large number of values. A more concise way\\nof deﬁning a set and its members is by providing a series of properties that the'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 54, 'page_label': '55'}, page_content='importantly the set may contain a large number of values. A more concise way\\nof deﬁning a set and its members is by providing a series of properties that the\\nvalues of the set must satisfy. For example, from the deﬁnitionA = {x|x >\\n0, x% 2 = 0} the set A contains only positive integers that are even.x is an\\nalias to the current value we are inspecting and to the right hand side of| are\\nthe properties thatx must satisfy to be in the setA. In this example,x must\\nbe > 0, and the remainder of the arithmetic expressionx/2 must be 0. You will\\nbe able to note from the previous deﬁnition of the setA that the set can contain\\nan inﬁnite number of values, and that the values of the setA will be all even\\nintegers that are a member of the natural numbers setN, whereN= {1, 2, 3, ...}.\\nFinally in this brief introduction to sets we will cover set intersection and\\nunion, both of which are very common operations (amongst many others) per-'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 54, 'page_label': '55'}, page_content='Finally in this brief introduction to sets we will cover set intersection and\\nunion, both of which are very common operations (amongst many others) per-\\nformed on sets. The union set can be deﬁned as followsA ∪ B = {x | x ∈\\nA or x∈ B}, and intersectionA ∩ B = {x | x ∈ A and x∈ B}. Figure 5.1\\ndemonstrates set intersection and union graphically.\\nGiven the set deﬁnitionsA = {1, 2, 3}, andB = {6, 2, 9} the union of the two\\nsets isA∪B = {1, 2, 3, 6, 9}, and the intersection of the two sets isA∩B = {2}.\\nBoth set union and intersection are sometimes provided within the frame-\\nwork associated with mainstream languages. This is the case in .NET 3.51\\nwhere such algorithms exist as extension methods deﬁned in the typeSys-\\ntem.Linq.Enumerable2, as a result DSA does not provide implementations of\\n1http://www.microsoft.com/NET/\\n2http://msdn.microsoft.com/en-us/library/system.linq.enumerable_members.aspx\\n44'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 55, 'page_label': '56'}, page_content='CHAPTER 5. SETS 45\\nFigure 5.1: a)A ∩ B; b)A ∪ B\\nthese algorithms. Most of the algorithms deﬁned inSystem.Linq.Enumerable\\ndeal mainly with sequences rather than sets exclusively.\\nSet union can be implemented as a simple traversal of both sets adding each\\nitem of the two sets to a new union set.\\n1) algorithm Union(set1, set2)\\n2) Pre: set1, andset2 ̸= ∅\\n3) union is a set\\n3) Post: A union ofset1, andset2 has been created\\n4) foreach item in set1\\n5) union.Add(item)\\n6) end foreach\\n7) foreach item in set2\\n8) union.Add(item)\\n9) end foreach\\n10) return union\\n11) end Union\\nThe run time of ourUnion algorithm is O(m + n) where m is the number\\nof items in the ﬁrst set andn is the number of items in the second set. This\\nruntime applies only to sets that exhibitO(1) insertions.\\nSet intersection is also trivial to implement. The only major thing worth\\npointing out about our algorithm is that we traverse the set containing the\\nfewest items. We can do this because if we have exhausted all the items in the'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 55, 'page_label': '56'}, page_content='pointing out about our algorithm is that we traverse the set containing the\\nfewest items. We can do this because if we have exhausted all the items in the\\nsmaller of the two sets then there are no more items that are members of both\\nsets, thus we have no more items to add to the intersection set.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 56, 'page_label': '57'}, page_content='CHAPTER 5. SETS 46\\n1) algorithm Intersection(set1, set2)\\n2) Pre: set1, andset2 ̸= ∅\\n3) intersection, andsmallerSet are sets\\n3) Post: An intersection ofset1, andset2 has been created\\n4) if set1.Count < set2.Count\\n5) smallerSet ← set1\\n6) else\\n7) smallerSet ← set2\\n8) end if\\n9) foreach item in smallerSet\\n10) if set1.Contains(item) and set2.Contains(item)\\n11) intersection.Add(item)\\n12) end if\\n13) end foreach\\n14) return intersection\\n15) end Intersection\\nThe run time of ourIntersection algorithm is O(n) where n is the number\\nof items in the smaller of the two sets. Just like ourUnion algorithm a linear\\nruntime can only be attained when operating on a set withO(1) insertion.\\n5.1 Unordered\\nSets in the general sense do not enforce the explicit ordering of their mem-\\nbers. For example the members ofB = {6, 2, 9} conform to no ordering scheme\\nbecause it is not required.\\nMost libraries provide implementations of unordered sets and so DSA does'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 56, 'page_label': '57'}, page_content='bers. For example the members ofB = {6, 2, 9} conform to no ordering scheme\\nbecause it is not required.\\nMost libraries provide implementations of unordered sets and so DSA does\\nnot; we simply mention it here to disambiguate between an unordered set and\\nordered set.\\nWe will only look at insertion for an unordered set and cover brieﬂy why a\\nhash table is an eﬃcient data structure to use for its implementation.\\n5.1.1 Insertion\\nAn unordered set can be eﬃciently implemented using a hash table as its backing\\ndata structure. As mentioned previously we only add an item to a set if that\\nitem is not already in the set, so the backing data structure we use must have\\na quick look up and insertion run time complexity.\\nA hash map generally provides the following:\\n1. O(1) for insertion\\n2. approaching O(1) for look up\\nThe above depends on how good the hashing algorithm of the hash table\\nis, but most hash tables employ incredibly eﬃcient general purpose hashing'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 56, 'page_label': '57'}, page_content='1. O(1) for insertion\\n2. approaching O(1) for look up\\nThe above depends on how good the hashing algorithm of the hash table\\nis, but most hash tables employ incredibly eﬃcient general purpose hashing\\nalgorithms and so the run time complexities for the hash table in your library\\nof choice should be very similar in terms of eﬃciency.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 57, 'page_label': '58'}, page_content='CHAPTER 5. SETS 47\\n5.2 Ordered\\nAn ordered set is similar to an unordered set in the sense that its members are\\ndistinct, but an ordered set enforces some predeﬁned comparison on each of its\\nmembers to produce a set whose members are ordered appropriately.\\nIn DSA 0.5 and earlier we used a binary search tree (deﬁned in§3) as the\\ninternal backing data structure for our ordered set. From versions 0.6 onwards\\nwe replaced the binary search tree with an AVL tree primarily because AVL is\\nbalanced.\\nThe ordered set has its order realised by performing an inorder traversal\\nupon its backing tree data structure which yields the correct ordered sequence\\nof set members.\\nBecause an ordered set in DSA is simply a wrapper for an AVL tree that\\nadditionally ensures that the tree contains unique items you should read§7 to\\nlearn more about the run time complexities associated with its operations.\\n5.3 Summary\\nSets provide a way of having a collection of unique objects, either ordered or\\nunordered.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 57, 'page_label': '58'}, page_content='learn more about the run time complexities associated with its operations.\\n5.3 Summary\\nSets provide a way of having a collection of unique objects, either ordered or\\nunordered.\\nWhen implementing a set (either ordered or unordered) it is key to select\\nthe correct backing data structure. As we discussed in§5.1.1 because we check\\nﬁrst if the item is already contained within the set before adding it we need\\nthis check to be as quick as possible. For unordered sets we can rely on the use\\nof a hash table and use the key of an item to determine whether or not it is\\nalready contained within the set. Using a hash table this check results in a near\\nconstant run time complexity. Ordered sets cost a little more for this check,\\nhowever the logarithmic growth that we incur by using a binary search tree as\\nits backing data structure is acceptable.\\nAnother key property of sets implemented using the approach we describe is\\nthat both have favourably fast look-up times. Just like the check before inser-'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 57, 'page_label': '58'}, page_content='its backing data structure is acceptable.\\nAnother key property of sets implemented using the approach we describe is\\nthat both have favourably fast look-up times. Just like the check before inser-\\ntion, for a hash table this run time complexity should be near constant. Ordered\\nsets as described in 3 perform a binary chop at each stage when searching for\\nthe existence of an item yielding a logarithmic run time.\\nWe can use sets to facilitate many algorithms that would otherwise be a little\\nless clear in their implementation. For example in§11.4 we use an unordered\\nset to assist in the construction of an algorithm that determines the number of\\nrepeated words within a string.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 58, 'page_label': '59'}, page_content='Chapter 6\\nQueues\\nQueues are an essential data structure that are found in vast amounts of soft-\\nware from user mode to kernel mode applications that are core to the system.\\nFundamentally they honour a ﬁrst in ﬁrst out (FIFO) strategy, that is the item\\nﬁrst put into the queue will be the ﬁrst served, the second item added to the\\nqueue will be the second to be served and so on.\\nA traditional queue only allows you to access the item at the front of the\\nqueue; when you add an item to the queue that item is placed at the back of\\nthe queue.\\nHistorically queues always have the following three core methods:\\nEnqueue: places an item at the back of the queue;\\nDequeue: retrieves the item at the front of the queue, and removes it from the\\nqueue;\\nPeek: 1 retrieves the item at the front of the queue without removing it from\\nthe queue\\nAs an example to demonstrate the behaviour of a queue we will walk through\\na scenario whereby we invoke each of the previously mentioned methods observ-'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 58, 'page_label': '59'}, page_content='the queue\\nAs an example to demonstrate the behaviour of a queue we will walk through\\na scenario whereby we invoke each of the previously mentioned methods observ-\\ning the mutations upon the queue data structure. The following list describes\\nthe operations performed upon the queue in Figure 6.1:\\n1. Enqueue(10)\\n2. Enqueue(12)\\n3. Enqueue(9)\\n4. Enqueue(8)\\n5. Enqueue(3)\\n6. Dequeue()\\n7. Peek()\\n1This operation is sometimes referred to as Front\\n48'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 59, 'page_label': '60'}, page_content='CHAPTER 6. QUEUES 49\\n8. Enqueue(33)\\n9. Peek()\\n10. Dequeue()\\n6.1 A standard queue\\nA queue is implicitly like that described prior to this section. In DSA we don’t\\nprovide a standard queue because queues are so popular and such a core data\\nstructure that you will ﬁnd pretty much every mainstream library provides a\\nqueue data structure that you can use with your language of choice. In this\\nsection we will discuss how you can, if required, implement an eﬃcient queue\\ndata structure.\\nThe main property of a queue is that we have access to the item at the\\nfront of the queue. The queue data structure can be eﬃciently implemented\\nusing a singly linked list (deﬁned in§2.1). A singly linked list providesO(1)\\ninsertion and deletion run time complexities. The reason we have anO(1) run\\ntime complexity for deletion is because we only ever remove items from the front\\nof queues (with the Dequeue operation). Since we always have a pointer to the'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 59, 'page_label': '60'}, page_content='time complexity for deletion is because we only ever remove items from the front\\nof queues (with the Dequeue operation). Since we always have a pointer to the\\nitem at the head of a singly linked list, removal is simply a case of returning\\nthe value of the old head node, and then modifying the head pointer to be the\\nnext node of the old head node. The run time complexity for searching a queue\\nremains the same as that of a singly linked list:O(n).\\n6.2 Priority Queue\\nUnlike a standard queue where items are ordered in terms of who arrived ﬁrst,\\na priority queue determines the order of its items by using a form of custom\\ncomparer to see which item has the highest priority. Other than the items in a\\npriority queue being ordered by priority it remains the same as a normal queue:\\nyou can only access the item at the front of the queue.\\nA sensible implementation of a priority queue is to use a heap data structure\\n(deﬁned in§4). Using a heap we can look at the ﬁrst item in the queue by simply'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 59, 'page_label': '60'}, page_content='A sensible implementation of a priority queue is to use a heap data structure\\n(deﬁned in§4). Using a heap we can look at the ﬁrst item in the queue by simply\\nreturning the item at index 0 within the heap array. A heap provides us with the\\nability to construct a priority queue where the items with the highest priority\\nare either those with the smallest value, or those with the largest.\\n6.3 Double Ended Queue\\nUnlike the queues we have talked about previously in this chapter a double\\nended queue allows you to access the items at both the front, and back of the\\nqueue. A double ended queue is commonly known as a deque which is the name\\nwe will here on in refer to it as.\\nA deque applies no prioritization strategy to its items like a priority queue\\ndoes, items are added in order to either the front of back of the deque. The\\nformer properties of the deque are denoted by the programmer utilising the data\\nstructures exposed interface.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 60, 'page_label': '61'}, page_content='CHAPTER 6. QUEUES 50\\nFigure 6.1: Queue mutations'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 61, 'page_label': '62'}, page_content='CHAPTER 6. QUEUES 51\\nDeque’s provide front and back speciﬁc versions of common queue operations,\\ne.g. you may want to enqueue an item to the front of the queue rather than\\nthe back in which case you would use a method with a name along the lines\\nof EnqueueFront. The following list identiﬁes operations that are commonly\\nsupported by deque’s:\\n• EnqueueFront\\n• EnqueueBack\\n• DequeueFront\\n• DequeueBack\\n• PeekFront\\n• PeekBack\\nFigure 6.2 shows a deque after the invocation of the following methods (in-\\norder):\\n1. EnqueueBack(12)\\n2. EnqueueFront(1)\\n3. EnqueueBack(23)\\n4. EnqueueFront(908)\\n5. DequeueFront()\\n6. DequeueBack()\\nThe operations have a one-to-one translation in terms of behaviour with\\nthose of a normal queue, or priority queue. In some cases the set of algorithms\\nthat add an item to the back of the deque may be named as they are with\\nnormal queues, e.g.EnqueueBack may simply be calledEnqueue an so on. Some\\nframeworks also specify explicit behaviour’s that data structures must adhere to.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 61, 'page_label': '62'}, page_content='normal queues, e.g.EnqueueBack may simply be calledEnqueue an so on. Some\\nframeworks also specify explicit behaviour’s that data structures must adhere to.\\nThis is certainly the case in .NET where most collections implement an interface\\nwhich requires the data structure to expose a standardAdd method. In such\\na scenario you can safely assume that theAdd method will simply enqueue an\\nitem to the back of the deque.\\nWith respect to algorithmic run time complexities a deque is the same as\\na normal queue. That is enqueueing an item to the back of a the queue is\\nO(1), additionally enqueuing an item to the front of the queue is also anO(1)\\noperation.\\nA deque is a wrapper data structure that uses either an array, or a doubly\\nlinked list. Using an array as the backing data structure would require the pro-\\ngrammer to be explicit about the size of the array up front, this would provide\\nan obvious advantage if the programmer could deterministically state the maxi-'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 61, 'page_label': '62'}, page_content='grammer to be explicit about the size of the array up front, this would provide\\nan obvious advantage if the programmer could deterministically state the maxi-\\nmum number of items the deque would contain at any one time. Unfortunately\\nin most cases this doesn’t hold, as a result the backing array will inherently\\nincur the expense of invoking a resizing algorithm which would most likely be\\nan O(n) operation. Such an approach would also leave the library developer'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 62, 'page_label': '63'}, page_content='CHAPTER 6. QUEUES 52\\nFigure 6.2: Deque data structure after several mutations'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 63, 'page_label': '64'}, page_content='CHAPTER 6. QUEUES 53\\nto look at array minimization techniques as well, it could be that after several\\ninvocations of the resizing algorithm and various mutations on the deque later\\nthat we have an array taking up a considerable amount of memory yet we are\\nonly using a few small percentage of that memory. An algorithm described\\nwould also beO(n) yet its invocation would be harder to gauge strategically.\\nTo bypass all the aforementioned issues a deque typically uses a doubly\\nlinked list as its baking data structure. While a node that has two pointers\\nconsumes more memory than its array item counterpart it makes redundant the\\nneed for expensive resizing algorithms as the data structure increases in size\\ndynamically. With a language that targets a garbage collected virtual machine\\nmemory reclamation is an opaque process as the nodes that are no longer ref-\\nerenced become unreachable and are thus marked for collection upon the next'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 63, 'page_label': '64'}, page_content='memory reclamation is an opaque process as the nodes that are no longer ref-\\nerenced become unreachable and are thus marked for collection upon the next\\ninvocation of the garbage collection algorithm. With C++ or any other lan-\\nguage that uses explicit memory allocation and deallocation it will be up to the\\nprogrammer to decide when the memory that stores the object can be freed.\\n6.4 Summary\\nWith normal queues we have seen that those who arrive ﬁrst are dealt with ﬁrst;\\nthat is they are dealt with in a ﬁrst-in-ﬁrst-out (FIFO) order. Queues can be\\never so useful; for example the Windows CPU scheduler uses a diﬀerent queue\\nfor each priority of process to determine which should be the next process to\\nutilise the CPU for a speciﬁed time quantum. Normal queues have constant\\ninsertion and deletion run times. Searching a queue is fairly unusual—typically\\nyou are only interested in the item at the front of the queue. Despite that,'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 63, 'page_label': '64'}, page_content='insertion and deletion run times. Searching a queue is fairly unusual—typically\\nyou are only interested in the item at the front of the queue. Despite that,\\nsearching is usually exposed on queues and typically the run time is linear.\\nIn this chapter we have also seen priority queues where those at the front\\nof the queue have the highest priority and those near the back have the lowest.\\nOne implementation of a priority queue is to use a heap data structure as its\\nbacking store, so the run times for insertion, deletion, and searching are the\\nsame as those for a heap (deﬁned in§4).\\nQueues are a very natural data structure, and while they are fairly primitive\\nthey can make many problems a lot simpler. For example the breadth ﬁrst\\nsearch deﬁned in§3.7.4 makes extensive use of queues.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 64, 'page_label': '65'}, page_content='Chapter 7\\nAVL Tree\\nIn the early 60’s G.M. Adelson-Velsky and E.M. Landis invented the ﬁrst self-\\nbalancing binary search tree data structure, calling it AVL Tree.\\nAn AVL tree is a binary search tree (BST, deﬁned in§3) with a self-balancing\\ncondition stating that the diﬀerence between the height of the left and right\\nsubtrees cannot be no more than one, see Figure 7.1. This condition, restored\\nafter each tree modiﬁcation, forces the general shape of an AVL tree. Before\\ncontinuing, let us focus on why balance is so important. Consider a binary\\nsearch tree obtained by starting with an empty tree and inserting some values\\nin the following order 1,2,3,4,5.\\nThe BST in Figure 7.2 represents the worst case scenario in which the run-\\nning time of all common operations such as search, insertion and deletion are\\nO(n). By applying a balance condition we ensure that the worst case running\\ntime of each common operation isO(log n). The height of an AVL tree withn'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 64, 'page_label': '65'}, page_content='O(n). By applying a balance condition we ensure that the worst case running\\ntime of each common operation isO(log n). The height of an AVL tree withn\\nnodes isO(log n) regardless of the order in which values are inserted.\\nThe AVL balance condition, known also as the node balance factor represents\\nan additional piece of information stored for each node. This is combined with\\na technique that eﬃciently restores the balance condition for the tree. In an\\nAVL tree the inventors make use of a well-known technique called tree rotation.\\nh\\nh+1\\nFigure 7.1: The left and right subtrees of an AVL tree diﬀer in height by at\\nmost 1\\n54'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 65, 'page_label': '66'}, page_content='CHAPTER 7. AVL TREE 55\\n/K31\\n/K32\\n/K33\\n/K34\\n/K35\\nFigure 7.2: Unbalanced binary search tree\\n2\\n4\\n5\\n1\\n3\\n4\\n5\\n3\\n2\\n1\\na) b)\\nFigure 7.3: Avl trees, insertion order: -a)1,2,3,4,5 -b)1,5,4,3,2'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 66, 'page_label': '67'}, page_content='CHAPTER 7. AVL TREE 56\\n7.1 Tree Rotations\\nA tree rotation is a constant time operation on a binary search tree that changes\\nthe shape of a tree while preserving standard BST properties. There are left and\\nright rotations both of them decrease the height of a BST by moving smaller\\nsubtrees down and larger subtrees up.\\n/K31/K34\\n/K32/K34\\n/K31/K31\\n/K38\\n/K32\\n/K38\\n/K31/K34\\n/K32/K34\\n/K32\\n/K31/K31\\n/K52/K69/K67/K68/K74 /K52/K6F/K74/K61/K74/K69/K6F/K6E\\n/K4C/K65/K66/K74 /K52/K6F/K74/K61/K74/K69/K6F/K6E\\nFigure 7.4: Tree left and right rotations'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 67, 'page_label': '68'}, page_content='CHAPTER 7. AVL TREE 57\\n1) algorithm LeftRotation(node)\\n2) Pre: node.Right ! =∅\\n3) Post: node.Right is the new root of the subtree,\\n4) node has becomenode.Right’s left child and,\\n5) BST properties are preserved\\n6) RightNode ← node.Right\\n7) node.Right ← RightNode .Left\\n8) RightNode .Left ← node\\n9) end LeftRotation\\n1) algorithm RightRotation(node)\\n2) Pre: node.Left ! =∅\\n3) Post: node.Left is the new root of the subtree,\\n4) node has becomenode.Left’s right child and,\\n5) BST properties are preserved\\n6) LeftNode ← node.Left\\n7) node.Left ← LeftNode .Right\\n8) LeftNode .Right ← node\\n9) end RightRotation\\nThe right and left rotation algorithms are symmetric. Only pointers are\\nchanged by a rotation resulting in anO(1) runtime complexity; the other ﬁelds\\npresent in the nodes are not changed.\\n7.2 Tree Rebalancing\\nThe algorithm that we present in this section veriﬁes that the left and right\\nsubtrees diﬀer at most in height by 1. If this property is not present then we\\nperform the correct rotation.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 67, 'page_label': '68'}, page_content='The algorithm that we present in this section veriﬁes that the left and right\\nsubtrees diﬀer at most in height by 1. If this property is not present then we\\nperform the correct rotation.\\nNotice that we use two new algorithms that represent double rotations.\\nThese algorithms are namedLeftAndRightRotation, andRightAndLeftRotation.\\nThe algorithms are self documenting in their names, e.g.LeftAndRightRotation\\nﬁrst performs a left rotation and then subsequently a right rotation.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 68, 'page_label': '69'}, page_content='CHAPTER 7. AVL TREE 58\\n1) algorithm CheckBalance(current)\\n2) Pre: current is the node to start from balancing\\n3) Post: current height has been updated while tree balance is if needed\\n4) restored through rotations\\n5) if current.Left =∅ and current.Right =∅\\n6) current.Height = -1;\\n7) else\\n8) current.Height = Max(Height(current.Left),Height(current.Right)) + 1\\n9) end if\\n10) if Height(current.Left) -Height(current.Right) > 1\\n11) if Height(current.Left.Left) -Height(current.Left.Right) > 0\\n12) RightRotation( current)\\n13) else\\n14) LeftAndRightRotation( current)\\n15) end if\\n16) else if Height(current.Left) -Height(current.Right) < −1\\n17) if Height(current.Right.Left) -Height(current.Right.Right) < 0\\n18) LeftRotation( current)\\n19) else\\n20) RightAndLeftRotation( current)\\n21) end if\\n22) end if\\n23) end CheckBalance\\n7.3 Insertion\\nAVL insertion operates ﬁrst by inserting the given value the same way as BST\\ninsertion and then by applying rebalancing techniques if necessary. The latter'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 68, 'page_label': '69'}, page_content='23) end CheckBalance\\n7.3 Insertion\\nAVL insertion operates ﬁrst by inserting the given value the same way as BST\\ninsertion and then by applying rebalancing techniques if necessary. The latter\\nis only performed if the AVL property no longer holds, that is the left and right\\nsubtrees height diﬀer by more than 1. Each time we insert a node into an AVL\\ntree:\\n1. We go down the tree to ﬁnd the correct point at which to insert the node,\\nin the same manner as for BST insertion; then\\n2. we travel up the tree from the inserted node and check that the node\\nbalancing property has not been violated; if the property hasn’t been\\nviolated then we need not rebalance the tree, the opposite is true if the\\nbalancing property has been violated.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 69, 'page_label': '70'}, page_content='CHAPTER 7. AVL TREE 59\\n1) algorithm Insert(value)\\n2) Pre: value has passed custom type checks for typeT\\n3) Post: value has been placed in the correct location in the tree\\n4) if root = ∅\\n5) root ← node(value)\\n6) else\\n7) InsertNode( root, value)\\n8) end if\\n9) end Insert\\n1) algorithm InsertNode(current, value)\\n2) Pre: current is the node to start from\\n3) Post: value has been placed in the correct location in the tree while\\n4) preserving tree balance\\n5) if value < current.Value\\n6) if current.Left =∅\\n7) current.Left ← node(value)\\n8) else\\n9) InsertNode( current.Left, value)\\n10) end if\\n11) else\\n12) if current.Right =∅\\n13) current.Right ← node(value)\\n14) else\\n15) InsertNode( current.Right, value)\\n16) end if\\n17) end if\\n18) CheckBalance(current)\\n19) end InsertNode\\n7.4 Deletion\\nOur balancing algorithm is like the one presented for our BST (deﬁned in§3.3).\\nThe major diﬀerence is that we have to ensure that the tree still adheres to the'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 69, 'page_label': '70'}, page_content='19) end InsertNode\\n7.4 Deletion\\nOur balancing algorithm is like the one presented for our BST (deﬁned in§3.3).\\nThe major diﬀerence is that we have to ensure that the tree still adheres to the\\nAVL balance property after the removal of the node. If the tree doesn’t need\\nto be rebalanced and the value we are removing is contained within the tree\\nthen no further step are required. However, when the value is in the tree and\\nits removal upsets the AVL balance property then we must perform the correct\\nrotation(s).'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 70, 'page_label': '71'}, page_content='CHAPTER 7. AVL TREE 60\\n1) algorithm Remove(value)\\n2) Pre: value is the value of the node to remove,root is the root node\\n3) of the Avl\\n4) Post: node withvalue is removed and tree rebalanced if found in which\\n5) case yields true, otherwise false\\n6) nodeToRemove ← root\\n7) parent ← ∅\\n8) Stackpath ← root\\n9) while nodeT oRemove̸= ∅ and nodeT oRemove.V alue= V alue\\n10) parent = nodeToRemove\\n11) if value < nodeT oRemove.Value\\n12) nodeT oRemove← nodeToRemove.Left\\n13) else\\n14) nodeT oRemove← nodeToRemove.Right\\n15) end if\\n16) path.Push(nodeToRemove)\\n17) end while\\n18) if nodeT oRemove= ∅\\n19) return false// value not in Avl\\n20) end if\\n21) parent ← FindParent(value)\\n22) if count = 1 //count keeps track of the # of nodes in the Avl\\n23) root ← ∅// we are removing the only node in the Avl\\n24) else if nodeToRemove .Left =∅ and nodeT oRemove.Right =null\\n25) // case #1\\n26) if nodeToRemove .Value < parent.Value\\n27) parent.Left ← ∅\\n28) else\\n29) parent.Right ← ∅\\n30) end if'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 70, 'page_label': '71'}, page_content='24) else if nodeToRemove .Left =∅ and nodeT oRemove.Right =null\\n25) // case #1\\n26) if nodeToRemove .Value < parent.Value\\n27) parent.Left ← ∅\\n28) else\\n29) parent.Right ← ∅\\n30) end if\\n31) else if nodeToRemove .Left =∅ and nodeT oRemove.Right ̸= ∅\\n32) // case # 2\\n33) if nodeToRemove .Value < parent.Value\\n34) parent.Left ← nodeToRemove .Right\\n35) else\\n36) parent.Right ← nodeToRemove .Right\\n37) end if\\n38) else if nodeToRemove .Left ̸= ∅ and nodeT oRemove.Right =∅\\n39) // case #3\\n40) if nodeToRemove .Value < parent.Value\\n41) parent.Left ← nodeToRemove .Left\\n42) else\\n43) parent.Right ← nodeToRemove .Left\\n44) end if\\n45) else\\n46) // case #4\\n47) largestV alue← nodeT oRemove.Left\\n48) while largestV alue.Right ̸= ∅\\n49) // ﬁnd the largest value in the left subtree of nodeToRemove\\n50) largestV alue← largestV alue.Right'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 71, 'page_label': '72'}, page_content='CHAPTER 7. AVL TREE 61\\n51) end while\\n52) // set the parents’ Right pointer of largestV alueto ∅\\n53) FindParent( largestV alue.Value).Right ← ∅\\n54) nodeT oRemove.Value ← largestV alue.Value\\n55) end if\\n56) while path.Count >0\\n57) CheckBalance(path.Pop()) // we trackback to the root node check balance\\n58) end while\\n59) count ← count − 1\\n60) return true\\n61) end Remove\\n7.5 Summary\\nThe AVL tree is a sophisticated self balancing tree. It can be thought of as\\nthe smarter, younger brother of the binary search tree. Unlike its older brother\\nthe AVL tree avoids worst case linear complexity runtimes for its operations.\\nThe AVL tree guarantees via the enforcement of balancing algorithms that the\\nleft and right subtrees diﬀer in height by at most 1 which yields at most a\\nlogarithmic runtime complexity.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 72, 'page_label': '73'}, page_content='Part II\\nAlgorithms\\n62'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 73, 'page_label': '74'}, page_content='Chapter 8\\nSorting\\nAll the sorting algorithms in this chapter use data structures of a speciﬁc type\\nto demonstrate sorting, e.g. a 32 bit integer is often used as its associated\\noperations (e.g. <, >, etc) are clear in their behaviour.\\nThe algorithms discussed can easily be translated into generic sorting algo-\\nrithms within your respective language of choice.\\n8.1 Bubble Sort\\nOne of the most simple forms of sorting is that of comparing each item with\\nevery other item in some list, however as the description may imply this form\\nof sorting is not particularly eﬀecientO(n2). In it’s most simple form bubble\\nsort can be implemented as two loops.\\n1) algorithm BubbleSort(list)\\n2) Pre: list ̸= ∅\\n3) Post: list has been sorted into values of ascending order\\n4) for i ← 0 tolist.Count − 1\\n5) for j ← 0 tolist.Count − 1\\n6) if list[i] < list[j]\\n7) Swap(list[i], list[j])\\n8) end if\\n9) end for\\n10) end for\\n11) return list\\n12) end BubbleSort\\n8.2 Merge Sort'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 73, 'page_label': '74'}, page_content='4) for i ← 0 tolist.Count − 1\\n5) for j ← 0 tolist.Count − 1\\n6) if list[i] < list[j]\\n7) Swap(list[i], list[j])\\n8) end if\\n9) end for\\n10) end for\\n11) return list\\n12) end BubbleSort\\n8.2 Merge Sort\\nMerge sort is an algorithm that has a fairly eﬃcient space time complexity -\\nO(n log n) and is fairly trivial to implement. The algorithm is based on splitting\\na list, into two similar sized lists (left, andright) and sorting each list and then\\nmerging the sorted lists back together.\\nNote: the function MergeOrdered simply takes two ordered lists and makes\\nthem one.\\n63'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 74, 'page_label': '75'}, page_content='CHAPTER 8. SORTING 64\\n/K35/K34/K32/K37/K34/K37/K35/K34\\n/K30 /K31 /K32 /K33 /K34\\n/K35/K34/K32/K37/K34/K37/K35/K34\\n/K30 /K31 /K32 /K33 /K34\\n/K35/K34/K32/K37/K35/K37/K34/K34\\n/K30 /K31 /K32 /K33 /K34\\n/K35/K34/K37/K35/K32/K37/K34/K34\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K35/K34/K32/K37/K34/K34\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K35/K34/K32/K37/K34/K34\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K35/K34/K32/K37/K34/K34\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K35/K34/K37/K34/K32/K34\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K37/K34/K35/K34/K32/K34\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K37/K34/K35/K34/K32/K34\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K37/K34/K35/K34/K34/K32\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K37/K34/K35/K34/K34/K32\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K37/K34/K35/K34/K34/K32\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K37/K34/K35/K34/K34/K32\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K37/K34/K35/K34/K34/K32\\n/K30 /K31 /K32 /K33 /K34\\nFigure 8.1: Bubble Sort Iterations\\n1) algorithm Mergesort(list)\\n2) Pre: list ̸= ∅'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 74, 'page_label': '75'}, page_content='/K37/K35/K37/K34/K35/K34/K34/K32\\n/K30 /K31 /K32 /K33 /K34\\n/K37/K35/K37/K34/K35/K34/K34/K32\\n/K30 /K31 /K32 /K33 /K34\\nFigure 8.1: Bubble Sort Iterations\\n1) algorithm Mergesort(list)\\n2) Pre: list ̸= ∅\\n3) Post: list has been sorted into values of ascending order\\n4) if list.Count = 1 // already sorted\\n5) return list\\n6) end if\\n7) m ← list.Count / 2\\n8) left ← list(m)\\n9) right ← list(list.Count − m)\\n10) for i ← 0 toleft.Count−1\\n11) left[i] ← list[i]\\n12) end for\\n13) for i ← 0 toright.Count−1\\n14) right[i] ← list[i]\\n15) end for\\n16) left ← Mergesort(left)\\n17) right ← Mergesort(right)\\n18) return MergeOrdered(left, right)\\n19) end Mergesort'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 75, 'page_label': '76'}, page_content='CHAPTER 8. SORTING 65\\n/K35/K34\\n/K32\\n/K37/K34\\n/K37/K35\\n/K34\\n/K37/K35\\n/K34\\n/K35/K34\\n/K32\\n/K37/K34\\n/K34\\n/K37/K35\\n/K37/K34\\n/K35/K34\\n/K32\\n/K32\\n/K35\\n/K34\\n/K44/K69/K76/K69/K64/K65\\n/K35/K34\\n/K32\\n/K37/K35\\n/K34\\n/K37/K34\\n/K35/K34\\n/K32\\n/K37/K35\\n/K37/K34\\n/K35/K34\\n/K34\\n/K32\\n/K49/K6D/K70/K65/K72/K61 /K28/K4D/K65/K72/K67/K65/K29\\nFigure 8.2: Merge Sort Divide et Impera Approach\\n8.3 Quick Sort\\nQuick sort is one of the most popular sorting algorithms based on divide et\\nimpera strategy, resulting in anO(n log n) complexity. The algorithm starts by\\npicking an item, called pivot, and moving all smaller items before it, while all\\ngreater elements after it. This is the main quick sort operation, called partition,\\nrecursively repeated on lesser and greater sub lists until their size is one or zero\\n- in which case the list is implicitly sorted.\\nChoosing an appropriate pivot, as for example the median element is funda-\\nmental for avoiding the drastically reduced performance ofO(n2).'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 76, 'page_label': '77'}, page_content='CHAPTER 8. SORTING 66\\n/K35/K34/K32/K37/K34/K37/K35/K34\\n/K50/K69/K76/K6F/K74\\n/K35/K34/K32/K37/K34/K37/K35/K34\\n/K50/K69/K76/K6F/K74\\n/K37/K35/K32/K37/K34/K35/K34/K34\\n/K50/K69/K76/K6F/K74\\n/K37/K35/K35/K34/K37/K34/K32/K34\\n/K50/K69/K76/K6F/K74\\n/K37/K35/K37/K34/K35/K34/K32/K34\\n/K50/K69/K76/K6F/K74\\n/K32/K34\\n/K50/K69/K76/K6F/K74\\n/K34/K32\\n/K50/K69/K76/K6F/K74\\n/K37/K35/K37/K34\\n/K50/K69/K76/K6F/K74\\n/K37/K35/K37/K34\\n/K37/K35/K37/K34/K35/K34/K34/K32\\n/K50/K69/K76/K6F/K74\\nFigure 8.3: Quick Sort Example (pivot median strategy)\\n1) algorithm QuickSort(list)\\n2) Pre: list ̸= ∅\\n3) Post: list has been sorted into values of ascending order\\n4) if list.Count = 1 // already sorted\\n5) return list\\n6) end if\\n7) pivot ←MedianValue(list)\\n8) for i ← 0 tolist.Count−1\\n9) if list[i] =pivot\\n10) equal.Insert(list[i])\\n11) end if\\n12) if list[i] < pivot\\n13) less.Insert(list[i])\\n14) end if\\n15) if list[i] > pivot\\n16) greater.Insert(list[i])\\n17) end if\\n18) end for'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 76, 'page_label': '77'}, page_content='9) if list[i] =pivot\\n10) equal.Insert(list[i])\\n11) end if\\n12) if list[i] < pivot\\n13) less.Insert(list[i])\\n14) end if\\n15) if list[i] > pivot\\n16) greater.Insert(list[i])\\n17) end if\\n18) end for\\n19) return Concatenate(QuickSort(less), equal, QuickSort(greater))\\n20) end Quicksort'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 77, 'page_label': '78'}, page_content='CHAPTER 8. SORTING 67\\n8.4 Insertion Sort\\nInsertion sort is a somewhat interesting algorithm with an expensive runtime of\\nO(n2). It can be best thought of as a sorting scheme similar to that of sorting\\na hand of playing cards, i.e. you take one card and then look at the rest with\\nthe intent of building up an ordered set of cards in your hand.\\n/K35/K34/K32/K37/K34/K37/K35/K34 /K35/K34/K32/K37/K34/K37/K35/K34 /K35/K34/K32/K37/K34/K37/K35/K34\\n/K37/K34\\n/K35/K34/K32/K37/K35/K37/K34/K34\\n/K32\\n/K37/K35\\n/K35/K34/K37/K35/K37/K34/K34/K32\\n/K35/K34\\n/K37/K35/K37/K34/K35/K34/K34/K32\\n/K34\\nFigure 8.4: Insertion Sort Iterations\\n1) algorithm Insertionsort(list)\\n2) Pre: list ̸= ∅\\n3) Post: list has been sorted into values of ascending order\\n4) unsorted ← 1\\n5) while unsorted < list.Count\\n6) hold ← list[unsorted]\\n7) i ← unsorted − 1\\n8) while i ≥ 0 and hold < list[i]\\n9) list[i + 1]← list[i]\\n10) i ← i − 1\\n11) end while\\n12) list[i + 1]← hold\\n13) unsorted ← unsorted + 1\\n14) end while\\n15) return list'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 77, 'page_label': '78'}, page_content='7) i ← unsorted − 1\\n8) while i ≥ 0 and hold < list[i]\\n9) list[i + 1]← list[i]\\n10) i ← i − 1\\n11) end while\\n12) list[i + 1]← hold\\n13) unsorted ← unsorted + 1\\n14) end while\\n15) return list\\n16) end Insertionsort'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 78, 'page_label': '79'}, page_content='CHAPTER 8. SORTING 68\\n8.5 Shell Sort\\nPut simply shell sort can be thought of as a more eﬃcient variation of insertion\\nsort as described in§8.4, it achieves this mainly by comparing items of varying\\ndistances apart resulting in a run time complexity ofO(n log2 n).\\nShell sort is fairly straight forward but may seem somewhat confusing at\\nﬁrst as it diﬀers from other sorting algorithms in the way it selects items to\\ncompare. Figure 8.5 shows shell sort being ran on an array of integers, the red\\ncoloured square is the current value we are holding.\\n1) algorithm ShellSort(list)\\n2) Pre: list ̸= ∅\\n3) Post: list has been sorted into values of ascending order\\n4) increment ← list.Count / 2\\n5) while increment ̸= 0\\n6) current ← increment\\n7) while current < list.Count\\n8) hold ← list[current]\\n9) i ← current − increment\\n10) while i ≥ 0 and hold < list[i]\\n11) list[i + increment] ← list[i]\\n12) i− = increment\\n13) end while\\n14) list[i + increment] ← hold\\n15) current ← current + 1\\n16) end while'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 78, 'page_label': '79'}, page_content='9) i ← current − increment\\n10) while i ≥ 0 and hold < list[i]\\n11) list[i + increment] ← list[i]\\n12) i− = increment\\n13) end while\\n14) list[i + increment] ← hold\\n15) current ← current + 1\\n16) end while\\n17) increment /= 2\\n18) end while\\n19) return list\\n20) end ShellSort\\n8.6 Radix Sort\\nUnlike the sorting algorithms described previously radix sort uses buckets to\\nsort items, each bucket holds items with a particular property called a key.\\nNormally a bucket is a queue, each time radix sort is performed these buckets\\nare emptied starting the smallest key bucket to the largest. When looking at\\nitems within a list to sort we do so by isolating a speciﬁc key, e.g. in the example\\nwe are about to show we have a maximum of three keys for all items, that is\\nthe highest key we need to look at is hundreds. Because we are dealing with, in\\nthis example base 10 numbers we have at any one point 10 possible key values\\n0..9 each of which has their own bucket. Before we show you this ﬁrst simple'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 78, 'page_label': '79'}, page_content='this example base 10 numbers we have at any one point 10 possible key values\\n0..9 each of which has their own bucket. Before we show you this ﬁrst simple\\nversion of radix sort let us clarify what we mean by isolating keys. Given the\\nnumber 102 if we look at the ﬁrst key, the ones then we can see we have two of\\nthem, progressing to the next key - tens we can see that the number has zero\\nof them, ﬁnally we can see that the number has a single hundred. The number\\nused as an example has in total three keys:'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 79, 'page_label': '80'}, page_content='CHAPTER 8. SORTING 69\\nFigure 8.5: Shell sort'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 80, 'page_label': '81'}, page_content='CHAPTER 8. SORTING 70\\n1. Ones\\n2. Tens\\n3. Hundreds\\nFor further clariﬁcation what if we wanted to determine how many thousands\\nthe number 102 has? Clearly there are none, but often looking at a number as\\nﬁnal like we often do it is not so obvious so when asked the question how many\\nthousands does 102 have you should simply pad the number with a zero in that\\nlocation, e.g. 0102 here it is more obvious that the key value at the thousands\\nlocation is zero.\\nThe last thing to identify before we actually show you a simple implemen-\\ntation of radix sort that works on only positive integers, and requires you to\\nspecify the maximum key size in the list is that we need a way to isolate a\\nspeciﬁc key at any one time. The solution is actually very simple, but its not\\noften you want to isolate a key in a number so we will spell it out clearly\\nhere. A key can be accessed from any integer with the following expression:\\nkey ← (number / keyT oAccess) % 10. As a simple example lets say that we'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 80, 'page_label': '81'}, page_content='here. A key can be accessed from any integer with the following expression:\\nkey ← (number / keyT oAccess) % 10. As a simple example lets say that we\\nwant to access the tens key of the number 1290, the tens column is key 10 and\\nso after substitution yieldskey ← (1290 / 10) % 10 = 9. The next key to\\nlook at for a number can be attained by multiplying the last key by ten working\\nleft to right in a sequential manner. The value ofkey is used in the following\\nalgorithm to work out the index of an array of queues to enqueue the item into.\\n1) algorithm Radix(list, maxKeySize )\\n2) Pre: list ̸= ∅\\n3) maxKeySize ≥ 0 and represents the largest key size in the list\\n4) Post: list has been sorted\\n5) queues ← Queue[10]\\n6) indexOfKey ← 1\\n7) fori ← 0 to maxKeySize − 1\\n8) foreach item in list\\n9) queues[GetQueueIndex(item, indexOfKey )].Enqueue(item)\\n10) end foreach\\n11) list ← CollapseQueues(queues)\\n12) ClearQueues( queues)\\n13) indexOfKey ← indexOfKey ∗ 10\\n14) end for\\n15) return list\\n16) end Radix'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 80, 'page_label': '81'}, page_content='10) end foreach\\n11) list ← CollapseQueues(queues)\\n12) ClearQueues( queues)\\n13) indexOfKey ← indexOfKey ∗ 10\\n14) end for\\n15) return list\\n16) end Radix\\nFigure 8.6 shows the members ofqueues from the algorithm described above\\noperating on the list whose members are 90, 12, 8, 791, 123, and 61, the key we\\nare interested in for each number is highlighted. Omitted queues in Figure 8.6\\nmean that they contain no items.\\n8.7 Summary\\nThroughout this chapter we have seen many diﬀerent algorithms for sorting\\nlists, some are very eﬃcient (e.g. quick sort deﬁned in§8.3), some are not (e.g.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 81, 'page_label': '82'}, page_content='CHAPTER 8. SORTING 71\\nFigure 8.6: Radix sort base 10 algorithm\\nbubble sort deﬁned in§8.1).\\nSelecting the correct sorting algorithm is usually denoted purely by eﬃciency,\\ne.g. you would always choose merge sort over shell sort and so on. There are\\nalso other factors to look at though and these are based on the actual imple-\\nmentation. Some algorithms are very nicely expressed in a recursive fashion,\\nhowever these algorithms ought to be pretty eﬃcient, e.g. implementing a linear,\\nquadratic, or slower algorithm using recursion would be a very bad idea.\\nIf you want to learn more about why you should be very, very careful when\\nimplementing recursive algorithms see Appendix C.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 82, 'page_label': '83'}, page_content='Chapter 9\\nNumeric\\nUnless stated otherwise the aliasn denotes a standard 32 bit integer.\\n9.1 Primality Test\\nA simple algorithm that determines whether or not a given integer is a prime\\nnumber, e.g. 2, 5, 7, and 13 areall prime numbers, however 6 is not as it can\\nbe the result of the product of two numbers that are< 6.\\nIn an attempt to slow down the inner loop the√n is used as the upper\\nbound.\\n1) algorithm IsPrime(n)\\n2) Post: n is determined to be a prime or not\\n3) for i ← 2 to n do\\n4) for j ← 1 to sqrt(n) do\\n5) if i ∗ j = n\\n6) return false\\n7) end if\\n8) end for\\n9) end for\\n10) end IsPrime\\n9.2 Base conversions\\nDSA contains a number of algorithms that convert a base 10 number to its\\nequivalent binary, octal or hexadecimal form. For example 7810 has a binary\\nrepresentation of 10011102.\\nTable 9.1 shows the algorithm trace when the number to convert to binary\\nis 74210.\\n72'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 83, 'page_label': '84'}, page_content='CHAPTER 9. NUMERIC 73\\n1) algorithm ToBinary(n)\\n2) Pre: n ≥ 0\\n3) Post: n has been converted into its base 2 representation\\n4) while n >0\\n5) list.Add(n % 2)\\n6) n ← n/2\\n7) end while\\n8) return Reverse(list)\\n9) end ToBinary\\nn list\\n742 { 0 }\\n371 { 0, 1 }\\n185 { 0, 1, 1 }\\n92 { 0, 1, 1, 0 }\\n46 { 0, 1, 1, 0, 1 }\\n23 { 0, 1, 1, 0, 1, 1 }\\n11 { 0, 1, 1, 0, 1, 1, 1 }\\n5 { 0, 1, 1, 0, 1, 1, 1, 1 }\\n2 { 0, 1, 1, 0, 1, 1, 1, 1, 0 }\\n1 { 0, 1, 1, 0, 1, 1, 1, 1, 0, 1 }\\nTable 9.1: Algorithm trace of ToBinary\\n9.3 Attaining the greatest common denomina-\\ntor of two numbers\\nA fairly routine problem in mathematics is that of ﬁnding the greatest common\\ndenominator of two integers, what we are essentially after is the greatest number\\nwhich is a multiple of both, e.g. the greatest common denominator of 9, and\\n15 is 3. One of the most elegant solutions to this problem is based on Euclid’s\\nalgorithm that has a run time complexity ofO(n2).\\n1) algorithm GreatestCommonDenominator(m, n)\\n2) Pre: m and n are integers'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 83, 'page_label': '84'}, page_content='algorithm that has a run time complexity ofO(n2).\\n1) algorithm GreatestCommonDenominator(m, n)\\n2) Pre: m and n are integers\\n3) Post: the greatest common denominator of the two integers is calculated\\n4) if n = 0\\n5) return m\\n6) end if\\n7) return GreatestCommonDenominator(n, m % n)\\n8) end GreatestCommonDenominator'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 84, 'page_label': '85'}, page_content='CHAPTER 9. NUMERIC 74\\n9.4 Computing the maximum value for a num-\\nber of a speciﬁc base consisting of N digits\\nThis algorithm computes the maximum value of a number for a given number\\nof digits, e.g. using the base 10 system the maximum number we can have\\nmade up of 4 digits is the number 999910. Similarly the maximum number that\\nconsists of 4 digits for a base 2 number is 11112 which is 1510.\\nThe expression by which we can compute this maximum value forN digits\\nis: BN − 1. In the previous expressionB is the number base, andN is the\\nnumber of digits. As an example if we wanted to determine the maximum value\\nfor a hexadecimal number (base 16) consisting of 6 digits the expression would\\nbe as follows: 166 − 1. The maximum value of the previous example would be\\nrepresented asFF F F F F16 which yields 1677721510.\\nIn the following algorithmnumberBase should be considered restricted to\\nthe values of 2, 8, 9, and 16. For this reason in our actual implementation'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 84, 'page_label': '85'}, page_content='represented asFF F F F F16 which yields 1677721510.\\nIn the following algorithmnumberBase should be considered restricted to\\nthe values of 2, 8, 9, and 16. For this reason in our actual implementation\\nnumberBase has an enumeration type. TheBase enumeration type is deﬁned\\nas:\\nBase = {Binary ← 2, Octal← 8, Decimal← 10, Hexadecimal← 16}\\nThe reason we provide the deﬁnition ofBase is to give you an idea how this\\nalgorithm can be modelled in a more readable manner rather than using various\\nchecks to determine the correct base to use. For our implementation we cast the\\nvalue ofnumberBase to an integer, as such we extract the value associated with\\nthe relevant option in theBase enumeration. As an example if we were to cast\\nthe optionOctal to an integer we would get the value 8. In the algorithm listed\\nbelow the cast is implicit so we just use the actual argumentnumberBase.\\n1) algorithm MaxValue(numberBase, n)\\n2) Pre: numberBase is the number system to use,n is the number of digits'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 84, 'page_label': '85'}, page_content='below the cast is implicit so we just use the actual argumentnumberBase.\\n1) algorithm MaxValue(numberBase, n)\\n2) Pre: numberBase is the number system to use,n is the number of digits\\n3) Post: the maximum value fornumberBase consisting ofn digits is computed\\n4) return Power(numberBase, n) −1\\n5) end MaxValue\\n9.5 Factorial of a number\\nAttaining the factorial of a number is a primitive mathematical operation. Many\\nimplementations of the factorial algorithm are recursive as the problem is re-\\ncursive in nature, however here we present an iterative solution. The iterative\\nsolution is presented because it too is trivial to implement and doesn’t suﬀer\\nfrom the use of recursion (for more on recursion see§C).\\nThe factorial of 0 and 1 is 0. The aforementioned acts as a base case that we\\nwill build upon. The factorial of 2 is 2∗ the factorial of 1, similarly the factorial\\nof 3 is 3∗ the factorial of 2 and so on. We can indicate that we are after the'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 84, 'page_label': '85'}, page_content='will build upon. The factorial of 2 is 2∗ the factorial of 1, similarly the factorial\\nof 3 is 3∗ the factorial of 2 and so on. We can indicate that we are after the\\nfactorial of a number using the formN! where N is the number we wish to\\nattain the factorial of. Our algorithm doesn’t use such notation but it is handy\\nto know.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 85, 'page_label': '86'}, page_content='CHAPTER 9. NUMERIC 75\\n1) algorithm Factorial(n)\\n2) Pre: n ≥ 0, n is the number to compute the factorial of\\n3) Post: the factorial ofn is computed\\n4) if n <2\\n5) return 1\\n6) end if\\n7) factorial ← 1\\n8) for i ← 2 to n\\n9) factorial ← factorial ∗ i\\n10) end for\\n11) return factorial\\n12) end Factorial\\n9.6 Summary\\nIn this chapter we have presented several numeric algorithms, most of which\\nare simply here because they were fun to design. Perhaps the message that\\nthe reader should gain from this chapter is that algorithms can be applied to\\nseveral domains to make work in that respective domain attainable. Numeric\\nalgorithms in particular drive some of the most advanced systems on the planet\\ncomputing such data as weather forecasts.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 86, 'page_label': '87'}, page_content='Chapter 10\\nSearching\\n10.1 Sequential Search\\nA simple algorithm that search for a speciﬁc item inside a list. It operates\\nlooping on each elementO(n) until a match occurs or the end is reached.\\n1) algorithm SequentialSearch(list, item)\\n2) Pre: list ̸= ∅\\n3) Post: return index of item if found, otherwise−1\\n4) index ← 0\\n5) while index < list.Count and list[index] ̸= item\\n6) index ← index + 1\\n7) end while\\n8) if index < list.Count and list[index] =item\\n9) return index\\n10) end if\\n11) return −1\\n12) end SequentialSearch\\n10.2 Probability Search\\nProbability search is a statistical sequential searching algorithm. In addition to\\nsearching for an item, it takes into account its frequency by swapping it with\\nit’s predecessor in the list. The algorithm complexity still remains atO(n) but\\nin a non-uniform items search the more frequent items are in the ﬁrst positions,\\nreducing list scanning time.\\nFigure 10.1 shows the resulting state of a list after searching for two items,'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 86, 'page_label': '87'}, page_content='in a non-uniform items search the more frequent items are in the ﬁrst positions,\\nreducing list scanning time.\\nFigure 10.1 shows the resulting state of a list after searching for two items,\\nnotice how the searched items have had their search probability increased after\\neach search operation respectively.\\n76'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 87, 'page_label': '88'}, page_content='CHAPTER 10. SEARCHING 77\\nFigure 10.1: a) Search(12), b) Search(101)\\n1) algorithm ProbabilitySearch(list, item)\\n2) Pre: list ̸= ∅\\n3) Post: a boolean indicating where the item is found or not;\\nin the former case swap founded item with its predecessor\\n4) index ← 0\\n5) while index < list.Count and list[index] ̸= item\\n6) index ← index + 1\\n7) end while\\n8) if index ≥ list.Count or list[index] ̸= item\\n9) return false\\n10) end if\\n11) if index >0\\n12) Swap(list[index], list[index − 1])\\n13) end if\\n14) return true\\n15) end ProbabilitySearch\\n10.3 Summary\\nIn this chapter we have presented a few novel searching algorithms. We have\\npresented more eﬃcient searching algorithms earlier on, like for instance the\\nlogarithmic searching algorithm that AVL and BST tree’s use (deﬁned in§3.2).\\nWe decided not to cover a searching algorithm known as binary chop (another\\nname for binary search, binary chop usually refers to its array counterpart) as'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 88, 'page_label': '89'}, page_content='CHAPTER 10. SEARCHING 78\\nthe reader has already seen such an algorithm in§3.\\nSearching algorithms and their eﬃciency largely depends on the underlying\\ndata structure being used to store the data. For instance it is quicker to deter-\\nmine whether an item is in a hash table than it is an array, similarly it is quicker\\nto search a BST than it is a linked list. If you are going to search for data fairly\\noften then we strongly advise that you sit down and research the data structures\\navailable to you. In most cases using a list or any other primarily linear data\\nstructure is down to lack of knowledge. Model your data and then research the\\ndata structures that best ﬁt your scenario.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 89, 'page_label': '90'}, page_content='Chapter 11\\nStrings\\nStrings have their own chapter in this text purely because string operations\\nand transformations are incredibly frequent within programs. The algorithms\\npresented are based on problems the authors have come across previously, or\\nwere formulated to satisfy curiosity.\\n11.1 Reversing the order of words in a sentence\\nDeﬁning algorithms for primitive string operations is simple, e.g. extracting a\\nsub-string of a string, however some algorithms that require more inventiveness\\ncan be a little more tricky.\\nThe algorithm presented here does not simply reverse the characters in a\\nstring, rather it reverses the order of words within a string. This algorithm\\nworks on the principal that words are all delimited by white space, and using a\\nfew markers to deﬁne where words start and end we can easily reverse them.\\n79'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 90, 'page_label': '91'}, page_content='CHAPTER 11. STRINGS 80\\n1) algorithm ReverseWords(value)\\n2) Pre: value ̸= ∅, sb is a string buﬀer\\n3) Post: the words invalue have been reversed\\n4) last ← value.Length − 1\\n5) start ← last\\n6) while last ≥ 0\\n7) // skip whitespace\\n8) while start ≥ 0 and value[start] = whitespace\\n9) start ← start − 1\\n10) end while\\n11) last ← start\\n12) // march down to the index before the beginning of the word\\n13) while start ≥ 0 and start ̸= whitespace\\n14) start ← start − 1\\n15) end while\\n16) // append chars from start + 1 tolength + 1 to string buﬀer sb\\n17) for i ← start + 1to last\\n18) sb.Append(value[i])\\n19) end for\\n20) // if this isn’t the last word in the string add some whitespace after the word in the buﬀer\\n21) if start >0\\n22) sb.Append(‘ ’)\\n23) end if\\n24) last ← start − 1\\n25) start ← last\\n26) end while\\n27) // check if we have added one too many whitespace tosb\\n28) if sb[sb.Length −1] = whitespace\\n29) // cut the whitespace\\n30) sb.Length ← sb.Length −1\\n31) end if\\n32) return sb\\n33) end ReverseWords'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 90, 'page_label': '91'}, page_content='27) // check if we have added one too many whitespace tosb\\n28) if sb[sb.Length −1] = whitespace\\n29) // cut the whitespace\\n30) sb.Length ← sb.Length −1\\n31) end if\\n32) return sb\\n33) end ReverseWords\\n11.2 Detecting a palindrome\\nAlthough not a frequent algorithm that will be applied in real-life scenarios\\ndetecting a palindrome is a fun, and as it turns out pretty trivial algorithm to\\ndesign.\\nThe algorithm that we present has aO(n) run time complexity. Our algo-\\nrithm uses two pointers at opposite ends of string we are checking is a palindrome\\nor not. These pointers march in towards each other always checking that each\\ncharacter they point to is the same with respect to value. Figure 11.1 shows the\\nIsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\\nIf you remove all punctuation, and white space from the aforementioned string\\nyou will ﬁnd that it is a valid palindrome.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 91, 'page_label': '92'}, page_content='CHAPTER 11. STRINGS 81\\nFigure 11.1: left and right pointers marching in towards one another\\n1) algorithm IsPalindrome(value)\\n2) Pre: value ̸= ∅\\n3) Post: value is determined to be a palindrome or not\\n4) word ← value.Strip().ToUpperCase()\\n5) left ← 0\\n6) right ← word.Length −1\\n7) while word[left] =word[right] and left < right\\n8) left ← left + 1\\n9) right ← right − 1\\n10) end while\\n11) return word[left] =word[right]\\n12) end IsPalindrome\\nIn theIsPalindrome algorithm we call a method by the name ofStrip. This\\nalgorithm discards punctuation in the string, including white space. As a result\\nword contains a heavily compacted representation of the original string, each\\ncharacter of which is in its uppercase representation.\\nPalindromes discard white space, punctuation, and case making these changes\\nallows us to design a simple algorithm while making our algorithm fairly robust\\nwith respect to the palindromes it will detect.\\n11.3 Counting the number of words in a string'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 91, 'page_label': '92'}, page_content='allows us to design a simple algorithm while making our algorithm fairly robust\\nwith respect to the palindromes it will detect.\\n11.3 Counting the number of words in a string\\nCounting the number of words in a string can seem pretty trivial at ﬁrst, however\\nthere are a few cases that we need to be aware of:\\n1. tracking when we are in a string\\n2. updating the word count at the correct place\\n3. skipping white space that delimits the words\\nAs an example consider the string “Ben ate hay” Clearly this string contains\\nthree words, each of which distinguished via white space. All of the previously\\nlisted points can be managed by using three variables:\\n1. index\\n2. wordCount\\n3. inWord'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 92, 'page_label': '93'}, page_content='CHAPTER 11. STRINGS 82\\nFigure 11.2: String with three words\\nFigure 11.3: String with varying number of white space delimiting the words\\nOf the previously listedindex keeps track of the current index we are at in\\nthe string,wordCount is an integer that keeps track of the number of words we\\nhave encountered, and ﬁnallyinWord is a Boolean ﬂag that denotes whether\\nor not at the present time we are within a word. If we are not currently hitting\\nwhite space we are in a word, the opposite is true if at the present index we are\\nhitting white space.\\nWhat denotes a word? In our algorithm each word is separated by one or\\nmore occurrences of white space. We don’t take into account any particular\\nsplitting symbols you may use, e.g. in .NETString.Split1 can take a char (or\\narray of characters) that determines a delimiter to use to split the characters\\nwithin the string into chunks of strings, resulting in an array of sub-strings.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 92, 'page_label': '93'}, page_content='array of characters) that determines a delimiter to use to split the characters\\nwithin the string into chunks of strings, resulting in an array of sub-strings.\\nIn Figure 11.2 we present a string indexed as an array. Typically the pattern\\nis the same for most words, delimited by a single occurrence of white space.\\nFigure 11.3 shows the same string, with the same number of words but with\\nvarying white space splitting them.\\n1http://msdn.microsoft.com/en-us/library/system.string.split.aspx'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 93, 'page_label': '94'}, page_content='CHAPTER 11. STRINGS 83\\n1) algorithm WordCount(value)\\n2) Pre: value ̸= ∅\\n3) Post: the number of words contained withinvalue is determined\\n4) inWord ← true\\n5) wordCount ← 0\\n6) index ← 0\\n7) // skip initial white space\\n8) while value[index] = whitespaceand index < value.Length −1\\n9) index ← index + 1\\n10) end while\\n11) // was the string just whitespace?\\n12) if index = value.Length and value[index] = whitespace\\n13) return 0\\n14) end if\\n15) while index < value.Length\\n16) if value[index] = whitespace\\n17) // skip all whitespace\\n18) while value[index] = whitespaceand index < value.Length −1\\n19) index ← index + 1\\n20) end while\\n21) inWord ← false\\n22) wordCount ← wordCount + 1\\n23) else\\n24) inWord ← true\\n25) end if\\n26) index ← index + 1\\n27) end while\\n28) // last word may have not been followed by whitespace\\n29) if inW ord\\n30) wordCount ← wordCount + 1\\n31) end if\\n32) return wordCount\\n33) end WordCount\\n11.4 Determining the number of repeated words\\nwithin a string'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 93, 'page_label': '94'}, page_content='29) if inW ord\\n30) wordCount ← wordCount + 1\\n31) end if\\n32) return wordCount\\n33) end WordCount\\n11.4 Determining the number of repeated words\\nwithin a string\\nWith the help of an unordered set, and an algorithm that can split the words\\nwithin a string using a speciﬁed delimiter this algorithm is straightforward to\\nimplement. If we split all the words using a single occurrence of white space\\nas our delimiter we get all the words within the string back as elements of\\nan array. Then if we iterate through these words adding them to a set which\\ncontains only unique strings we can attain the number of unique words from the\\nstring. All that is left to do is subtract the unique word count from the total\\nnumber of stings contained in the array returned from the split operation. The\\nsplit operation that we refer to is the same as that mentioned in§11.3.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 94, 'page_label': '95'}, page_content='CHAPTER 11. STRINGS 84\\nFigure 11.4: a) Undesireduniques set; b) desireduniques set\\n1) algorithm RepeatedWordCount(value)\\n2) Pre: value ̸= ∅\\n3) Post: the number of repeated words invalue is returned\\n4) words ← value.Split(’ ’)\\n5) uniques ← Set\\n6) foreach word in words\\n7) uniques.Add(word.Strip())\\n8) end foreach\\n9) return words.Length −uniques.Count\\n10) end RepeatedWordCount\\nYou will notice in theRepeatedWordCount algorithm that we use theStrip\\nmethod we referred to earlier in§11.1. This simply removes any punctuation\\nfrom a word. The reason we perform this operation on eachword is so that\\nwe can build a more accurate unique string collection, e.g. “test”, and “test!”\\nare the same word minus the punctuation. Figure 11.4 shows the undesired and\\ndesired sets for theunique set respectively.\\n11.5 Determining the ﬁrst matching character\\nbetween two strings\\nThe algorithm to determine whether any character of a string matches any of the'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 94, 'page_label': '95'}, page_content='desired sets for theunique set respectively.\\n11.5 Determining the ﬁrst matching character\\nbetween two strings\\nThe algorithm to determine whether any character of a string matches any of the\\ncharacters in another string is pretty trivial. Put simply, we can parse the strings\\nconsidered using a double loop and check, discarding punctuation, the equality\\nbetween any characters thus returning a non-negative index that represents the\\nlocation of the ﬁrst character in the match (Figure 11.5); otherwise we return\\n-1 if no match occurs. This approach exhibit a run time complexity ofO(n2).'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 95, 'page_label': '96'}, page_content='CHAPTER 11. STRINGS 85\\ntset\\n0 1 2 3 4\\nsretp\\n0 1 2 3 4 5 6\\nWord\\nMatch\\ni\\ntset\\n0 1 2 3 4\\nsretp\\n0 1 2 3 4 5 6\\ni\\nindex\\ntset\\n0 1 2 3 4\\nsretp\\n0 1 2 3 4 5 6\\ni\\nindexindex\\na) b) c)\\nFigure 11.5: a) First Step; b) Second Step c) Match Occurred\\n1) algorithm Any(word,match)\\n2) Pre: word, match ̸= ∅\\n3) Post: index representing match location if occured,−1 otherwise\\n4) for i ← 0 toword.Length − 1\\n5) while word[i] = whitespace\\n6) i ← i + 1\\n7) end while\\n8) for index ← 0 tomatch.Length − 1\\n9) while match[index] = whitespace\\n10) index ← index + 1\\n11) end while\\n12) if match[index] =word[i]\\n13) return index\\n14) end if\\n15) end for\\n16) end for\\n17) return −1\\n18) end Any\\n11.6 Summary\\nWe hope that the reader has seen how fun algorithms on string data types\\nare. Strings are probably the most common data type (and data structure -\\nremember we are dealing with an array) that you will work with so its important\\nthat you learn to be creative with them. We for one ﬁnd strings fascinating. A'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 95, 'page_label': '96'}, page_content='remember we are dealing with an array) that you will work with so its important\\nthat you learn to be creative with them. We for one ﬁnd strings fascinating. A\\nsimple Google search on string nuances between languages and encodings will\\nprovide you with a great number of problems. Now that we have spurred you\\nalong a little with our introductory algorithms you can devise some of your own.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 96, 'page_label': '97'}, page_content='Appendix A\\nAlgorithm Walkthrough\\nLearning how to design good algorithms can be assisted greatly by using a\\nstructured approach to tracing its behaviour. In most cases tracing an algorithm\\nonly requires a single table. In most cases tracing is not enough, you will also\\nwant to use a diagram of the data structure your algorithm operates on. This\\ndiagram will be used to visualise the problem more eﬀectively. Seeing things\\nvisually can help you understand the problem quicker, and better.\\nThe trace table will store information about the variables used in your algo-\\nrithm. The values within this table are constantly updated when the algorithm\\nmutates them. Such an approach allows you to attain a history of the various\\nvalues each variable has held. You may also be able to infer patterns from the\\nvalues each variable has contained so that you can make your algorithm more\\neﬃcient.\\nWe have found this approach both simple, and powerful. By combining a'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 96, 'page_label': '97'}, page_content='values each variable has contained so that you can make your algorithm more\\neﬃcient.\\nWe have found this approach both simple, and powerful. By combining a\\nvisual representation of the problem as well as having a history of past values\\ngenerated by the algorithm it can make understanding, and solving problems\\nmuch easier.\\nIn this chapter we will show you how to work through both iterative, and\\nrecursive algorithms using the technique outlined.\\nA.1 Iterative algorithms\\nWe will trace theIsPalindrome algorithm (deﬁned in §11.2) as our example\\niterative walkthrough. Before we even look at the variables the algorithm uses,\\nﬁrst we will look at the actual data structure the algorithm operates on. It\\nshould be pretty obvious that we are operating on a string, but how is this\\nrepresented? A string is essentially a block of contiguous memory that consists\\nof some char data types, one after the other. Each character in the string can'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 96, 'page_label': '97'}, page_content='represented? A string is essentially a block of contiguous memory that consists\\nof some char data types, one after the other. Each character in the string can\\nbe accessed via an index much like you would do when accessing items within\\nan array. The picture should be presenting itself - a string can be thought of as\\nan array of characters.\\nFor our example we will useIsPalindrome to operate on the string “Never\\nodd or even” Now we know how the string data structure is represented, and\\nthe value of the string we will operate on let’s go ahead and draw it as shown\\nin Figure A.1.\\n86'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 97, 'page_label': '98'}, page_content='APPENDIX A. ALGORITHM WALKTHROUGH 87\\nFigure A.1: Visualising the data structure we are operating on\\nvalue word left right\\nTable A.1: A column for each variable we wish to track\\nThe IsPalindrome algorithm uses the following list of variables in some form\\nthroughout its execution:\\n1. value\\n2. word\\n3. left\\n4. right\\nHaving identiﬁed the values of the variables we need to keep track of we\\nsimply create a column for each in a table as shown in Table A.1.\\nNow, using the IsPalindrome algorithm execute each statement updating\\nthe variable values in the table appropriately. Table A.2 shows the ﬁnal table\\nvalues for each variable used inIsPalindrome respectively.\\nWhile this approach may look a little bloated in print, on paper it is much\\nmore compact. Where we have the strings in the table you should annotate\\nthese strings with array indexes to aid the algorithm walkthrough.\\nThere is one other point that we should clarify at this time - whether to'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 97, 'page_label': '98'}, page_content='these strings with array indexes to aid the algorithm walkthrough.\\nThere is one other point that we should clarify at this time - whether to\\ninclude variables that change only a few times, or not at all in the trace table.\\nIn Table A.2 we have included both thevalue, and word variables because it\\nwas convenient to do so. You may ﬁnd that you want to promote these values\\nto a larger diagram (like that in Figure A.1) and only use the trace table for\\nvariables whose values change during the algorithm. We recommend that you\\npromote the core data structure being operated on to a larger diagram outside\\nof the table so that you can interrogate it more easily.\\nvalue word left right\\n“Never odd or even” “NEVERODDOREVEN” 0 13\\n1 12\\n2 11\\n3 10\\n4 9\\n5 8\\n6 7\\n7 6\\nTable A.2: Algorithm trace forIsPalindrome'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 98, 'page_label': '99'}, page_content='APPENDIX A. ALGORITHM WALKTHROUGH 88\\nWe cannot stress enough how important such traces are when designing\\nyour algorithm. You can use these trace tables to verify algorithm correctness.\\nAt the cost of a simple table, and quick sketch of the data structure you are\\noperating on you can devise correct algorithms quicker. Visualising the problem\\ndomain and keeping track of changing data makes problems a lot easier to solve.\\nMoreover you always have a point of reference which you can look back on.\\nA.2 Recursive Algorithms\\nFor the most part working through recursive algorithms is as simple as walking\\nthrough an iterative algorithm. One of the things that we need to keep track\\nof though is which method call returns to who. Most recursive algorithms are\\nmuch simple to follow when you draw out the recursive calls rather than using\\na table based approach. In this section we will use a recursive implementation\\nof an algorithm that computes a number from the Fiboncacci sequence.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 98, 'page_label': '99'}, page_content='a table based approach. In this section we will use a recursive implementation\\nof an algorithm that computes a number from the Fiboncacci sequence.\\n1) algorithm Fibonacci(n)\\n2) Pre: n is the number in the ﬁbonacci sequence to compute\\n3) Post: the ﬁbonacci sequence numbern has been computed\\n4) if n <1\\n5) return 0\\n6) else if n <2\\n7) return 1\\n8) end if\\n9) return Fibonacci(n − 1) + Fibonacci(n − 2)\\n10) end Fibonacci\\nBefore we jump into showing you a diagrammtic representation of the algo-\\nrithm calls for theFibonacci algorithm we will brieﬂy talk about the cases of\\nthe algorithm. The algorithm has three cases in total:\\n1. n <1\\n2. n <2\\n3. n ≥ 2\\nThe ﬁrst two items in the preceeding list are the base cases of the algorithm.\\nUntil we hit one of our base cases in our recursive method call tree we won’t\\nreturn anything. The third item from the list is our recursive case.\\nWith each call to the recursive case we etch ever closer to one of our base'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 98, 'page_label': '99'}, page_content='return anything. The third item from the list is our recursive case.\\nWith each call to the recursive case we etch ever closer to one of our base\\ncases. Figure A.2 shows a diagrammtic representation of the recursive call chain.\\nIn Figure A.2 the order in which the methods are called are labelled. Figure\\nA.3 shows the call chain annotated with the return values of each method call\\nas well as the order in which methods return to their callers. In Figure A.3 the\\nreturn values are represented as annotations to the red arrows.\\nIt is important to note that each recursive call only ever returns to its caller\\nupon hitting one of the two base cases. When you do eventually hit a base case\\nthat branch of recursive calls ceases. Upon hitting a base case you go back to'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 99, 'page_label': '100'}, page_content='APPENDIX A. ALGORITHM WALKTHROUGH 89\\nFigure A.2: Call chain forFibonacci algorithm\\nFigure A.3: Return chain forFibonacci algorithm'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 100, 'page_label': '101'}, page_content='APPENDIX A. ALGORITHM WALKTHROUGH 90\\nthe caller and continue execution of that method. Execution in the caller is\\ncontiued at the next statement, or expression after the recursive call was made.\\nIn the Fibonacci algorithms’ recursive case we make two recursive calls.\\nWhen the ﬁrst recursive call (Fibonacci(n − 1)) returns to the caller we then\\nexecute the the second recursive call (Fibonacci(n − 2)). After both recursive\\ncalls have returned to their caller, the caller can then subesequently return to\\nits caller and so on.\\nRecursive algorithms are much easier to demonstrate diagrammatically as\\nFigure A.2 demonstrates. When you come across a recursive algorithm draw\\nmethod call diagrams to understand how the algorithm works at a high level.\\nA.3 Summary\\nUnderstanding algorithms can be hard at times, particularly from an implemen-\\ntation perspective. In order to understand an algorithm try and work through\\nit using trace tables. In cases where the algorithm is also recursive sketch the'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 100, 'page_label': '101'}, page_content='tation perspective. In order to understand an algorithm try and work through\\nit using trace tables. In cases where the algorithm is also recursive sketch the\\nrecursive calls out so you can visualise the call/return chain.\\nIn the vast majority of cases implementing an algorithm is simple provided\\nthat you know how the algorithm works. Mastering how an algorithm works\\nfrom a high level is key for devising a well designed solution to the problem in\\nhand.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 101, 'page_label': '102'}, page_content='Appendix B\\nTranslation Walkthrough\\nThe conversion from pseudo to an actual imperative language is usually very\\nstraight forward, to clarify an example is provided. In this example we will\\nconvert the algorithm in§9.1 to the C# language.\\n1) public static bool IsPrime(int number)\\n2) {\\n3) if (number < 2)\\n4) {\\n5) return false;\\n6) }\\n7) int innerLoopBound = (int)Math.Floor(Math.Sqrt(number));\\n8) for (int i = 1; i < number; i++)\\n9) {\\n10) for(int j = 1; j <= innerLoopBound; j++)\\n11) {\\n12) if (i ∗ j == number)\\n13) {\\n14) return false;\\n15) }\\n16) }\\n17) }\\n18) return true;\\n19) }\\nFor the most part the conversion is a straight forward process, however you\\nmay have to inject various calls to other utility algorithms to ascertain the\\ncorrect result.\\nA consideration to take note of is that many algorithms have fairly strict\\npreconditions, of which there may be several - in these scenarios you will need\\nto inject the correct code to handle such situations to preserve the correctness of'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 101, 'page_label': '102'}, page_content='preconditions, of which there may be several - in these scenarios you will need\\nto inject the correct code to handle such situations to preserve the correctness of\\nthe algorithm. Most of the preconditions can be suitably handled by throwing\\nthe correct exception.\\n91'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 102, 'page_label': '103'}, page_content='APPENDIX B. TRANSLATION WALKTHROUGH 92\\nB.1 Summary\\nAs you can see from the example used in this chapter we have tried to make the\\ntranslation of our pseudo code algorithms to mainstream imperative languages\\nas simple as possible.\\nWhenever you encounter a keyword within our pseudo code examples that\\nyou are unfamiliar with just browse to Appendix E which descirbes each key-\\nword.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 103, 'page_label': '104'}, page_content='Appendix C\\nRecursive Vs. Iterative\\nSolutions\\nOne of the most succinct properties of modern programming languages like\\nC++, C#, and Java (as well as many others) is that these languages allow\\nyou to deﬁne methods that reference themselves, such methods are said to be\\nrecursive. One of the biggest advantages recursive methods bring to the table is\\nthat they usually result in more readable, and compact solutions to problems.\\nA recursive method then is one that is deﬁned in terms of itself. Generally\\na recursive algorithms has two main properties:\\n1. One or more base cases; and\\n2. A recursive case\\nFor now we will brieﬂy cover these two aspects of recursive algorithms. With\\neach recursive call we should be making progress to our base case otherwise we\\nare going to run into trouble. The trouble we speak of manifests itself typically\\nas a stack overﬂow, we will describe why later.\\nNow that we have brieﬂy described what a recursive algorithm is and why'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 103, 'page_label': '104'}, page_content='as a stack overﬂow, we will describe why later.\\nNow that we have brieﬂy described what a recursive algorithm is and why\\nyou might want to use such an approach for your algorithms we will now talk\\nabout iterative solutions. An iterative solution uses no recursion whatsoever.\\nAn iterative solution relies only on the use of loops (e.g. for, while, do-while,\\netc). The down side to iterative algorithms is that they tend not to be as clear\\nas to their recursive counterparts with respect to their operation. The major\\nadvantage of iterative solutions is speed. Most production software you will\\nﬁnd uses little or no recursive algorithms whatsoever. The latter property can\\nsometimes be a companies prerequisite to checking in code, e.g. upon checking\\nin a static analysis tool may verify that the code the developer is checking in\\ncontains no recursive algorithms. Normally it is systems level code that has this\\nzero tolerance policy for recursive algorithms.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 103, 'page_label': '104'}, page_content='contains no recursive algorithms. Normally it is systems level code that has this\\nzero tolerance policy for recursive algorithms.\\nUsing recursion should always be reserved for fast algorithms, you should\\navoid it for the following algorithm run time deﬁciencies:\\n1. O(n2)\\n2. O(n3)\\n93'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 104, 'page_label': '105'}, page_content='APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS 94\\n3. O(2n)\\nIf you use recursion for algorithms with any of the above run time eﬃciency’s\\nyou are inviting trouble. The growth rate of these algorithms is high and in\\nmost cases such algorithms will lean very heavily on techniques like divide and\\nconquer. While constantly splitting problems into smaller problems is good\\npractice, in these cases you are going to be spawning a lot of method calls. All\\nthis overhead (method calls don’t comethat cheap) will soon pile up and either\\ncause your algorithm to run a lot slower than expected, or worse, you will run\\nout of stack space. When you exceed the allotted stack space for a thread the\\nprocess will be shutdown by the operating system. This is the case irrespective\\nof the platform you use, e.g. .NET, or native C++ etc. You can ask for a bigger\\nstack size, but you typically only want to do this if you have a very good reason\\nto do so.\\nC.1 Activation Records'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 104, 'page_label': '105'}, page_content='of the platform you use, e.g. .NET, or native C++ etc. You can ask for a bigger\\nstack size, but you typically only want to do this if you have a very good reason\\nto do so.\\nC.1 Activation Records\\nAn activation record is created every time you invoke a method. Put simply\\nan activation record is something that is put on the stack to support method\\ninvocation. Activation records take a small amount of time to create, and are\\npretty lightweight.\\nNormally an activation record for a method call is as follows (this is very\\ngeneral):\\n• The actual parameters of the method are pushed onto the stack\\n• The return address is pushed onto the stack\\n• The top-of-stack index is incremented by the total amount of memory\\nrequired by the local variables within the method\\n• A jump is made to the method\\nIn many recursive algorithms operating on large data structures, or algo-\\nrithms that are ineﬃcient you will run out of stack space quickly. Consider an'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 104, 'page_label': '105'}, page_content='• A jump is made to the method\\nIn many recursive algorithms operating on large data structures, or algo-\\nrithms that are ineﬃcient you will run out of stack space quickly. Consider an\\nalgorithm that when invoked given a speciﬁc value it creates many recursive\\ncalls. In such a case a big chunk of the stack will be consumed. We will have to\\nwait until the activation records start to be unwound after the nested methods\\nin the call chain exit and return to their respective caller. When a method exits\\nit’s activation record is unwound. Unwinding an activation record results in\\nseveral steps:\\n1. The top-of-stack index is decremented by the total amount of memory\\nconsumed by the method\\n2. The return address is popped oﬀ the stack\\n3. The top-of-stack index is decremented by the total amount of memory\\nconsumed by the actual parameters'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 105, 'page_label': '106'}, page_content='APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS 95\\nWhile activation records are an eﬃcient way to support method calls they\\ncan build up very quickly. Recursive algorithms can exhaust the stack size\\nallocated to the thread fairly fast given the chance.\\nJust about now we should be dusting the cobwebs oﬀ the age old example of\\nan iterative vs. recursive solution in the form of the Fibonacci algorithm. This\\nis a famous example as it highlights both the beauty and pitfalls of a recursive\\nalgorithm. The iterative solution is not as pretty, nor self documenting but it\\ndoes the job a lot quicker. If we were to give the Fibonacci algorithm an input\\nof say 60 then we would have to wait a while to get the value back because it\\nhas an O(gn) run time. The iterative version on the other hand has aO(n)\\nrun time. Don’t let this put you oﬀ recursion. This example is mainly used\\nto shock programmers into thinking about the ramiﬁcations of recursion rather\\nthan warning them oﬀ.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 105, 'page_label': '106'}, page_content='run time. Don’t let this put you oﬀ recursion. This example is mainly used\\nto shock programmers into thinking about the ramiﬁcations of recursion rather\\nthan warning them oﬀ.\\nC.2 Some problems are recursive in nature\\nSomething that you may come across is that some data structures and algo-\\nrithms are actually recursive in nature. A perfect example of this is a tree data\\nstructure. A common tree node usually contains a value, along with two point-\\ners to two other nodes of the same node type. As you can see tree is recursive\\nin its makeup wit each node possibly pointing to two other nodes.\\nWhen using recursive algorithms on tree’s it makes sense as you are simply\\nadhering to the inherent design of the data structure you are operating on. Of\\ncourse it is not all good news, after all we are still bound by the limitations we\\nhave mentioned previously in this chapter.\\nWe can also look at sorting algorithms like merge sort, and quick sort. Both'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 105, 'page_label': '106'}, page_content='have mentioned previously in this chapter.\\nWe can also look at sorting algorithms like merge sort, and quick sort. Both\\nof these algorithms are recursive in their design and so it makes sense to model\\nthem recursively.\\nC.3 Summary\\nRecursion is a powerful tool, and one that all programmers should know of.\\nOften software projects will take a trade between readability, and eﬃciency in\\nwhich case recursion is great provided you don’t go and use it to implement\\nan algorithm with a quadratic run time or higher. Of course this is not a rule\\nof thumb, this is just us throwing caution to the wind. Defensive coding will\\nalways prevail.\\nMany times recursion has a natural home in recursive data structures and\\nalgorithms which are recursive in nature. Using recursion in such scenarios is\\nperfectly acceptable. Using recursion for something like linked list traversal is\\na little overkill. Its iterative counterpart is probably less lines of code than its\\nrecursive counterpart.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 105, 'page_label': '106'}, page_content='perfectly acceptable. Using recursion for something like linked list traversal is\\na little overkill. Its iterative counterpart is probably less lines of code than its\\nrecursive counterpart.\\nBecause we can only talk about the implications of using recursion from an\\nabstract point of view you should consult your compiler and run time environ-\\nment for more details. It may be the case that your compiler recognises things\\nlike tail recursion and can optimise them. This isn’t unheard of, in fact most\\ncommercial compilers will do this. The amount of optimisation compilers can'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 106, 'page_label': '107'}, page_content='APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS 96\\ndo though is somewhat limited by the fact that you are still using recursion.\\nYou, as the developer have to accept certain accountability’s for performance.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 107, 'page_label': '108'}, page_content='Appendix D\\nTesting\\nTesting is an essential part of software development. Testing has often been\\ndiscarded by many developers in the belief that the burden of proof of their\\nsoftware is on those within the company who hold test centric roles. This\\ncouldn’t be further from the truth. As a developer you should at least provide\\na suite of unit tests that verify certain boundary conditions of your software.\\nA great thing about testing is that you build up progressively a safety net. If\\nyou add or tweak algorithms and then run your suite of tests you will be quickly\\nalerted to any cases that you have broken with your recent changes. Such a suite\\nof tests in any sizeable project is absolutely essential to maintaining a fairly high\\nbar when it comes to quality. Of course in order to attain such a standard you\\nneed to think carefully about the tests that you construct.\\nUnit testing which will be the subject of the vast majority of this chapter'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 107, 'page_label': '108'}, page_content='need to think carefully about the tests that you construct.\\nUnit testing which will be the subject of the vast majority of this chapter\\nare widely available on most platforms. Most modern languages like C++, C#,\\nand Java oﬀer an impressive catalogue of testing frameworks that you can use\\nfor unit testing.\\nThe following list identiﬁes testing frameworks which are popular:\\nJUnit: Targeted at Jav.,http://www.junit.org/\\nNUnit: Can be used with languages that target Microsoft’s Common Language\\nRuntime. http://www.nunit.org/index.php\\nBoost Test Library:Targeted at C++. The test library that ships with the incredibly popular\\nBoost libraries.http://www.boost.org. A direct link to the libraries doc-\\numentation http://www.boost.org/doc/libs/1_36_0/libs/test/doc/\\nhtml/index.html\\nCppUnit: Targeted at C++.http://cppunit.sourceforge.net/\\nDon’t worry if you think that the list is very sparse, there are far more on\\noﬀer than those that we have listed. The ones listed are the testing frameworks'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 107, 'page_label': '108'}, page_content='Don’t worry if you think that the list is very sparse, there are far more on\\noﬀer than those that we have listed. The ones listed are the testing frameworks\\nthat we believe are the most popular for C++, C#, and Java.\\nD.1 What constitutes a unit test?\\nA unit test should focus on a single atomic property of the subject being tested.\\nDo not try and test many things at once, this will result in a suite of somewhat\\n97'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 108, 'page_label': '109'}, page_content='APPENDIX D. TESTING 98\\nunstructured tests. As an example if you were wanting to write a test that\\nveriﬁed that a particular valueV is returned from a speciﬁc inputI then your\\ntest should do the smallest amount of work possible to verify thatV is correct\\ngiven I. A unit test should be simple and self describing.\\nAs well as a unit test being relatively atomic you should also make sure that\\nyour unit tests execute quickly. If you can imagine in the future when you may\\nhave a test suite consisting of thousands of tests you want those tests to execute\\nas quickly as possible. Failure to attain such a goal will most likely result in\\nthe suite of tests not being ran that often by the developers on your team. This\\ncan occur for a number of reasons but the main one would be that it becomes\\nincredibly tedious waiting several minutes to run tests on a developers local\\nmachine.\\nBuilding up a test suite can help greatly in a team scenario, particularly'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 108, 'page_label': '109'}, page_content='incredibly tedious waiting several minutes to run tests on a developers local\\nmachine.\\nBuilding up a test suite can help greatly in a team scenario, particularly\\nwhen using a continuous build server. In such a scenario you can have the suite\\nof tests devised by the developers and testers ran as part of the build process.\\nEmploying such strategies can help you catch niggling little error cases early\\nrather than via your customer base. There is nothing more embarrassing for a\\ndeveloper than to have a very trivial bug in their code reported to them from a\\ncustomer.\\nD.2 When should I write my tests?\\nA source of great debate would be an understatement to personify such a ques-\\ntion as this. In recent years a test driven approach to development has become\\nvery popular. Such an approach is known as test driven development, or more\\ncommonly the acronym TDD.\\nOne of the founding principles of TDD is to write the unit test ﬁrst, watch'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 108, 'page_label': '109'}, page_content='very popular. Such an approach is known as test driven development, or more\\ncommonly the acronym TDD.\\nOne of the founding principles of TDD is to write the unit test ﬁrst, watch\\nit fail and then make it pass. The premise being that you only ever write\\nenough code at any one time to satisfy the state based assertions made in a unit\\ntest. We have found this approach to provide a more structured intent to the\\nimplementation of algorithms. At any one stage you only have a single goal, to\\nmake the failing test pass. Because TDD makes you write the tests up front you\\nnever ﬁnd yourself in a situation where you forget, or can’t be bothered to write\\ntests for your code. This is often the case when you write your tests after you\\nhave coded up your implementation. We, as the authors of this book ourselves\\nuse TDD as our preferred method.\\nAs we have already mentioned that TDD is our favoured approach to testing\\nit would be somewhat of an injustice to not list, and describe the mantra that'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 108, 'page_label': '109'}, page_content='use TDD as our preferred method.\\nAs we have already mentioned that TDD is our favoured approach to testing\\nit would be somewhat of an injustice to not list, and describe the mantra that\\nis often associate with it:\\nRed: Signiﬁes that the test has failed.\\nGreen: The failing test now passes.\\nRefactor: Can we restructure our program so it makes more sense, and easier to\\nmaintain?\\nThe ﬁrst point of the above list always occurs at least once (more if you count\\nthe build error) in TDD initially. Your task at this stage is solely to make the\\ntest pass, that is to make the respective test green. The last item is based around'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 109, 'page_label': '110'}, page_content='APPENDIX D. TESTING 99\\nthe restructuring of your program to make it as readable and maintainable as\\npossible. The last point is very important as TDD is a progressive methodology\\nto building a solution. If you adhere to progressive revisions of your algorithm\\nrestructuring when appropriate you will ﬁnd that using TDD you can implement\\nvery cleanly structured types and so on.\\nD.3 How seriously should I view my test suite?\\nYour tests are a major part of your project ecosystem and so they should be\\ntreated with the same amount of respect as your production code. This ranges\\nfrom correct, and clean code formatting, to the testing code being stored within\\na source control repository.\\nEmploying a methodology like TDD, or testing after implementing you will\\nﬁnd that you spend a great amount of time writing tests and thus they should\\nbe treated no diﬀerently to your production code. All tests should be clearly\\nnamed, and fully documented as to their intent.\\nD.4 The three A’s'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 109, 'page_label': '110'}, page_content='be treated no diﬀerently to your production code. All tests should be clearly\\nnamed, and fully documented as to their intent.\\nD.4 The three A’s\\nNow that you have a sense of the importance of your test suite you will inevitably\\nwant to know how to actually structure each block of imperatives within a single\\nunit test. A popular approach - the three A’s is described in the following list:\\nAssemble: Create the objects you require in order to perform the state based asser-\\ntions.\\nAct: Invoke the respective operations on the objects you have assembled to\\nmutate the state to that desired for your assertions.\\nAssert: Specify what you expect to hold after the previous two steps.\\nThe following example shows a simple test method that employs the three\\nA’s:\\npublic void MyTest()\\n{\\n// assemble\\nType t = new Type();\\n// act\\nt.MethodA();\\n// assert\\nAssert.IsTrue(t.BoolExpr)\\n}\\nD.5 The structuring of tests\\nStructuring tests can be viewed upon as being the same as structuring pro-'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 109, 'page_label': '110'}, page_content='{\\n// assemble\\nType t = new Type();\\n// act\\nt.MethodA();\\n// assert\\nAssert.IsTrue(t.BoolExpr)\\n}\\nD.5 The structuring of tests\\nStructuring tests can be viewed upon as being the same as structuring pro-\\nduction code, e.g. all unit tests for aPerson type may be contained within'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 110, 'page_label': '111'}, page_content='APPENDIX D. TESTING 100\\na PersonTest type. Typically all tests are abstracted from production code.\\nThat is that the tests are disjoint from the production code, you may have two\\ndynamic link libraries (dll); the ﬁrst containing the production code, the second\\ncontaining your test code.\\nWe can also use things like inheritance etc when deﬁning classes of tests.\\nThe point being that the test code is very much like your production code and\\nyou should apply the same amount of thought to its structure as you would do\\nthe production code.\\nD.6 Code Coverage\\nSomething that you can get as a product of unit testing are code coverage\\nstatistics. Code coverage is merely an indicator as to the portions of production\\ncode that your units tests cover. Using TDD it is likely that your code coverage\\nwill be very high, although it will vary depending on how easy it is to use TDD\\nwithin your project.\\nD.7 Summary\\nTesting is key to the creation of a moderately stable product. Moreover unit'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 110, 'page_label': '111'}, page_content='will be very high, although it will vary depending on how easy it is to use TDD\\nwithin your project.\\nD.7 Summary\\nTesting is key to the creation of a moderately stable product. Moreover unit\\ntesting can be used to create a safety blanket when adding and removing features\\nproviding an early warning for breaking changes within your production code.'),\n",
       " Document(metadata={'source': 'Data\\\\Dsa.pdf', 'page': 111, 'page_label': '112'}, page_content='Appendix E\\nSymbol Deﬁnitions\\nThroughout the pseudocode listings you will ﬁnd several symbols used, describes\\nthe meaning of each of those symbols.\\nSymbol Description\\n← Assignment.\\n= Equality.\\n≤ Less than or equal to.\\n< Less than.*\\n≥ Greater than or equal to.\\n> Greater than.*\\n̸= Inequality.\\n∅ Null.\\nand Logical and.\\nor Logical or.\\nwhitespace Single occurrence of whitespace.\\nyield Like return but builds a sequence.\\nTable E.1: Pseudo symbol deﬁnitions\\n* This symbol has a direct translation with the vast majority of imperative\\ncounterparts.\\n101'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 0, 'page_label': '1'}, page_content='SQL(NotesbyApnaCollege)\\nWhatisDatabase?Databaseisacollectionofinterrelateddata.\\nWhatisDBMS?DBMS(DatabaseManagement System)issoftwareusedtocreate,manage,andorganizedatabases.\\nWhatisRDBMS?● RDBMS(RelationalDatabaseManagement System)-isaDBMSbasedontheconceptoftables(alsocalledrelations).● Dataisorganizedintotables(alsoknownasrelations)withrows(records)andcolumns(attributes).● Eg-MySQL,PostgreSQL,Oracleetc.\\nWhatisSQL?SQLisStructuredQueryLanguage-usedtostore,manipulateandretrievedatafromRDBMS.(Itisnotadatabase,itisalanguageusedtointeractwithdatabase)\\nWeuseSQLforCRUDOperations:● CREATE-Tocreatedatabases,tables,inserttuplesintablesetc● READ-Toreaddatapresentinthedatabase.● UPDATE-Modifyalreadyinserteddata.● DELETE-Deletedatabase,tableorspecificdatapoint/tuple/rowormultiplerows.\\n*Note-SQLkeywordsareNOTcasesensitive.Eg:selectisthesameasSELECTinSQL.\\nSQLv/sMySQLSQLisalanguageusedtoperformCRUDoperationsinRelationalDB,whileMySQLisaRDBMSthatusesSQL.'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 1, 'page_label': '2'}, page_content='SQLDataTypesInSQL,datatypesdefinethekindofdatathatcanbestoredinacolumnorvariable.\\nToSeealldatatypesofMYSQL,visit:https://dev.mysql.com/doc/refman/8.0/en/data-types.html\\nHerearethefrequentlyusedSQLdatatypes:\\nDATATYPE DESCRIPTION USAGE\\nCHAR string(0-255),canstorecharactersoffixedlength CHAR(50)\\nVARCHAR string(0-255),canstorecharactersuptogivenlength VARCHAR(50)\\nBLOB string(0-65535),canstorebinarylargeobject BLOB(1000)\\nINT integer(-2,147,483,648to2,147,483,647) INT\\nTINYINT integer(-128to127) TINYINT\\nBIGINT integer(-9,223,372,036,854,775,808to9,223,372,036,854,775,807)\\nBIGINT\\nBIT canstorex-bitvalues.xcanrangefrom1to64 BIT(2)\\nFLOAT Decimalnumber-withprecisionto23digits FLOAT\\nDOUBLE Decimalnumber-with24to53digits DOUBLE\\nBOOLEAN Booleanvalues0or1 BOOLEAN\\nDATE dateinformatofYYYY-MM-DDrangingfrom1000-01-01to9999-12-31\\nDATE\\nTIME HH:MM:SS TIME\\nYEAR yearin4digitsformatrangingfrom1901to2155 YEAR'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 1, 'page_label': '2'}, page_content='BOOLEAN Booleanvalues0or1 BOOLEAN\\nDATE dateinformatofYYYY-MM-DDrangingfrom1000-01-01to9999-12-31\\nDATE\\nTIME HH:MM:SS TIME\\nYEAR yearin4digitsformatrangingfrom1901to2155 YEAR\\n*Note-CHARisforfixedlength&VARCHARisforvariablelengthstrings.Generally,VARCHARisbetterasitonlyoccupiesnecessarymemory&worksmoreefficiently.\\nWecanalsouseUNSIGNEDwithdatatypeswhenweonlyhavepositivevaluestoadd.Eg-UNSIGNEDINT\\nTypesofSQLCommands:'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 2, 'page_label': '3'}, page_content='1. DQL(DataQueryLanguage):Usedtoretrievedatafromdatabases.(SELECT)\\n2. DDL(DataDefinitionLanguage):Usedtocreate,alter,anddeletedatabaseobjectsliketables,indexes,etc.(CREATE,DROP,ALTER,RENAME,TRUNCATE)\\n3. DML(DataManipulationLanguage):Usedtomodifythedatabase.(INSERT,UPDATE,DELETE)\\n4. DCL(DataControl Language):Usedtogrant&revokepermissions.(GRANT,REVOKE)\\n5. TCL(TransactionControl Language):Usedtomanagetransactions.(COMMIT,ROLLBACK,STARTTRANSACTIONS,SAVEPOINT)\\n1. DataDefinitionLanguage(DDL)\\nDataDefinitionLanguage(DDL)isasubsetofSQL(StructuredQueryLanguage)responsiblefordefiningandmanagingthestructureofdatabasesandtheirobjects.\\nDDLcommandsenableyoutocreate,modify,anddeletedatabaseobjectsliketables,indexes,constraints,andmore.\\nKeyDDLCommandsare:\\n● CREATETABLE:\\n○ Usedtocreateanewtableinthedatabase.○ Specifiesthetablename,columnnames,datatypes,constraints,andmore.○ Example:CREATETABLEemployees(idINTPRIMARYKEY,nameVARCHAR(50),salaryDECIMAL(10,2));\\n● ALTERTABLE:'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 2, 'page_label': '3'}, page_content='● ALTERTABLE:\\n○ Usedtomodifythestructureofanexistingtable.○ Youcanadd,modify,ordropcolumns,constraints,andmore.○ Example:ALTERTABLEemployeesADDCOLUMNemailVARCHAR(100);\\n● DROPTABLE:\\n○ Usedtodeleteanexistingtablealongwithitsdataandstructure.○ Example:DROPTABLEemployees;'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 3, 'page_label': '4'}, page_content='● CREATEINDEX:\\n○ Usedtocreateanindexononeormorecolumnsinatable.○ Improvesqueryperformancebyenablingfasterdataretrieval.○ Example:CREATEINDEXidx_employee_nameONemployees(name);\\n● DROPINDEX:\\n○ Usedtoremoveanexistingindexfromatable.○ Example:DROPINDEXidx_employee_name;\\n● CREATECONSTRAINT:\\n○ Usedtodefineconstraintsthatensuredataintegrity.○ ConstraintsincludePRIMARYKEY,FOREIGNKEY,UNIQUE,NOTNULL,andCHECK.○ Example:ALTERTABLEordersADDCONSTRAINTfk_customerFOREIGNKEY(customer_id)REFERENCEScustomers(id);\\n● DROPCONSTRAINT:\\n○ Usedtoremoveanexistingconstraintfromatable.○ Example:ALTERTABLEordersDROPCONSTRAINTfk_customer;\\n● TRUNCATETABLE:\\n○ Usedtodeletethedatainsideatable,butnotthetableitself.○ Syntax–TRUNCATETABLEtable_name\\n2. DATAQUERY/RETRIEVALLANGUAGE(DQLorDRL)\\nDQL(DataQueryLanguage)isasubsetofSQLfocusedonretrievingdatafromdatabases.\\nTheSELECTstatementisthefoundationofDQLandallowsustoextractspecificcolumnsfromatable.\\n● SELECT:\\nTheSELECTstatementisusedtoselectdatafromadatabase.'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 4, 'page_label': '5'}, page_content=\"Syntax: SELECTcolumn1,column2,...FROMtable_name;\\nHere,column1,column2,...arethefieldnamesofthetable.\\nIfyouwanttoselectallthefieldsavailableinthetable,usethefollowingsyntax:SELECT*FROMtable_name;\\nEx:SELECTCustomerName,CityFROMCustomers;\\n● WHERE:\\nTheWHEREclauseisusedtofilterrecords.\\nSyntax:SELECTcolumn1,column2,...FROMtable_nameWHEREcondition;\\nEx:SELECT*FROMCustomersWHERECountry='Mexico';\\nOperatorsusedinWHEREare:\\n= :Equal> :Greaterthan< :Lessthan>=:Greaterthanorequal<=:Lessthanorequal<>:Notequal.\\nNote:InsomeversionsofSQLthisoperatormaybewrittenas!=\\n● AND,ORandNOT:\\n- TheWHEREclausecanbecombinedwithAND,OR,andNOToperators.\\n- TheANDandORoperatorsareusedtofilterrecordsbasedonmorethanonecondition:\\n- TheANDoperatordisplaysarecordifalltheconditionsseparatedbyANDareTRUE.\\n- TheORoperatordisplaysarecordifanyoftheconditionsseparatedbyORisTRUE.\\n- TheNOToperatordisplaysarecordifthecondition(s)isNOTTRUE.\\nSyntax:\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 5, 'page_label': '6'}, page_content='SELECTcolumn1,column2,...FROMtable_nameWHEREcondition1ANDcondition2ANDcondition3...;\\nSELECTcolumn1,column2,...FROMtable_nameWHEREcondition1ORcondition2ORcondition3...;\\nSELECTcolumn1,column2,...FROMtable_nameWHERENOTcondition;\\nExample:\\nSELECT*FROMCustomersWHERECountry=’India’ANDCity=’Japan’;\\nSELECT*FROMCustomersWHERECountry=’America’AND(City=’India’ORCity=’Korea’);\\n● DISTINCT:\\nRemovesduplicaterowsfromqueryresults.\\nSyntax:SELECTDISTINCTcolumn1,column2FROMtable_name;\\n● LIKE:\\nTheLIKEoperatorisusedinaWHEREclausetosearchforaspecifiedpatterninacolumn.\\nTherearetwowildcardsoftenusedinconjunctionwiththeLIKEoperator:\\n- Thepercentsign(%)representszero,one,ormultiplecharacters- Theunderscoresign(_)representsone,singlecharacter\\nExample:SELECT*FROMemployeesWHEREfirst_nameLIKE\\'J%\\';\\nWHERECustomerNameLIKE\\'a%\\'- Findsanyvaluesthatstartwith\"a\"\\nWHERECustomerNameLIKE\\'%a\\'- Findsanyvaluesthatendwith\"a\"\\nWHERECustomerNameLIKE\\'%or%\\'- Findsanyvaluesthathave\"or\"inanyposition'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 5, 'page_label': '6'}, page_content='WHERECustomerNameLIKE\\'a%\\'- Findsanyvaluesthatstartwith\"a\"\\nWHERECustomerNameLIKE\\'%a\\'- Findsanyvaluesthatendwith\"a\"\\nWHERECustomerNameLIKE\\'%or%\\'- Findsanyvaluesthathave\"or\"inanyposition\\nWHERECustomerNameLIKE\\'_r%\\'- Findsanyvaluesthathave\"r\"inthesecondposition'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 6, 'page_label': '7'}, page_content='WHERECustomerNameLIKE\\'a_%\\'- Findsanyvaluesthatstartwith\"a\"andareatleast2charactersinlength\\nWHERECustomerNameLIKE\\'a__%\\'- Findsanyvaluesthatstartwith\"a\"andareatleast3charactersinlength\\nWHEREContactNameLIKE\\'a%o\\'- Findsanyvaluesthatstartwith\"a\"andendswith\"o\"\\n● IN:\\nFiltersresultsbasedonalistofvaluesintheWHEREclause.\\nExample:SELECT*FROMproductsWHEREcategory_idIN(1,2,3);\\n● BETWEEN:\\nFiltersresultswithinaspecifiedrangeintheWHEREclause.\\nExample:SELECT*FROMordersWHEREorder_dateBETWEEN\\'2023-01-01\\'AND\\'2023-06-30\\';\\n● ISNULL:\\nChecksforNULLvaluesintheWHEREclause.\\nExample:SELECT*FROMcustomersWHEREemailISNULL;\\n● AS:\\nRenamescolumnsorexpressionsinqueryresults.\\nExample:SELECTfirst_nameAS\"FirstName\",last_nameAS\"LastName\"FROMemployees;\\n● ORDERBY\\nTheORDERBYclauseallowsyoutosorttheresultsetofaquerybasedononeormorecolumns.\\nBasicSyntax:\\n- TheORDERBYclauseisusedaftertheSELECTstatementtosortqueryresults.'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 7, 'page_label': '8'}, page_content=\"- Syntax:SELECTcolumn1,column2FROMtable_nameORDERBYcolumn1[ASC|DESC];\\nAscendingandDescendingOrder:\\n- Bydefault,theORDERBYclausesortsinascendingorder(smallesttolargest).- YoucanexplicitlyspecifydescendingorderusingtheDESCkeyword.- Example:SELECTproduct_name,priceFROMproductsORDERBYpriceDESC;\\nSortingbyMultipleColumns:\\n- YoucansortbymultiplecolumnsbylistingthemsequentiallyintheORDERBYclause.- Rowsarefirstsortedbasedonthefirstcolumn,andforrowswithequalvalues,subsequentcolumnsareusedforfurthersorting.- Example:SELECTfirst_name,last_nameFROMemployeesORDERBYlast_name,first_name;\\nSortingbyExpressions:\\n- It'spossibletosortbycalculatedexpressions,notjustcolumnvalues.- Example:SELECTproduct_name,price,price*1.1ASdiscounted_priceFROMproductsORDERBYdiscounted_price;\\nSortingNULLValues:\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 7, 'page_label': '8'}, page_content=\"- It'spossibletosortbycalculatedexpressions,notjustcolumnvalues.- Example:SELECTproduct_name,price,price*1.1ASdiscounted_priceFROMproductsORDERBYdiscounted_price;\\nSortingNULLValues:\\n- Bydefault,NULLvaluesareconsideredthesmallestinascendingorderandthelargestindescendingorder.- YoucancontrolthesortingbehaviourofNULLvaluesusingtheNULLSFIRSTorNULLSLASToptions.- Example:SELECTcolumn_nameFROMtable_nameORDERBYcolumn_nameNULLSLAST;\\nSortingbyPosition:\\n- Insteadofspecifyingcolumnnames,youcansortbycolumnpositionsintheORDERBYclause.- Example:SELECTproduct_name,priceFROMproductsORDERBY2DESC,1ASC;\\n● GROUPBY\\nTheGROUPBYclauseinSQLisusedtogrouprowsfromatablebasedononeormorecolumns.\\nSyntax:\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 8, 'page_label': '9'}, page_content=\"- TheGROUPBYclausefollowstheSELECTstatementandisusedtogrouprowsbasedonspecifiedcolumns.\\n- Syntax:SELECTcolumn1,aggregate_function(column2)FROMtable_nameGROUPBYcolumn1;\\n- AggregationFunctions:○ Aggregationfunctions(e.g.,COUNT,SUM,AVG,MAX,MIN)areoftenusedwithGROUPBYtocalculatevaluesforeachgroup.○ Example:SELECTdepartment,AVG(salary)FROMemployeesGROUPBYdepartment;- GroupingbyMultipleColumns:\\n○ YoucangroupbymultiplecolumnsbylistingthemintheGROUPBYclause.○ Thiscreatesahierarchicalgroupingbasedonthespecifiedcolumns.○ Example:SELECTdepartment,gender,AVG(salary)FROMemployeesGROUPBYdepartment,gender;\\n- HAVINGClause:\\n○ TheHAVINGclauseisusedwithGROUPBYtofiltergroupsbasedonaggregatefunctionresults.○ It'ssimilartotheWHEREclausebutoperatesongroupeddata.○ Example:SELECTdepartment,AVG(salary)FROMemployeesGROUPBYdepartmentHAVINGAVG(salary)>50000;\\n- CombiningGROUPBYandORDERBY:\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 8, 'page_label': '9'}, page_content='- CombiningGROUPBYandORDERBY:\\n○ YoucanusebothGROUPBYandORDERBYinthesamequerytocontroltheorderofgroupedresults.○ Example:SELECTdepartment,COUNT(*)FROMemployeesGROUPBYdepartmentORDERBYCOUNT(*)DESC;\\n● AGGREGATEFUNCTIONS\\nTheseareusedtoperformcalculationsongroupsofrowsorentireresultsets.Theyprovideinsightsintodatabysummarisingandprocessinginformation.\\nCommonAggregateFunctions:\\n- COUNT():Countsthenumberofrowsinagrouporresultset.\\n- SUM():Calculatesthesumofnumericvaluesinagrouporresultset.\\n- AVG():'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 9, 'page_label': '10'}, page_content=\"Computestheaverageofnumericvaluesinagrouporresultset.\\n- MAX():Findsthemaximumvalueinagrouporresultset.\\n- MIN():Retrievestheminimumvalueinagrouporresultset.\\n3. DATAMANIPULATIONLANGUAGE\\nDataManipulationLanguage(DML)inSQLencompassescommandsthatmanipulatedatawithinadatabase.DMLallowsyoutoinsert,update,anddeleterecords,ensuringtheaccuracyandcurrencyofyourdata.\\n● INSERT:\\n- TheINSERTstatementaddsnewrecordstoatable.- Syntax:INSERTINTOtable_name(column1,column2,...)VALUES(value1,value2,...);\\n- Example:INSERTINTOemployees(first_name,last_name,salary)VALUES('John','Doe',50000);\\n● UPDATE:\\n- TheUPDATEstatementmodifiesexistingrecordsinatable.- Syntax:UPDATEtable_nameSETcolumn1=value1,column2=value2,...WHEREcondition;- Example:UPDATEemployeesSETsalary=55000WHEREfirst_name='John';\\n● DELETE:\\n- TheDELETEstatementremovesrecordsfromatable.- Syntax:DELETEFROMtable_nameWHEREcondition;- Example:DELETEFROMemployeesWHERElast_name='Doe';\\n4. DataControlLanguage(DCL)\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 10, 'page_label': '11'}, page_content='DataControlLanguagefocusesonthemanagementofaccessrights,permissions,andsecurity-relatedaspectsofadatabasesystem.\\nDCLcommandsareusedtocontrolwhocanaccessthedata,modifythedata,orperformadministrativetaskswithinadatabase.\\nDCLisanimportantaspectofdatabasesecurity,ensuringthatdataremainsprotectedandonlyauthorisedusershavethenecessaryprivileges.\\nTherearetwomainDCLcommandsinSQL:GRANTandREVOKE.\\n1.GRANT:\\nTheGRANTcommandisusedtoprovidespecificprivilegesorpermissionstousersorroles.Privilegescanincludetheabilitytoperformvariousactionsontables,views,procedures,andotherdatabaseobjects.\\nSyntax:\\nGRANTprivilege_typeONobject_nameTOuser_or_role;\\nInthissyntax:\\n● privilege_typereferstothespecificprivilegeorpermissionbeinggranted(e.g.,SELECT,INSERT,UPDATE,DELETE).● object_nameisthenameofthedatabaseobject(e.g.,table,view)towhichtheprivilegeisbeinggranted.● user_or_roleisthenameoftheuserorrolethatisbeinggrantedtheprivilege.\\nExample:GrantingSELECTprivilegeonatablenamed\"Employees\"toausernamed\"Analyst\":'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 10, 'page_label': '11'}, page_content='Example:GrantingSELECTprivilegeonatablenamed\"Employees\"toausernamed\"Analyst\":\\nGRANTSELECTONEmployeesTOAnalyst;\\n2.REVOKE:\\nTheREVOKEcommandisusedtoremoveorrevokespecificprivilegesorpermissionsthathavebeenpreviouslygrantedtousersorroles.\\nSyntax:\\nREVOKEprivilege_typeONobject_name'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 11, 'page_label': '12'}, page_content='FROMuser_or_role;\\nInthissyntax:\\n● privilege_typeistheprivilegeorpermissionbeingrevoked.● object_nameisthenameofthedatabaseobjectfromwhichtheprivilegeisbeingrevoked.● user_or_roleisthenameoftheuserorrolefromwhichtheprivilegeisbeingrevoked.\\nExample:RevokingtheSELECTprivilegeonthe\"Employees\"tablefromthe\"Analyst\"user:\\nREVOKESELECTONEmployeesFROMAnalyst;\\nDCLandDatabaseSecurity:\\nDCLplaysacrucialroleinensuringthesecurityandintegrityofadatabasesystem.\\nBycontrollingaccessandpermissions,DCLhelpspreventunauthorisedusersfromtamperingwithoraccessingsensitivedata.ProperuseofGRANTandREVOKEcommandsensuresthatonlyuserswhorequirespecificprivilegescanperformcertainactionsondatabaseobjects.\\n5. TransactionControlLanguage(TCL)'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 11, 'page_label': '12'}, page_content='5. TransactionControlLanguage(TCL)\\nTransactionControlLanguage(TCL)dealswiththemanagementoftransactionswithinadatabase.TCLcommandsareusedtocontroltheinitiation,execution,andterminationoftransactions,whicharesequencesofoneormoreSQLstatementsthatareexecutedasasingleunitofwork.Transactionsensuredataconsistency,integrity,andreliabilityinadatabasebygroupingrelatedoperationstogetherandeithercommittingorrollingbackchangesbasedonthesuccessorfailureofthoseoperations.\\nTherearethreemainTCLcommandsinSQL:COMMIT,ROLLBACK,andSAVEPOINT.\\n1.COMMIT:\\nTheCOMMITcommandisusedtopermanentlysavethechangesmadeduringatransaction.'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 12, 'page_label': '13'}, page_content=\"ItmakesallthechangesappliedtothedatabasesincethelastCOMMITorROLLBACKcommandpermanent.OnceaCOMMITisexecuted,thetransactionisconsideredsuccessful,andthechangesaremadepermanent.\\nExample:Committingchangesmadeduringatransaction:\\nUPDATEEmployeesSETSalary=Salary*1.10WHEREDepartment='Sales';\\nCOMMIT;\\n2.ROLLBACK:\\nTheROLLBACKcommandisusedtoundochangesmadeduringatransaction.Itrevertsallthechangesappliedtothedatabasesincethetransactionbegan.\\nROLLBACKistypicallyusedwhenanerroroccursduringtheexecutionofatransaction,ensuringthatthedatabaseremainsinaconsistentstate.\\nExample:Rollingbackchangesduetoanerrorduringatransaction:\\nBEGIN;\\nUPDATEInventorySETQuantity=Quantity-10WHEREProductID=101;\\n--Anerroroccurshere\\nROLLBACK;\\n3.SAVEPOINT:\\nTheSAVEPOINTcommandcreatesanamedpointwithinatransaction,allowingyoutosetapointtowhichyoucanlaterROLLBACKifneeded.\\nSAVEPOINTsareusefulwhenyouwanttoundopartofatransactionwhilepreservingotherchanges.\\nSyntax:SAVEPOINTsavepoint_name;\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 12, 'page_label': '13'}, page_content='SAVEPOINTsareusefulwhenyouwanttoundopartofatransactionwhilepreservingotherchanges.\\nSyntax:SAVEPOINTsavepoint_name;\\nExample:UsingSAVEPOINTtocreateapointwithinatransaction:\\nBEGIN;'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 13, 'page_label': '14'}, page_content=\"UPDATEAccountsSETBalance=Balance-100WHEREAccountID=123;\\nSAVEPOINTbefore_withdrawal;\\nUPDATEAccountsSETBalance=Balance+100WHEREAccountID=456;\\n--Anerroroccurshere\\nROLLBACKTObefore_withdrawal;\\n--Thefirstupdateisstillapplied\\nCOMMIT;\\nTCLandTransactionManagement:\\nTransactionControlLanguage(TCL)commandsarevitalformanagingtheintegrityandconsistencyofadatabase'sdata.Theyallowyoutogrouprelatedchangesintotransactions,andintheeventoferrors,eithercommitthosechangesorrollthembacktomaintaindataintegrity.TCLcommandsareusedincombinationwithDataManipulationLanguage(DML)andotherSQLcommandstoensurethatthedatabaseremainsinareliablestatedespiteunforeseenerrorsorissues.\\nJOINS\\nInaDBMS,ajoinisanoperationthatcombinesrowsfromtwoormoretablesbasedonarelatedcolumnbetweenthem.Joinsareusedtoretrievedatafrommultipletablesbylinkingthemtogetherusingacommonkeyorcolumn.\\nTypesofJoins:\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 14, 'page_label': '15'}, page_content='1. InnerJoin2. OuterJoin3. CrossJoin4. SelfJoin\\n1) InnerJoin\\nAninnerjoincombinesdatafromtwoormoretablesbasedonaspecifiedcondition,knownasthejoincondition.Theresultofaninnerjoinincludesonlytherowswherethejoinconditionismetinallparticipatingtables.Itessentiallyfiltersoutnon-matchingrowsandreturnsonlytherowsthathavematchingvaluesinbothtables.\\nSyntax:\\nSELECTcolumnsFROMtable1INNERJOINtable2ONtable1.column=table2.column;\\nHere:\\n● columnsreferstothespecificcolumnsyouwanttoretrievefromthetables.● table1andtable2arethenamesofthetablesyouarejoining.● columnisthecommoncolumnusedtomatchrowsbetweenthetables.● TheONclausespecifiesthejoincondition,whereyoudefinehowthetablesarerelated.\\nExample:Considertwotables:CustomersandOrders.\\nCustomersTable:\\nCustomerID CustomerName\\n1 Alice\\n2 Bob\\n3 Carol\\nOrdersTable:\\nOrderID CustomerID Product'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 15, 'page_label': '16'}, page_content='101 1 Laptop\\n102 3 Smartphone\\n103 2 Headphones\\nInnerJoinQuery:\\nSELECTCustomers.CustomerName,Orders.ProductFROMCustomersINNERJOINOrdersONCustomers.CustomerID=Orders.CustomerID;\\nResult:\\nCustomerName Product\\nAlice Laptop\\nBob Headphones\\nCarol Smartphone\\n2) OuterJoin\\nOuterjoinscombinedatafromtwoormoretablesbasedonaspecifiedcondition,justlikeinnerjoins.However,unlikeinnerjoins,outerjoinsalsoincluderowsthatdonothavematchingvaluesinbothtables.Outerjoinsareparticularlyusefulwhenyouwanttoincludedatafromonetableevenifthereisnocorrespondingmatchintheothertable.\\nTypes:\\nTherearethreetypesofouterjoins:leftouterjoin,rightouterjoin,andfullouterjoin.\\n1.LeftOuterJoin(LeftJoin):\\nAleftouterjoinreturnsalltherowsfromthelefttableandthematchingrowsfromtherighttable.'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 16, 'page_label': '17'}, page_content=\"Ifthereisnomatchintherighttable,theresultwillstillincludethelefttable'srowwithNULLvaluesintherighttable'scolumns.\\nExample:\\nSELECTCustomers.CustomerName,Orders.ProductFROMCustomersLEFTJOINOrdersONCustomers.CustomerID=Orders.CustomerID;\\nResult:\\nCustomerName Product\\nAlice Laptop\\nBob Headphones\\nCarol Smartphone\\nNULL Monitor\\nInthisexample,theleftouterjoinincludesallrowsfromtheCustomerstable.\\nSincethereisnomatchingcustomerfortheorderwithOrderID103(Monitor),theresultincludesarowwithNULLvaluesintheCustomerNamecolumn.\\n2.RightOuterJoin(RightJoin):\\nArightouterjoinissimilartoaleftouterjoin,butitreturnsallrowsfromtherighttableandthematchingrowsfromthelefttable.\\nIfthereisnomatchinthelefttable,theresultwillstillincludetherighttable'srowwithNULLvaluesinthelefttable'scolumns.\\nExample:UsingthesameCustomersandOrderstables.\\nSELECTCustomers.CustomerName,Orders.ProductFROMCustomersRIGHTJOINOrdersONCustomers.CustomerID=Orders.CustomerID;\\nResult:\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 17, 'page_label': '18'}, page_content=\"CustomerName Product\\nAlice Laptop\\nCarol Smartphone\\nBob Headphones\\nNULL Keyboard\\nHere,therightouterjoinincludesallrowsfromtheOrderstable.SincethereisnomatchingorderforthecustomerwithCustomerID4,theresultincludesarowwithNULLvaluesintheCustomerNamecolumn.\\n3.FullOuterJoin(FullJoin):\\nAfullouterjoinreturnsallrowsfromboththeleftandrighttables,includingmatchesandnon-matches.\\nIfthere'snomatch,NULLvaluesappearincolumnsfromthetablewherethere'snocorrespondingvalue.\\nExample:UsingthesameCustomersandOrderstables.\\nSELECTCustomers.CustomerName,Orders.ProductFROMCustomersFULLOUTERJOINOrdersONCustomers.CustomerID=Orders.CustomerID;\\nResult:\\nCustomerName Product\\nAlice Laptop\\nBob Headphones\\nCarol Smartphone\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 18, 'page_label': '19'}, page_content='NULL Monitor\\nNULL Keyboard\\nInthisfullouterjoinexample,allrowsfrombothtablesareincludedintheresult.Bothnon-matchingrowsfromtheCustomersandOrderstablesarerepresentedwithNULLvalues.\\n3) CrossJoin\\nAcrossjoin,alsoknownasaCartesianproduct,isatypeofjoinoperationinaDatabaseManagementSystem(DBMS)thatcombineseveryrowfromonetablewitheveryrowfromanothertable.\\nUnlikeotherjointypes,acrossjoindoesnotrequireaspecificconditiontomatchrowsbetweenthetables.Instead,itgeneratesaresultsetthatcontainsallpossiblecombinationsofrowsfrombothtables.\\nCrossjoinscanleadtoalargeresultset,especiallywhentheparticipatingtableshavemanyrows.\\nSyntax:\\nSELECTcolumnsFROMtable1CROSSJOINtable2;\\nInthissyntax:\\n● columnsreferstothespecificcolumnsyouwanttoretrievefromthecross-joinedtables.● table1andtable2arethenamesofthetablesyouwanttocombineusingacrossjoin.\\nExample:Considertwotables:StudentsandCourses.\\nStudentsTable:\\nStudentID StudentName\\n1 Alice'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 19, 'page_label': '20'}, page_content='2 Bob\\nCoursesTable:\\nCourseID CourseName\\n101 Maths\\n102 Science\\nCrossJoinQuery:\\nSELECTStudents.StudentName,Courses.CourseNameFROMStudentsCROSSJOINCourses;\\nResult:\\nStudentName CourseName\\nAlice Maths\\nAlice Science\\nBob Maths\\nBob Science\\nInthisexample,thecrossjoinbetweentheStudentsandCoursestablesgeneratesallpossiblecombinationsofrowsfrombothtables.Asaresult,eachstudentispairedwitheachcourse,leadingtoatotaloffourrowsintheresultset.\\n4) SelfJoin\\nAselfjoininvolvesjoiningatablewithitself.\\nThistechniqueisusefulwhenatablecontainshierarchicalorrelateddataandyouneedtocompareoranalyserowswithinthesametable.'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 20, 'page_label': '21'}, page_content=\"Selfjoinsarecommonlyusedtofindrelationships,hierarchies,orpatternswithinasingletable.\\nInaselfjoin,youtreatthetableasifitweretwoseparatetables,referringtothemwithdifferentaliases.\\nSyntax:\\nThesyntaxforperformingaselfjoininSQLisasfollows:\\nSELECTcolumnsFROMtable1ASalias1JOINtable1ASalias2ONalias1.column=alias2.column;\\nInthissyntax:● columnsreferstothespecificcolumnsyouwanttoretrievefromtheself-joinedtable.● table1isthenameofthetableyou'rejoiningwithitself.● alias1andalias2arealiasesyouassigntothetableinstancesfordifferentiation.● columnisthecolumnyouuseasthejoinconditiontolinkrowsfromthesametable.\\nExample:ConsideranEmployeestablethatcontainsinformationaboutemployeesandtheirmanagers.\\nEmployeesTable:\\nEmployeeID EmployeeName ManagerID\\n1 Alice 3\\n2 Bob 3\\n3 Carol NULL\\n4 David 1\\nSelfJoinQuery:\\nSELECTe1.EmployeeNameASEmployee,e2.EmployeeNameASManagerFROMEmployeesASe1JOINEmployeesASe2ONe1.ManagerID=e2.EmployeeID;\\nResult:\\nEmployee Manager\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 21, 'page_label': '22'}, page_content='Alice Carol\\nBob Carol\\nDavid Alice\\nInthisexample,theselfjoinisperformedontheEmployeestabletofindtherelationshipbetweenemployeesandtheirmanagers.ThejoinconditionconnectstheManagerIDcolumninthee1alias(representingemployees)withtheEmployeeIDcolumninthee2alias(representingmanagers).\\nSETOPERATIONS\\nSetoperationsinSQLareusedtocombineormanipulatetheresultsetsofmultipleSELECTqueries.Theyallowyoutoperformoperationssimilartothoseinsettheory,suchasunion,intersection,anddifference,onthedataretrievedfromdifferenttablesorqueries.\\nSetoperationsprovidepowerfultoolsformanagingandmanipulatingdata,enablingyoutoanalyseandcombineinformationinvariousways.\\nTherearefourprimarysetoperationsinSQL:\\n● UNION● INTERSECT● EXCEPT(orMINUS)● UNIONALL\\n1.UNION:\\nTheUNIONoperatorcombinestheresultsetsoftwoormoreSELECTqueriesintoasingleresultset.Itremovesduplicatesbydefault,meaningthatifthereareidenticalrowsintheresultsets,onlyoneinstanceofeachrowwillappearinthefinalresult.\\nExample:\\nAssumewehavetwotables:CustomersandSuppliers.'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 22, 'page_label': '23'}, page_content='CustomersTable:\\nCustomerID CustomerName\\n1 Alice\\n2 Bob\\nSuppliersTable:\\nSupplierID SupplierName\\n101 SupplierA\\n102 SupplierB\\nUNIONQuery:\\nSELECTCustomerNameFROMCustomersUNIONSELECTSupplierNameFROMSuppliers;\\nResult:\\nCustomerName\\nAlice\\nBob\\nSupplierA\\nSupplierB\\n2.INTERSECT:\\nTheINTERSECToperatorreturnsthecommonrowsthatexistintheresultsetsoftwoormoreSELECTqueries.\\nItonlyreturnsdistinctrowsthatappearinallresultsets.'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 23, 'page_label': '24'}, page_content='Example:Usingthesametablesasbefore.\\nSELECTCustomerNameFROMCustomersINTERSECTSELECTSupplierNameFROMSuppliers;\\nResult:\\nCustomerName\\nInthisexample,therearenocommonnamesbetweencustomersandsuppliers,sotheresultisanemptyset.\\n3.EXCEPT(orMINUS):\\nTheEXCEPToperator(alsoknownasMINUSinsomedatabases)returnsthedistinctrowsthatarepresentintheresultsetofthefirstSELECTquerybutnotintheresultsetofthesecondSELECTquery.\\nExample:Usingthesametablesasbefore.\\nSELECTCustomerNameFROMCustomersEXCEPTSELECTSupplierNameFROMSuppliers;\\nResult:\\nCustomerName\\nAlice\\nBob\\nInthisexample,thenames\"Alice\"and\"Bob\"arecustomersbutnotsuppliers,sotheyappearintheresultset.\\n4.UNIONALL:\\nTheUNIONALLoperatorperformsthesamefunctionastheUNIONoperatorbutdoesnotremoveduplicatesfromtheresultset.Itsimplyconcatenatesallrowsfromthedifferentresultsets.'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 24, 'page_label': '25'}, page_content='Example:Usingthesametablesasbefore.\\nSELECTCustomerNameFROMCustomersUNIONALLSELECTSupplierNameFROMSuppliers;\\nResult:\\nCustomerName\\nAlice\\nBob\\nSupplierA\\nSupplierB\\nDifferencebetweenSetOperationsandJoins\\nA s p e c t S e t O p e r a t i o n s J o i n s \\n P u r p o s e \\n M a n i p u l a t e r e s u l t s e t s b a s e d o n \\n s e t t h e o r y p r i n c i p l e s . \\n C o m b i n e d a t a f r o m r e l a t e d \\n t a b l e s b a s e d o n s p e c i ﬁ e d \\n c o n d i t i o n s .'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 25, 'page_label': '26'}, page_content='D a t a S o u r c e R e s u l t s e t s o f S E L E C T q u e r i e s . \\n T a b l e s t h a t a r e r e l a t e d b y \\n c o m m o n c o l u m n s . \\n C o m b i n i n g R o w s \\n C o m b i n e r o w s f r o m d i f f e r e n t \\n r e s u l t s e t s . M a y r e m o v e \\n d u p l i c a t e s . \\n C o m b i n e r o w s f r o m d i f f e r e n t \\n t a b l e s b a s e d o n s p e c i ﬁ e d \\n c o n d i t i o n s . \\n O u t p u t C o l u m n s \\n R e q u i r e t h e S E L E C T q u e r i e s t o \\n h a v e t h e s a m e n u m b e r o f o u t p u t \\n c o l u m n s a n d c o m p a t i b l e d a t a \\n t y p e s . \\n C a n c o m b i n e c o l u m n s f r o m \\n d i f f e r e n t t a b l e s , r e g a r d l e s s o f \\n d a t a t y p e s o r c o l u m n n u m b e r s . \\n C o m m o n \\n O p e r a t i o n s \\n U N I O N , I N T E R S E C T , E X C E P T \\n ( M I N U S ) . \\n I N N E R J O I N , L E F T J O I N , R I G H T \\n J O I N , F U L L J O I N . \\n C o n d i t i o n a l \\n R e q u i r e m e n t s'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 25, 'page_label': '26'}, page_content='U N I O N , I N T E R S E C T , E X C E P T \\n ( M I N U S ) . \\n I N N E R J O I N , L E F T J O I N , R I G H T \\n J O I N , F U L L J O I N . \\n C o n d i t i o n a l \\n R e q u i r e m e n t s \\n N o s p e c i ﬁ c j o i n c o n d i t i o n s a r e \\n r e q u i r e d . \\n R e q u i r e s p e c i ﬁ e d j o i n c o n d i t i o n s \\n f o r c o m b i n i n g d a t a . \\n H a n d l i n g \\n D u p l i c a t e s \\n U N I O N r e m o v e s d u p l i c a t e s b y \\n d e f a u l t . \\n J o i n s d o n o t i n h e r e n t l y h a n d l e \\n d u p l i c a t e s ; i t d e p e n d s o n t h e j o i n \\n t y p e a n d d a t a .'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 26, 'page_label': '27'}, page_content='U s a g e S c e n a r i o s \\n U s e f u l f o r c o m b i n i n g a n d \\n a n a l y s i n g r e l a t e d d a t a f r o m \\n d i f f e r e n t q u e r i e s o r t a b l e s . \\n U s e d t o r e t r i e v e a n d r e l a t e d a t a \\n f r o m d i f f e r e n t t a b l e s b a s e d o n \\n t h e i r r e l a t i o n s h i p s . \\n R e s u l t S e t \\n S t r u c t u r e \\n R e s u l t s e t s m a y h a v e d i f f e r e n t \\n c o l u m n n a m e s , b u t d a t a t y p e s a n d \\n c o u n t s m u s t m a t c h . \\n R e s u l t s e t s c a n h a v e d i f f e r e n t \\n c o l u m n n a m e s , d a t a t y p e s , a n d \\n c o u n t s . \\n P e r f o r m a n c e \\n C o n s i d e r a t i o n s \\n G e n e r a l l y f a s t e r a n d l e s s c o m p l e x \\n t h a n j o i n s . \\n J o i n s c a n b e m o r e c o m p l e x a n d \\n r e s o u r c e - i n t e n s i v e , e s p e c i a l l y f o r \\n l a r g e r d a t a s e t s . \\nSUBQUERIES'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 26, 'page_label': '27'}, page_content='t h a n j o i n s . \\n J o i n s c a n b e m o r e c o m p l e x a n d \\n r e s o u r c e - i n t e n s i v e , e s p e c i a l l y f o r \\n l a r g e r d a t a s e t s . \\nSUBQUERIES\\nSubqueries,alsoknownasnestedqueriesorinnerqueries,allowyoutousetheresultofonequery(theinnerquery)astheinputforanotherquery(theouterquery).\\nSubqueriesareoftenusedtoretrievedatathatwillbeusedforfiltering,comparison,orcalculationwithinthecontextofalargerquery.\\nTheyareawaytobreakdowncomplextasksintosmaller,manageablesteps.\\nSyntax:\\nSELECTcolumns'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 27, 'page_label': '28'}, page_content=\"FROMtableWHEREcolumnOPERATOR(SELECTcolumnFROMtableWHEREcondition);\\nInthissyntax:\\n● columnsreferstothespecificcolumnsyouwanttoretrievefromtheouterquery.● tableisthenameofthetableyou'requerying.● columnisthecolumnyou'reapplyingtheoperatortointheouterquery.● OPERATORisacomparisonoperatorsuchas=,>,<,IN,NOTIN,etc.● (SELECTcolumnFROMtableWHEREcondition)isthesubquerythatprovidestheinputforthecomparison.\\nExample:Considertwotables:ProductsandOrders.\\nProductsTable:\\nProductID ProductName Price\\n1 Laptop 1000\\n2 Smartphone 500\\n3 Headphones 50\\nOrdersTable:\\nOrderID ProductID Quantity\\n101 1 2\\n102 3 1\\nForExample:Retrievetheproductnamesandquantitiesfororderswithatotalcostgreaterthantheaveragepriceofallproducts.\\nSELECTProductName,QuantityFROMProductsWHEREPrice*Quantity>(SELECTAVG(Price)FROMProducts);\\nResult:\\nProductName Quantity\"),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 28, 'page_label': '29'}, page_content='Laptop 2\\nDifferencesBetweenSubqueriesandJoins:\\nAspect Subqueries Joins\\nPurpose\\nRetrievedataforfiltering,comparison,orcalculationwithinthecontextofalargerquery.\\nCombinedatafromrelatedtablesbasedonspecifiedconditions.\\nDataSource\\nResultofonequeryusedasinputforanotherquery.\\nDatafrommultiplerelatedtables.\\nCombiningRows\\nNotusedforcombiningrows;usedtofilterorevaluatedata.\\nCombinesrowsfromdifferenttablesbasedonspecifiedjoinconditions.\\nResultSetStructure\\nSubqueriesreturnscalarvalues,single-columnresults,orsmallresultsets.\\nJoinsreturnmulti-columnresultsets.\\nPerformanceConsiderations\\nSubqueriescanbeslowerandlessefficient,especiallywhendealingwithlargedatasets.\\nJoinscanbemoreefficientforcombiningdatafrommultipletables.\\nComplexity\\nSubqueriescanbeeasiertounderstandforsimpletasksorsmallerdatasets.\\nJoinscanbecomecomplex,butaremoresuitedforhandlinglarge-scaledataretrievalandcombinationtasks.\\nVersatility\\nSubqueriescanbeusedinvariousclauses:WHERE,FROM,HAVING,etc.'),\n",
       " Document(metadata={'source': 'Data\\\\SQL1.pdf', 'page': 28, 'page_label': '29'}, page_content='Joinscanbecomecomplex,butaremoresuitedforhandlinglarge-scaledataretrievalandcombinationtasks.\\nVersatility\\nSubqueriescanbeusedinvariousclauses:WHERE,FROM,HAVING,etc.\\nJoinsareprimarilyusedintheFROMclauseforcombiningtables.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Document\npage_content\n  Input should be a valid string [type=string_type, input_value=Document(metadata={'sourc...e/g425 Luca  Del Tongo'), input_type=Document]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document  \u001b[38;5;66;03m# Import Document class\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# If `chunks` is a list of strings, convert them into `Document` objects\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m documents \u001b[38;5;241m=\u001b[39m [\u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m      8\u001b[0m vector_db \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m      9\u001b[0m     documents\u001b[38;5;241m=\u001b[39mdocuments,  \n\u001b[0;32m     10\u001b[0m     embedding\u001b[38;5;241m=\u001b[39mOllamaEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnomic-embed-text\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     11\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal-rag\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVector database created successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PRATHMESH\\Documents\\Backend\\env\\Lib\\site-packages\\langchain_core\\documents\\base.py:285\u001b[0m, in \u001b[0;36mDocument.__init__\u001b[1;34m(self, page_content, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Pass page_content in as positional or named arg.\"\"\"\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# my-py is complaining that page_content is not defined on the base class.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Here, we're relying on pydantic base class to handle the validation.\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PRATHMESH\\Documents\\Backend\\env\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PRATHMESH\\Documents\\Backend\\env\\Lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for Document\npage_content\n  Input should be a valid string [type=string_type, input_value=Document(metadata={'sourc...e/g425 Luca  Del Tongo'), input_type=Document]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up LLM and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LLM and retrieval\n",
    "local_model = \"llama3.2\"  \n",
    "llm = ChatOllama(model=local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 14\u001b[0m\n\u001b[0;32m      2\u001b[0m QUERY_PROMPT \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m      3\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      4\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are an AI language model assistant. Your task is to generate 2\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m    Original question: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Set up retriever\u001b[39;00m\n\u001b[0;32m     13\u001b[0m retriever \u001b[38;5;241m=\u001b[39m MultiQueryRetriever\u001b[38;5;241m.\u001b[39mfrom_llm(\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mvector_db\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(), \n\u001b[0;32m     15\u001b[0m     llm,\n\u001b[0;32m     16\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mQUERY_PROMPT\n\u001b[0;32m     17\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector_db' is not defined"
     ]
    }
   ],
   "source": [
    "# Query prompt template\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate 2\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "# Set up retriever\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = \"\"\"Some point to note while generating an answer:\n",
    "a) Be curteous and creative in your responses. Answer like you are a friendly agent, making the user feel comfortable.\n",
    "a.1) Imagine yourself as an intelligent assistant which is helping the users on different types of study materials. You will have a knolwedgebase of study materials to search on.\n",
    "b) Be very structured in your response, Give the response with html tags as explained below\n",
    "give <b> html tags for bullet points and to bold the important words. Use <br> html tags to display contents in new lines wherever required for clear displaying. \n",
    "Important Note : We need to display the content with proper HTML tags. Your task is to automatically add the relevant <li>, <ul>, break <br>, <p>, bold <b> tags to beautifully present the responses to be displayed in an html <div> tag.\n",
    "c) Remember to not talk about any leaves that are not applicable to me. Example Maternity Leaves are not applicable to male employees. Contractual Leave is not valid for non contractual employeesS\n",
    "d) The answer should not be in the email format and look like a normal chat.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "Please provide the answer in a clear, point-wise format for better readability:\n",
    "1. ...\n",
    "2. ...\n",
    "3. ...\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chain\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_pdf(question):\n",
    "    \"\"\"\n",
    "    Chat with the PDF using the RAG chain.\n",
    "    \"\"\"\n",
    "    return display(Markdown(chain.invoke(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's the information about SQL:\n",
       "\n",
       "**What is SQL?**\n",
       "\n",
       "* SQL stands for Structured Query Language.\n",
       "* It is a programming language designed for managing and manipulating data stored in relational database management systems (RDBMS).\n",
       "\n",
       "**Main Characteristics of SQL:**\n",
       "\n",
       "1. **Declarative Language**: SQL is used to declare what you want to do with your data, rather than how to do it.\n",
       "2. **Structured**: SQL uses a structured syntax to define queries, with a focus on readability and maintainability.\n",
       "3. **Language**: SQL is a language that allows you to interact with databases, perform operations, and retrieve data.\n",
       "\n",
       "**SQL Syntax:**\n",
       "\n",
       "* SQL commands are written in a specific syntax, which includes:\n",
       "\t+ SELECT\n",
       "\t+ INSERT\n",
       "\t+ UPDATE\n",
       "\t+ DELETE\n",
       "\t+ CREATE\n",
       "\t+ DROP\n",
       "\t+ ALTER\n",
       "\n",
       "**Common SQL Operations:**\n",
       "\n",
       "1. **Data Retrieval**: Use the SELECT statement to retrieve data from a database.\n",
       "2. **Data Insertion**: Use the INSERT statement to add new data to a database.\n",
       "3. **Data Update**: Use the UPDATE statement to modify existing data in a database.\n",
       "4. **Data Deletion**: Use the DELETE statement to remove data from a database.\n",
       "\n",
       "**SQL Uses:**\n",
       "\n",
       "1. **Database Management**: SQL is used to manage and manipulate data stored in relational databases.\n",
       "2. **Data Analysis**: SQL is used to analyze and retrieve data for decision-making purposes.\n",
       "3. **Web Development**: SQL is used to interact with web applications that use databases as storage.\n",
       "4. **Business Intelligence**: SQL is used to perform complex queries and reports on large datasets.\n",
       "\n",
       "**Key Benefits of SQL:**\n",
       "\n",
       "1. **Standardization**: SQL is a standardized language, making it easy to communicate between different database systems.\n",
       "2. **Flexibility**: SQL allows for flexible data modeling, enabling efficient storage and retrieval of complex data structures.\n",
       "3. **Security**: SQL provides robust security features to protect sensitive data.\n",
       "\n",
       "Overall, SQL is an essential tool for anyone working with databases, providing a powerful and flexible language for managing and analyzing data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1\n",
    "chat_with_pdf(\"What is SQL?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the detailed information about SQL commands:\n",
       "\n",
       "**SQL Commands**\n",
       "\n",
       "### 1. CREATE INDEX\n",
       "* **Purpose**: Create an index on one or more columns in a table.\n",
       "* **Syntax**: `CREATE INDEX index_name ON table_name (column1, column2, ...)`\n",
       "* **Example**: `CREATE INDEX idx_employee_name ON employees (name);`\n",
       "* **Benefits**:\n",
       "\t+ Improves query performance by enabling faster data retrieval.\n",
       "\t+ Reduces the number of rows that need to be scanned during a query.\n",
       "\n",
       "### 2. DROP INDEX\n",
       "* **Purpose**: Remove an existing index from a table.\n",
       "* **Syntax**: `DROP INDEX index_name ON table_name;`\n",
       "* **Example**: `DROP INDEX idx_employee_name;`\n",
       "* **Benefits**:\n",
       "\t+ Removes the index, which can improve performance if the index is not used.\n",
       "\n",
       "### 3. CREATE CONSTRAINT\n",
       "* **Purpose**: Define constraints that ensure data integrity.\n",
       "* **Constraints include**:\n",
       "\t+ PRIMARY KEY: ensures a unique value in a column or set of columns.\n",
       "\t+ FOREIGN KEY: ensures relationships between tables.\n",
       "\t+ UNIQUE: ensures that only unique values are stored in a column.\n",
       "\t+ NOT NULL: ensures that a value is not null in a column.\n",
       "\t+ CHECK: ensures that a value meets a specific condition.\n",
       "* **Syntax**: `ALTER TABLE table_name ADD CONSTRAINT constraint_name [CONSTRAINT_TYPE] [COLUMN_NAME]`\n",
       "* **Example**: `ALTER TABLE orders ADD CONSTRAINT fk_customer FOREIGN KEY (customer_id) REFERENCES customers(id);`\n",
       "\n",
       "### 4. DROP CONSTRAINT\n",
       "* **Purpose**: Remove an existing constraint from a table.\n",
       "* **Syntax**: `ALTER TABLE table_name DROP CONSTRAINT constraint_name;`\n",
       "* **Example**: `ALTER TABLE orders DROP CONSTRAINT fk_customer;`\n",
       "* **Benefits**:\n",
       "\t+ Removes the constraint, which can simplify queries.\n",
       "\n",
       "### 5. TRUNCATE TABLE\n",
       "* **Purpose**: Delete data from a table, but not the table itself.\n",
       "* **Syntax**: `TRUNCATE TABLE table_name;`\n",
       "* **Example**: `TRUNCATE TABLE orders;`\n",
       "* **Benefits**:\n",
       "\t+ Quickly removes all rows from a table without affecting indexing or relationships.\n",
       "\n",
       "### 6. SELECT\n",
       "* **Purpose**: Retrieve data from a database.\n",
       "* **Syntax**: `SELECT column1, column2, ... FROM table_name [WHERE condition];`\n",
       "* **Example**: `SELECT * FROM employees;` (returns all columns and rows)\n",
       "* **Benefits**:\n",
       "\t+ Allows extraction of specific columns from a table.\n",
       "\n",
       "### 7. CREATE TABLE\n",
       "* **Purpose**: Create a new table in the database.\n",
       "* **Syntax**: `CREATE TABLE table_name (column1 data_type, column2 data_type, ...);`\n",
       "* **Example**: `CREATE TABLE employees (id INT PRIMARY KEY, name VARCHAR(50), department VARCHAR(20));`\n",
       "\n",
       "### 8. DROP TABLE\n",
       "* **Purpose**: Remove an existing table from the database.\n",
       "* **Syntax**: `DROP TABLE table_name;`\n",
       "* **Example**: `DROP TABLE orders;`\n",
       "* **Benefits**:\n",
       "\t+ Removes the table and all data it contains.\n",
       "\n",
       "### 9. ALTER TABLE\n",
       "* **Purpose**: Make changes to a table, such as adding or removing columns.\n",
       "* **Syntax**: `ALTER TABLE table_name [ADD|REMOVE] COLUMN column_name [data_type];`\n",
       "* **Example**: `ALTER TABLE employees ADD COLUMN salary DECIMAL(10, 2);`\n",
       "\n",
       "### 10. UPDATE\n",
       "* **Purpose**: Modify existing data in a table.\n",
       "* **Syntax**: `UPDATE table_name SET column1 = value1, column2 = value2 WHERE condition;`\n",
       "* **Example**: `UPDATE employees SET salary = 50000 WHERE id = 1;`\n",
       "\n",
       "### 11. DELETE\n",
       "* **Purpose**: Remove data from a table.\n",
       "* **Syntax**: `DELETE FROM table_name WHERE condition;`\n",
       "* **Example**: `DELETE FROM orders WHERE customer_id = 1;`\n",
       "\n",
       "Note that this is not an exhaustive list of SQL commands, but rather a selection of commonly used ones."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1\n",
    "chat_with_pdf(\"give me detail information about sql commands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a detailed explanation of Bubble Sort:\n",
       "\n",
       "**What is Bubble Sort?**\n",
       "\n",
       "Bubble Sort is a simple sorting algorithm that works by repeatedly iterating through a list of elements and swapping adjacent elements if they are in the wrong order.\n",
       "\n",
       "**How does it work?**\n",
       "\n",
       "1. The algorithm starts at the beginning of the list.\n",
       "2. It compares the first two elements and swaps them if they are in the wrong order (i.e., if the first element is greater than the second element).\n",
       "3. It then moves to the next pair of elements (the third and fourth elements) and repeats the process, comparing and swapping adjacent elements if necessary.\n",
       "4. This process continues until the end of the list is reached.\n",
       "5. The algorithm then starts over from the beginning of the list, but this time it only compares elements that have not been swapped yet. If any swaps are made, the process repeats until no more swaps are needed.\n",
       "\n",
       "**Step-by-Step Example**\n",
       "\n",
       "Suppose we want to sort the following list using Bubble Sort:\n",
       "\n",
       "`[5, 2, 8, 3, 1]`\n",
       "\n",
       "1. Start at the beginning of the list and compare the first two elements (5 and 2). Since 5 is greater than 2, swap them.\n",
       "`[2, 5, 8, 3, 1]`\n",
       "2. Move to the next pair of elements (5 and 8). Since 5 is less than 8, no swap is needed.\n",
       "3. Continue this process until the end of the list is reached:\n",
       "\t* Compare 5 and 3. Swap if necessary (no swap).\n",
       "\t* Compare 5 and 1. Swap if necessary (swap).\n",
       "\t* Compare 2 and 1. Swap if necessary (swap).\n",
       "4. The sorted list is now `[1, 2, 3, 5, 8]`.\n",
       "5. Start over from the beginning of the list:\n",
       "\t* Compare 1 and 2. No swap.\n",
       "\t* Compare 2 and 3. No swap.\n",
       "\t* ...and so on.\n",
       "6. Since no swaps were made this time, the algorithm terminates and the final sorted list is `[1, 2, 3, 5, 8]`.\n",
       "\n",
       "**Time Complexity**\n",
       "\n",
       "The time complexity of Bubble Sort is O(n^2), where n is the number of elements in the list. This means that the algorithm's running time increases quadratically with the size of the input.\n",
       "\n",
       "**Space Complexity**\n",
       "\n",
       "The space complexity of Bubble Sort is O(1), since it only requires a single additional memory location to store temporary swap values.\n",
       "\n",
       "**Use Cases**\n",
       "\n",
       "Bubble Sort is suitable for small datasets or when the dataset is nearly sorted, as its simplicity and stability make it easy to implement. However, for larger datasets or more complex data structures, other sorting algorithms like QuickSort or Merge Sort may be more efficient."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1\n",
    "chat_with_pdf(input(\"Enter your Query : \" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "   \n",
    "     \n",
    "         ## Clean up (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up when done \n",
    "vector_db.delete_collection()\n",
    "print(\"Vector database deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
